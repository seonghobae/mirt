[{"path":"https://philchalmers.github.io/mirt/articles/mirt-vignettes.html","id":"mirt-vignette-files","dir":"Articles","previous_headings":"","what":"mirt Vignette Files","title":"","text":"access examples, vignettes, exercise files generated knitr please visit link.","code":""},{"path":"https://philchalmers.github.io/mirt/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Phil Chalmers. Author, maintainer. Joshua Pritikin. Contributor. Alexander Robitzsch. Contributor. Mateusz Zoltak. Contributor. KwonHyun Kim. Contributor. Carl F. Falk. Contributor. Adam Meade. Contributor. Lennart Schneider. Contributor. David King. Contributor. Chen-Wei Liu. Contributor. Ogreden Oguzhan. Contributor.","code":""},{"path":"https://philchalmers.github.io/mirt/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"R. Philip Chalmers (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":"@Article{,   title = {{mirt}: A Multidimensional Item Response Theory Package for the {R} Environment},   author = {R. Philip Chalmers},   journal = {Journal of Statistical Software},   year = {2012},   volume = {48},   number = {6},   pages = {1--29},   doi = {10.18637/jss.v048.i06}, }"},{"path":"https://philchalmers.github.io/mirt/index.html","id":"mirt-","dir":"","previous_headings":"","what":"Multidimensional Item Response Theory","title":"Multidimensional Item Response Theory","text":"Multidimensional item response theory R.","code":""},{"path":"https://philchalmers.github.io/mirt/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"Multidimensional Item Response Theory","text":"Analysis dichotomous polytomous response data using unidimensional multidimensional latent trait models Item Response Theory paradigm. Exploratory confirmatory models can estimated quadrature (EM) stochastic (MHRM) methods. Confirmatory bi-factor two-tier analyses available modeling item testlets. Multiple group analysis mixed effects designs also available detecting differential item functioning modeling item person covariates.","code":""},{"path":"https://philchalmers.github.io/mirt/index.html","id":"examples-and-evaluated-help-files-are-available-on-the-wiki","dir":"","previous_headings":"","what":"Examples and evaluated help files are available on the wiki","title":"Multidimensional Item Response Theory","text":"Various examples worked help files compiled using knitr package generate HTML output, available package wiki. User contributions welcome!","code":""},{"path":"https://philchalmers.github.io/mirt/index.html","id":"installing-from-source","dir":"","previous_headings":"","what":"Installing from source","title":"Multidimensional Item Response Theory","text":"’s recommended use development version package since likely date version CRAN. install package source: Obtain recent gcc, g++, gfortran compilers. Windows users can install Rtools suite Mac users download necessary tools Xcode suite related command line tools (found within Xcode’s Preference Pane Downloads/Components); Linux distributions already date compilers (can updated easily). Windows users include checkbox option installing Rtools path easier command line usage. Install devtools package (necessary). R, paste following console: Load devtools package (requires version 1.4+) install Github source code.","code":"install.packages('devtools') library('devtools') install_github('philchalmers/mirt')"},{"path":"https://philchalmers.github.io/mirt/index.html","id":"installing-from-source-via-git","dir":"","previous_headings":"Installing from source","what":"Installing from source via git","title":"Multidimensional Item Response Theory","text":"devtools approach work system, can download install repository directly. Obtain recent gcc, g++, gfortran compilers (see instructions). Install git command line tools. Open terminal/command-line tool. following code download repository code computer, install package directly using R tools (Windows users may also add R git path)","code":"git clone https://github.com/philchalmers/mirt R CMD INSTALL mirt"},{"path":"https://philchalmers.github.io/mirt/index.html","id":"special-mac-os-x-installation-instructions","dir":"","previous_headings":"Installing from source","what":"Special Mac OS X Installation Instructions","title":"Multidimensional Item Response Theory","text":"reported cases XCode install appropriate gfortran compilers correct location, therefore installed manually instead. accomplished inputing following instructions terminal:","code":"curl -O http://r.research.att.com/libs/gfortran-4.8.2-darwin13.tar.bz2 sudo tar fvxz gfortran-4.8.2-darwin13.tar.bz2 -C /"},{"path":"https://philchalmers.github.io/mirt/index.html","id":"licence","dir":"","previous_headings":"","what":"Licence","title":"Multidimensional Item Response Theory","text":"package free open source software, licensed GPL (>= 3).","code":""},{"path":"https://philchalmers.github.io/mirt/index.html","id":"bugs-and-questions","dir":"","previous_headings":"","what":"Bugs and Questions","title":"Multidimensional Item Response Theory","text":"Bug reports always welcome preferred way address bugs Github ‘issues’. Feel free submit issues feature requests site, ’ll address ASAP. Also, questions package, IRT general, feel free create ‘New Topic’ mirt-package Google group. Cheers!","code":""},{"path":"https://philchalmers.github.io/mirt/reference/ASVAB.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of ASVAB data — ASVAB","title":"Description of ASVAB data — ASVAB","text":"Table counts extracted Mislvey (1985). Data 16 possible response patterns observed four items arithmetic reasoning test Armed Services Vocational Aptitude Battery (ASVAB), Form 8A, samples white males females black males females.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/ASVAB.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of ASVAB data — ASVAB","text":"Mislevy, R. J. (1985). Estimation latent group effects. Journal American Statistical Association, 80, 993-997.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/ASVAB.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of ASVAB data — ASVAB","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/ASVAB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of ASVAB data — ASVAB","text":"","code":"data(ASVAB) datWM <- expand.table(subset(ASVAB, select=c(Item.1:Item.4, White_Male))) datWF <- expand.table(subset(ASVAB, select=c(Item.1:Item.4, White_Female))) datBM <- expand.table(subset(ASVAB, select=c(Item.1:Item.4, Black_Male))) datBF <- expand.table(subset(ASVAB, select=c(Item.1:Item.4, Black_Female)))  dat <- rbind(datWM, datWF, datBM, datBF) sex <- rep(c(\"Male\", \"Female\", \"Male\", \"Female\"),   times=c(nrow(datWM), nrow(datWF), nrow(datBM), nrow(datBF))) |> factor() color <- rep(c(\"White\", \"Black\"),   times=c(nrow(datWM) + nrow(datWF), nrow(datBM) + nrow(datBF))) |> factor() group <- sex:color  itemstats(dat, group=group) #> $`Female:Black` #> $`Female:Black`$overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  145            1.462          1.014 0.046 0.087 0.176     0.921 #>  #> $`Female:Black`$itemstats #>          N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 145 0.503 0.502   0.659         0.213      -0.078 #> Item.2 145 0.421 0.495   0.550         0.074       0.152 #> Item.3 145 0.283 0.452   0.501         0.064       0.164 #> Item.4 145 0.255 0.437   0.421        -0.011       0.256 #>  #> $`Female:Black`$proportions #>            0     1 #> Item.1 0.497 0.503 #> Item.2 0.579 0.421 #> Item.3 0.717 0.283 #> Item.4 0.745 0.255 #>  #>  #> $`Female:White` #> $`Female:White`$overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  228            2.118          1.255 0.208 0.037 0.512     0.877 #>  #> $`Female:White`$itemstats #>          N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 228 0.618 0.487   0.615         0.277       0.464 #> Item.2 228 0.605 0.490   0.642         0.312       0.432 #> Item.3 228 0.487 0.501   0.629         0.284       0.458 #> Item.4 228 0.408 0.493   0.662         0.339       0.408 #>  #> $`Female:White`$proportions #>            0     1 #> Item.1 0.382 0.618 #> Item.2 0.395 0.605 #> Item.3 0.513 0.487 #> Item.4 0.592 0.408 #>  #>  #> $`Male:Black` #> $`Male:Black`$overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  140            1.443          1.027 0.051 0.102  0.18      0.93 #>  #> $`Male:Black`$itemstats #>          N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 140 0.443 0.499   0.612         0.158       0.029 #> Item.2 140 0.400 0.492   0.587         0.133       0.071 #> Item.3 140 0.329 0.471   0.426        -0.037       0.304 #> Item.4 140 0.271 0.446   0.521         0.100       0.123 #>  #> $`Male:Black`$proportions #>            0     1 #> Item.1 0.557 0.443 #> Item.2 0.600 0.400 #> Item.3 0.671 0.329 #> Item.4 0.729 0.271 #>  #>  #> $`Male:White` #> $`Male:White`$overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  263            2.475          1.361  0.34 0.075 0.673     0.779 #>  #> $`Male:White`$itemstats #>          N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 263 0.741 0.439   0.705         0.475       0.596 #> Item.2 263 0.635 0.482   0.649         0.361       0.667 #> Item.3 263 0.593 0.492   0.734         0.481       0.588 #> Item.4 263 0.506 0.501   0.754         0.507       0.569 #>  #> $`Male:White`$proportions #>            0     1 #> Item.1 0.259 0.741 #> Item.2 0.365 0.635 #> Item.3 0.407 0.593 #> Item.4 0.494 0.506 #>  #>"},{"path":"https://philchalmers.github.io/mirt/reference/Bock1997.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of Bock 1997 data — Bock1997","title":"Description of Bock 1997 data — Bock1997","text":"3-item tabulated data set extracted Table 3 Chapter Two.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Bock1997.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of Bock 1997 data — Bock1997","text":"Bock, R. D. (1997). Nominal Categories Model. van der Linden, W. J. & Hambleton, R. K. Handbook modern item response theory. New York: Springer.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Bock1997.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of Bock 1997 data — Bock1997","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Bock1997.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of Bock 1997 data — Bock1997","text":"","code":"if (FALSE) { # \\dontrun{ dat <- expand.table(Bock1997) head(dat) itemstats(dat, use_ts=FALSE)  mod <- mirt(dat, 1, 'nominal')  # reproduce table 3 in Bock (1997) fs <- round(fscores(mod, verbose = FALSE, full.scores = FALSE)[,c('F1','SE_F1')],2) fttd <- residuals(mod, type = 'exp') table <- data.frame(fttd[,-ncol(fttd)], fs) table  mod <- mirt(dat, 1, 'nominal') coef(mod)   } # }"},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential item functioning statistics — DIF","title":"Differential item functioning statistics — DIF","text":"function runs Wald likelihood-ratio approaches testing differential item functioning (DIF) two groups. primarily convenience wrapper multipleGroup function performing standard DIF procedures. Independent models can estimated parallel defining parallel object mirtCluster, help decrease run time. best results, baseline model contain set 'anchor' items freely estimated hyper-parameters focal groups.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential item functioning statistics — DIF","text":"","code":"DIF(   MGmodel,   which.par,   scheme = \"add\",   items2test = 1:extract.mirt(MGmodel, \"nitems\"),   groups2test = \"all\",   seq_stat = \"SABIC\",   Wald = FALSE,   p.adjust = \"none\",   pairwise = FALSE,   return_models = FALSE,   return_seq_model = FALSE,   max_run = Inf,   plotdif = FALSE,   type = \"trace\",   simplify = TRUE,   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential item functioning statistics — DIF","text":"MGmodel object returned multipleGroup used reference model .par character vector containing parameter names inspected DIF scheme type DIF analysis perform, either adding dropping constraints across   groups. can : 'add' parameters .par constrained item one time     items specified items2test. beneficial examining DIF     model parameters freely estimated across groups, inspecting differences via     Wald test 'drop' parameters .par freely estimated items     specified items2test. useful supplying overly restrictive model     attempting detect DIF slightly less restrictive model 'add_sequential' sequentially loop items tested, end     loop treat DIF tests satisfy seq_stat criteria invariant. loop     re-run remaining invariant items determine now displaying DIF     less constrained model, new invariant item found algorithm stops     returns items displayed DIF. Note DIF statistics relative final,     less constrained model includes DIF effects 'drop_sequential' sequentially loop items tested, end     loop treat items violate seq_stat criteria demonstrating DIF. loop     re-run, leaving items previously demonstrated DIF variable across groups,     remaining test items previously showed invariance re-tested. algorithm     stops items showing DIF found returns items displayed DIF.     Note DIF statistics relative final,     less constrained model includes DIF effects items2test numeric vector, character vector containing item names, indicating items tested DIF. models anchor items known, omit vector. example, items 1 2 anchors 10 item test, items2test = 3:10 work testing remaining items (important remember using sequential schemes) groups2test character vector indicating groups use DIF testing investigations. Default '', uses group information perform joint hypothesis tests DIF (two group setup result pair-wise tests). example, group names 'g1', 'g2' 'g3', DIF investigated group 'g1' 'g3' pass groups2test = c('g1', 'g3') seq_stat select statistic test sequential schemes. Potential values (descending order power) 'AIC', 'SABIC', 'HQ', 'BIC'. numeric value input ranges 0 1, 'p' value tested (e.g., seq_stat = .05 test difference p < .05 add scheme, p > .05 drop scheme), along specified p.adjust input Wald logical; perform Wald tests DIF instead likelihood ratio test? p.adjust string passed p.adjust function adjust p-values. Adjustments located adj_p element returned list pairwise logical; perform pairwise tests groups number groups greater 2? Useful quickly specified post-hoc tests return_models logical; return estimated model objects analysis? Default FALSE return_seq_model logical; last iteration sequential schemes, return fitted multiple-group model containing freely estimated parameters indicative DIF? generally useful scheme = 'add_sequential'. Default FALSE max_run number indicating maximum number cycles perform sequential searches. default perform search DIF found plotdif logical; create item plots items displaying DIF according seq_stat criteria? available 'add' type schemes type type plot argument passed plot(). Default 'trace', though another good option 'infotrace'. ease viewing, facet_item argument mirt's plot() function set TRUE simplify logical; simplify output returning data.frame object differences AIC, BIC, etc, well chi-squared test (X2) associated df p-values verbose logical print extra information console? ... additional arguments passed multipleGroup plot","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential item functioning statistics — DIF","text":"mirt_df object information-based criteria DIF, though may changed   list output return_models simplify modified. well, silent   'DIF_coefficeints' attribute included view item parameter differences   groups","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Differential item functioning statistics — DIF","text":"Generally, pre-computed baseline model configured two estimation properties: 1) set 'anchor' items, anchor items various parameters constrained equal across groups, 2) contain freely estimated latent mean variance terms one group (-called 'reference' group). two properties help fix metric groups item parameter estimates contain latent distribution characteristics.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Differential item functioning statistics — DIF","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P., Counsell, ., Flora, D. B. (2016). might   make big DIF: Improved Differential Test Functioning statistics account   sampling variability. Educational Psychological Measurement, 76, 114-140.   doi:10.1177/0013164415584576","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Differential item functioning statistics — DIF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Differential item functioning statistics — DIF","text":"","code":"if (FALSE) { # \\dontrun{  # simulate data where group 2 has a smaller slopes and more extreme intercepts set.seed(12345) a1 <- a2 <- matrix(abs(rnorm(15,1,.3)), ncol=1) d1 <- d2 <- matrix(rnorm(15,0,.7),ncol=1) a2[1:2, ] <- a1[1:2, ]/3 d1[c(1,3), ] <- d2[c(1,3), ]/4 head(data.frame(a.group1 = a1, a.group2 = a2, d.group1 = d1, d.group2 = d2)) itemtype <- rep('2PL', nrow(a1)) N <- 1000 dataset1 <- simdata(a1, d1, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  #### no anchors, all items tested for DIF by adding item constrains one item at a time. # define a parallel cluster (optional) to help speed up internal functions if(interactive()) mirtCluster()  # Information matrix with Oakes' identity (not controlling for latent group differences) # NOTE: Without properly equating the groups the following example code is not testing for DIF,      # but instead reflects a combination of DIF + latent-trait distribution effects model <- multipleGroup(dat, 1, group, SE = TRUE)  # Likelihood-ratio test for DIF (as well as model information) dif <- DIF(model, c('a1', 'd')) dif  # function silently includes \"DIF_coefficients\" attribute to view # the IRT parameters post-completion extract.mirt(dif, \"DIF_coefficients\")  # same as above, but using Wald tests with Benjamini & Hochberg adjustment DIF(model, c('a1', 'd'), Wald = TRUE, p.adjust = 'fdr')  # equate the groups by assuming the last 5 items have no DIF itemnames <- colnames(dat) model <- multipleGroup(dat, 1, group, SE = TRUE,    invariance = c(itemnames[11:ncol(dat)], 'free_means', 'free_var'))  # test whether adding slopes and intercepts constraints results in DIF. Plot items showing DIF resulta1d <- DIF(model, c('a1', 'd'), plotdif = TRUE, items2test=1:10) resulta1d  # test whether adding only slope constraints results in DIF for all items DIF(model, 'a1', items2test=1:10)  # Determine whether it's a1 or d parameter causing DIF (could be joint, however) (a1s <- DIF(model, 'a1', items2test = 1:3)) (ds <- DIF(model, 'd', items2test = 1:3))  ### drop down approach (freely estimating parameters across groups) when ### specifying a highly constrained model with estimated latent parameters model_constrained <- multipleGroup(dat, 1, group,   invariance = c(colnames(dat), 'free_means', 'free_var')) dropdown <- DIF(model_constrained, c('a1', 'd'), scheme = 'drop') dropdown  # View silent \"DIF_coefficients\" attribute extract.mirt(dropdown, \"DIF_coefficients\")  ### sequential schemes (add constraints)  ### sequential searches using SABIC as the selection criteria # starting from completely different models stepup <- DIF(model, c('a1', 'd'), scheme = 'add_sequential',               items2test=1:10) stepup  # step down procedure for highly constrained model stepdown <- DIF(model_constrained, c('a1', 'd'), scheme = 'drop_sequential') stepdown  # view final MG model (only useful when scheme is 'add_sequential') updated_mod <- DIF(model, c('a1', 'd'), scheme = 'add_sequential',                return_seq_model=TRUE) plot(updated_mod, type='trace')   ################################### # Multi-group example  a1 <- a2 <- a3 <- matrix(abs(rnorm(15,1,.3)), ncol=1) d1 <- d2 <- d3 <- matrix(rnorm(15,0,.7),ncol=1) a2[1:2, ] <- a1[1:2, ]/3 d3[c(1,3), ] <- d2[c(1,3), ]/4 head(data.frame(a.group1 = a1, a.group2 = a2, a.group3 = a3,                 d.group1 = d1, d.group2 = d2, d.group3 = d3)) itemtype <- rep('2PL', nrow(a1)) N <- 1000 dataset1 <- simdata(a1, d1, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5)) dataset3 <- simdata(a3, d3, N, itemtype, mu = .2) dat <- rbind(dataset1, dataset2, dataset3) group <- gl(3, N, labels = c('g1', 'g2', 'g3'))  # equate the groups by assuming the last 5 items have no DIF itemnames <- colnames(dat) model <- multipleGroup(dat, group=group, SE=TRUE,    invariance = c(itemnames[11:ncol(dat)], 'free_means', 'free_var')) coef(model, simplify=TRUE)  # omnibus tests dif <- DIF(model, which.par = c('a1', 'd'), items2test=1:9) dif  # pairwise post-hoc tests for items flagged via omnibus tests dif.posthoc <- DIF(model, which.par = c('a1', 'd'), items2test=1:2,                    pairwise = TRUE) dif.posthoc  # further probing for df = 1 tests, this time with Wald tests DIF(model, which.par = c('a1'), items2test=1:2, pairwise = TRUE,     Wald=TRUE) DIF(model, which.par = c('d'), items2test=1:2, pairwise = TRUE,     Wald=TRUE)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential Response Functioning statistics — DRF","title":"Differential Response Functioning statistics — DRF","text":"Function performs various omnibus differential item (DIF), bundle (DBF), test (DTF) functioning procedures object estimated multipleGroup(). compensatory non-compensatory statistics provided described Chalmers (2018), generally can interpreted IRT generalizations SIBTEST CSIBTEST statistics. hypothesis tests, measures require ACOV matrix computed fitted multiple-group model (otherwise, sets plausible draws posterior explicitly required).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential Response Functioning statistics — DRF","text":"","code":"DRF(   mod,   draws = NULL,   focal_items = 1L:extract.mirt(mod, \"nitems\"),   param_set = NULL,   den.type = \"marginal\",   best_fitting = FALSE,   CI = 0.95,   npts = 1000,   quadpts = NULL,   theta_lim = c(-6, 6),   Theta_nodes = NULL,   plot = FALSE,   DIF = FALSE,   DIF.cats = FALSE,   groups2test = \"all\",   pairwise = FALSE,   simplify = TRUE,   p.adjust = \"none\",   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential Response Functioning statistics — DRF","text":"mod multipleGroup object estimated 2 groups draws number indicating many draws take form suitable multiple imputation bootstrap estimate expected test scores (100 ). boot = FALSE, requires estimated parameter information matrix. Returns list containing bootstrap/imputation distribution null hypothesis test sDRF statistics focal_items character/numeric vector indicating items include DRF tests. default uses items (note including anchors focal items effect exactly equal across groups). Selecting fewer items result tests 'differential bundle functioning' param_set N x p matrix parameter values drawn posterior (e.g., using parametric sampling approach, bootstrap, MCMC). supplied, used compute DRF measures. Can much efficient pre-compute values DIF, DBF, DTF evaluated within model (especially using bootstrap method). See draw_parameters den.type character specifying density latent traits computed. Default 'marginal' include proportional information groups, 'focal' just focal group, 'reference' reference group best_fitting logical; use best fitting parametric distribution (Gaussian default) used time model estimation? result much fast computations, however results dependent upon underlying modelling assumptions. Default FALSE, uses empirical histogram approach CI range confidence interval using draws input npts number points use plotting. Default 1000 quadpts number quadrature nodes use constructing DRF statistics. Default extracted input model object theta_lim lower upper limits latent trait (theta) evaluated, used conjunction quadpts npts Theta_nodes optional matrix Theta values evaluated draws sDRF statistics. However, values averaged across, instead give bootstrap confidence intervals respective Theta nodes. Useful following large sDRF uDRF statistic, example, determine difference test curves large (still accounting sampling variability). Returns matrix observed variability plot logical; plot 'sDRF' functions evaluated sDBF sDTF values across integration grid , DIF = TRUE, selected items faceted plot individual items? plausible parameter sets obtained/supplied imputed confidence intervals included DIF logical; return list item-level imputation properties using DRF statistics? can generally used DIF detection method graphical display understanding DIF within item DIF.cats logical; DIF = TRUE, however computations performed item category probability functions rather score functions. useful understanding DIF polytomous items groups2test 2 groups investigated two groups used effect size comparisons? pairwise logical; perform pairwise computations applying multi-group settings simplify logical; attempt simplify output rather returning larger lists? p.adjust string passed p.adjust function adjust p-values. Adjustments located adj_pvals element returned list. applicable DIF = TRUE par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice verbose logical; include additional information console? ... additional arguments passed lattice","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Differential Response Functioning statistics — DRF","text":"effect sizes estimates DRF function $$sDRF = \\int [S(C|\\bm{\\Psi}^{(R)},\\theta) S(C|\\bm{\\Psi}^{(F)},\\theta)] f(\\theta)d\\theta,$$ $$uDRF = \\int |S(C|\\bm{\\Psi}^{(R)},\\theta) S(C|\\bm{\\Psi}^{(F)},\\theta)| f(\\theta)d\\theta,$$ $$dDRF = \\sqrt{\\int [S(C|\\bm{\\Psi}^{(R)},\\theta) S(C|\\bm{\\Psi}^{(F)},\\theta)]^2 f(\\theta)d\\theta}$$ \\(S(.)\\) scoring equations used evaluate model-implied difference focal reference group. \\(f(\\theta)\\) terms can either estimated posterior via empirical histogram approach (default), can use best fitting prior distribution obtain post-convergence (default Guassian distribution). Note , comparison Chalmers (2018), focal group leftmost scoring function reference group rightmost scoring function. largely keep consistent similar effect size statistics, SIBTEST, DFIT, Wainer's measures impact, etc, general can seen special-case estimators family.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Differential Response Functioning statistics — DRF","text":"Chalmers, R. P. (2018). Model-Based Measures Detecting Quantifying Response Bias.   Psychometrika, 83(3), 696-732. doi:10.1007/s11336-018-9626-9","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Differential Response Functioning statistics — DRF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Differential Response Functioning statistics — DRF","text":"","code":"if (FALSE) { # \\dontrun{  set.seed(1234) n <- 30 N <- 500  # only first 5 items as anchors model <- 'F = 1-30           CONSTRAINB = (1-5, a1), (1-5, d)'  a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('Group_1', N), rep('Group_2', N))  ## ------------- # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N, itemtype = 'dich') dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var')) plot(mod) plot(mod, which.items = 6:10) #DBF plot(mod, type = 'itemscore') plot(mod, type = 'itemscore', which.items = 10:15)  # empirical histogram approach DRF(mod) DRF(mod, focal_items = 6:10) #DBF DRF(mod, DIF=TRUE) DRF(mod, DIF=TRUE, focal_items = 10:15)  # Best-fitting Gaussian distributions DRF(mod, best_fitting=TRUE) DRF(mod, focal_items = 6:10, best_fitting=TRUE) #DBF DRF(mod, DIF=TRUE, best_fitting=TRUE) DRF(mod, DIF=TRUE, focal_items = 10:15, best_fitting=TRUE)  DRF(mod, plot = TRUE) DRF(mod, focal_items = 6:10, plot = TRUE) #DBF DRF(mod, DIF=TRUE, plot = TRUE) DRF(mod, DIF=TRUE, focal_items = 10:15, plot = TRUE)  if(interactive()) mirtCluster() DRF(mod, draws = 500) DRF(mod, draws = 500, best_fitting=TRUE) DRF(mod, draws = 500, plot=TRUE)  # pre-draw parameter set to save computations #  (more useful when using non-parametric bootstrap) param_set <- draw_parameters(mod, draws = 500) DRF(mod, focal_items = 6, param_set=param_set) #DIF test DRF(mod, DIF=TRUE, param_set=param_set) #DIF test DRF(mod, focal_items = 6:10, param_set=param_set) #DBF test DRF(mod, param_set=param_set) #DTF test  DRF(mod, focal_items = 6:10, draws=500) #DBF test DRF(mod, focal_items = 10:15, draws=500) #DBF test  DIFs <- DRF(mod, draws = 500, DIF=TRUE) print(DIFs) DRF(mod, draws = 500, DIF=TRUE, plot=TRUE)  DIFs <- DRF(mod, draws = 500, DIF=TRUE, focal_items = 6:10) print(DIFs) DRF(mod, draws = 500, DIF=TRUE, focal_items = 6:10, plot = TRUE)  DRF(mod, DIF=TRUE, focal_items = 6) DRF(mod, draws=500, DIF=TRUE, focal_items = 6)  # evaluate specific values for sDRF Theta_nodes <- matrix(seq(-6,6,length.out = 100))  sDTF <- DRF(mod, Theta_nodes=Theta_nodes) head(sDTF) sDTF <- DRF(mod, Theta_nodes=Theta_nodes, draws=200) head(sDTF)  # sDIF (isolate single item) sDIF <- DRF(mod, Theta_nodes=Theta_nodes, focal_items=6) head(sDIF) sDIF <- DRF(mod, Theta_nodes=Theta_nodes, focal_items = 6, draws=200) head(sDIF)  ## ------------- ## random slopes and intercepts for 15 items, and latent mean difference ##    (no systematic DTF should exist, but DIF will be present) set.seed(1234) dat1 <- simdata(a, d, N, itemtype = 'dich', mu=.50, sigma=matrix(1.5)) dat2 <- simdata(a + c(numeric(15), rnorm(n-15, 0, .25)),                 d + c(numeric(15), rnorm(n-15, 0, .5)), N, itemtype = 'dich') dat <- rbind(dat1, dat2) mod1 <- multipleGroup(dat, 1, group=group) plot(mod1) DRF(mod1) #does not account for group differences! Need anchors  mod2 <- multipleGroup(dat, model, group=group, SE=TRUE,                       invariance=c('free_means', 'free_var')) plot(mod2)  # significant DIF in multiple items.... # DIF(mod2, which.par=c('a1', 'd'), items2test=16:30) DRF(mod2) DRF(mod2, draws=500) #non-sig DTF due to item cancellation  ## ------------- ## systematic differing slopes and intercepts (clear DTF) set.seed(1234) dat1 <- simdata(a, d, N, itemtype = 'dich', mu=.50, sigma=matrix(1.5)) dat2 <- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)),                 d + c(numeric(15), rnorm(n-15, 1, .5)),                 N, itemtype = 'dich') dat <- rbind(dat1, dat2) mod3 <- multipleGroup(dat, model, group=group, SE=TRUE,                       invariance=c('free_means', 'free_var')) plot(mod3) #visable DTF happening  # DIF(mod3, c('a1', 'd'), items2test=16:30) DRF(mod3) #unsigned bias. Signed bias (group 2 scores higher on average) DRF(mod3, draws=500) DRF(mod3, draws=500, plot=TRUE) #multiple DRF areas along Theta  # plot the DIF DRF(mod3, draws=500, DIF=TRUE, plot=TRUE)  # evaluate specific values for sDRF Theta_nodes <- matrix(seq(-6,6,length.out = 100)) sDTF <- DRF(mod3, Theta_nodes=Theta_nodes, draws=200) head(sDTF)  # DIF sDIF <- DRF(mod3, Theta_nodes=Theta_nodes, focal_items = 30, draws=200) car::some(sDIF)  ## ---------------------------------------------------------------- # polytomous example # simulate data where group 2 has a different slopes/intercepts set.seed(4321) a1 <- a2 <- matrix(rlnorm(20,.2,.3)) a2[c(16:17, 19:20),] <- a1[c(16:17, 19:20),] + c(-.5, -.25, .25, .5)  # for the graded model, ensure that there is enough space between the intercepts, # otherwise closer categories will not be selected often diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d1 <- d2 <- diffs + rnorm(20) rownames(d1) <- rownames(d2) <- paste0('Item.', 1:20) d2[16:20,] <- d1[16:20,] + matrix(c(-.5, -.5, -.5, -.5,                                     1, 0, 0, -1,                                     .5, .5, -.5, -.5,                                     1, .5, 0, -1,                                     .5, .5, .5, .5), byrow=TRUE, nrow=5)  tail(data.frame(a.group1 = a1, a.group2 = a2), 6) list(d.group1 = d1[15:20,], d.group2 = d2[15:20,])  itemtype <- rep('graded', nrow(a1)) N <- 600 dataset1 <- simdata(a1, d1, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype, mu = -.25, sigma = matrix(1.25)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  # item 1-10 as anchors mod <- multipleGroup(dat, group=group, SE=TRUE,                      invariance=c(colnames(dat)[1:10], 'free_means', 'free_var')) coef(mod, simplify=TRUE) plot(mod) plot(mod, type='itemscore')  # DIF tests vis Wald method DIF(mod, items2test=11:20,    which.par=c('a1', paste0('d', 1:4)),    Wald=TRUE, p.adjust='holm')  DRF(mod) DRF(mod, DIF=TRUE, focal_items=11:20) DRF(mod, DIF.cats=TRUE, focal_items=11:20)  ## ---------------------------------------------------------------- ### multidimensional DTF  set.seed(1234) n <- 50 N <- 1000  # only first 5 items as anchors within each dimension model <- 'F1 = 1-25           F2 = 26-50           COV = F1*F2           CONSTRAINB = (1-5, a1), (1-5, 26-30, d), (26-30, a2)'  a <- matrix(c(rep(1, 25), numeric(50), rep(1, 25)), n) d <- matrix(rnorm(n), n) group <- c(rep('Group_1', N), rep('Group_2', N)) Cov <- matrix(c(1, .5, .5, 1.5), 2) Mean <- c(0, 0.5)  # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich', sigma = cov2cor(Cov)) dat2 <- simdata(a, d, N, itemtype = 'dich', sigma = Cov, mu = Mean) dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var')) coef(mod, simplify=TRUE) plot(mod, degrees = c(45,45)) DRF(mod)  # some intercepts slightly higher in Group 2 d2 <- d d2[c(10:15, 31:35)] <- d2[c(10:15, 31:35)] + 1 dat1 <- simdata(a, d, N, itemtype = 'dich', sigma = cov2cor(Cov)) dat2 <- simdata(a, d2, N, itemtype = 'dich', sigma = Cov, mu = Mean) dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var')) coef(mod, simplify=TRUE) plot(mod, degrees = c(45,45))  DRF(mod) DRF(mod, draws = 500)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential test functioning statistics — DTF","title":"Differential test functioning statistics — DTF","text":"Function performs various omnibus differential test functioning procedures object estimated multipleGroup(). latent means/covariances suspected differ input object contain set 'anchor' items ensure differential test features detected rather group differences. Returns signed (average area ) unsigned (total area) statistics, descriptives percent average bias group total scores statistic. grid Theta values passed, can evaluated well determine specific DTF location effects.  best results, baseline model contain set 'anchor' items freely estimated hyper-parameters focal groups. See DIF details.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential test functioning statistics — DTF","text":"","code":"DTF(   mod,   draws = NULL,   CI = 0.95,   npts = 1000,   theta_lim = c(-6, 6),   Theta_nodes = NULL,   plot = \"none\",   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential test functioning statistics — DTF","text":"mod multipleGroup object estimated 2 groups draws number indicating many draws take form suitable multiple imputation estimate expected test scores (usually 100 ). Returns list containing imputation distribution null hypothesis test sDTF statistic CI range confidence interval using draws input npts number points use integration. Default 1000 theta_lim lower upper limits latent trait (theta) evaluated, used conjunction npts Theta_nodes optional matrix Theta values evaluated draws sDTF statistic. However, values averaged across, instead give bootstrap confidence intervals respective Theta nodes. Useful following large uDTF/sDTF statistic determine difference test curves large (still accounting sampling variability). Returns matrix observed variability plot character vector indicating plot draw. Possible values 'none', 'func' test score functions, 'sDTF' evaluated sDTF values across integration grid. plot drawn imputed confidence envelopes auto.key logical; automatically generate key lattice plot? ... additional arguments passed lattice boot","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Differential test functioning statistics — DTF","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P., Counsell, ., Flora, D. B. (2016). might   make big DIF: Improved Differential Test Functioning statistics account   sampling variability. Educational Psychological Measurement, 76, 114-140.   doi:10.1177/0013164415584576","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Differential test functioning statistics — DTF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Differential test functioning statistics — DTF","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1234) n <- 30 N <- 500  # only first 5 items as anchors model <- 'F = 1-30           CONSTRAINB = (1-5, a1), (1-5, d)'  a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('Group_1', N), rep('Group_2', N))  ## ------------- # groups completely equal dat1 <- simdata(a, d, N, itemtype = '2PL') dat2 <- simdata(a, d, N, itemtype = '2PL') dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var')) plot(mod)  DTF(mod) if(interactive()) mirtCluster() DTF(mod, draws = 1000) #95% C.I. for sDTF containing 0. uDTF is very small DTF(mod, draws = 1000, plot='sDTF') #sDTF 95% C.I.'s across Theta always include 0  ## ------------- ## random slopes and intercepts for 15 items, and latent mean difference ##    (no systematic DTF should exist, but DIF will be present) set.seed(1234) dat1 <- simdata(a, d, N, itemtype = '2PL', mu=.50, sigma=matrix(1.5)) dat2 <- simdata(a + c(numeric(15), runif(n-15, -.2, .2)),                 d + c(numeric(15), runif(n-15, -.5, .5)), N, itemtype = '2PL') dat <- rbind(dat1, dat2) mod1 <- multipleGroup(dat, 1, group=group) plot(mod1) #does not account for group differences! Need anchors  mod2 <- multipleGroup(dat, model, group=group, SE=TRUE,                       invariance=c('free_means', 'free_var')) plot(mod2)  # significant DIF in multiple items.... # DIF(mod2, which.par=c('a1', 'd'), items2test=16:30) DTF(mod2) DTF(mod2, draws=1000) #non-sig DTF due to item cancellation  ## ------------- ## systematic differing slopes and intercepts (clear DTF) dat1 <- simdata(a, d, N, itemtype = '2PL', mu=.50, sigma=matrix(1.5)) dat2 <- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)), d + c(numeric(15), rnorm(n-15, 1, .5)),                 N, itemtype = '2PL') dat <- rbind(dat1, dat2) mod3 <- multipleGroup(dat, model, group=group, SE=TRUE,                       invariance=c('free_means', 'free_var')) plot(mod3) #visable DTF happening  # DIF(mod3, c('a1', 'd'), items2test=16:30) DTF(mod3) #unsigned bias. Signed bias indicates group 2 scores generally higher on average DTF(mod3, draws=1000) DTF(mod3, draws=1000, plot='func') DTF(mod3, draws=1000, plot='sDTF') #multiple DTF areas along Theta  # evaluate specific values for sDTF Theta_nodes <- matrix(seq(-6,6,length.out = 100)) sDTF <- DTF(mod3, Theta_nodes=Theta_nodes) head(sDTF) sDTF <- DTF(mod3, Theta_nodes=Theta_nodes, draws=100) head(sDTF)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned mdirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"print signature(x = \"DiscreteClass\") show signature(object = \"DiscreteClass\") anova signature(object = \"DiscreteClass\") coef signature(x = \"DiscreteClass\") summary signature(object = \"DiscreteClass\") residuals signature(object = \"DiscreteClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT6.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of LSAT6 data — LSAT6","title":"Description of LSAT6 data — LSAT6","text":"Data Thissen (1982); contains 5 dichotomously scored items obtained Law School Admissions Test, section 6.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT6.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of LSAT6 data — LSAT6","text":"Thissen, D. (1982). Marginal maximum likelihood estimation one-parameter logistic model. Psychometrika, 47, 175-186.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT6.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of LSAT6 data — LSAT6","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT6.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of LSAT6 data — LSAT6","text":"","code":"if (FALSE) { # \\dontrun{ dat <- expand.table(LSAT6) head(dat) itemstats(dat)  model <- 'F = 1-5          CONSTRAIN = (1-5, a1)' (mod <- mirt(dat, model)) M2(mod) itemfit(mod) coef(mod, simplify=TRUE)  # equivalentely, but with a different parameterization mod2 <- mirt(dat, 1, itemtype = 'Rasch') anova(mod, mod2) #equal M2(mod2) itemfit(mod2) coef(mod2, simplify=TRUE) sqrt(coef(mod2)$GroupPars[2]) #latent SD equal to the slope in mod  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/LSAT7.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of LSAT7 data — LSAT7","title":"Description of LSAT7 data — LSAT7","text":"Data Bock & Lieberman (1970); contains 5 dichotomously scored items obtained Law School Admissions Test, section 7. Data ","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT7.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of LSAT7 data — LSAT7","text":"Bock, R. D., & Lieberman, M. (1970). Fitting response model n dichotomously scored items. Psychometrika, 35(2), 179-197. Bock, R. D., & Lieberman, M. (1970). Fitting response model n dichotomously scored items. Psychometrika, 35(2), 179-197.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT7.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of LSAT7 data — LSAT7","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT7.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of LSAT7 data — LSAT7","text":"","code":"if (FALSE) { # \\dontrun{ dat <- expand.table(LSAT7) head(dat) itemstats(dat)  (mod <- mirt(dat, 1)) coef(mod) } # }  if (FALSE) { # \\dontrun{ dat <- expand.table(LSAT7) head(dat) itemstats(dat)  (mod <- mirt(dat, 1)) coef(mod) } # }"},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the M2 model fit statistic — M2","title":"Compute the M2 model fit statistic — M2","text":"Computes M2 (Maydeu-Olivares & Joe, 2006) statistic data dichotomous, collapsed M2* statistic (collapsing univariate bivariate response categories; see Cai Hansen, 2013), hybrid C2 statistic collapses bivariate moments (Cai Monro, 2014). C2 variant mainly useful polytomous response models sufficient degrees freedom compute M2*. function also computes associated fit indices based fitting null model. Supports single multiple-group models. latent trait density approximated (e.g., Davidian curves, Empirical histograms, etc) passing use_dentype_estimate = TRUE use internally saved quadrature density components (applicable).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the M2 model fit statistic — M2","text":"","code":"M2(   obj,   type = \"M2*\",   calcNull = TRUE,   quadpts = NULL,   theta_lim = c(-6, 6),   CI = 0.9,   residmat = FALSE,   QMC = FALSE,   suppress = 1,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the M2 model fit statistic — M2","text":"obj estimated model object mirt package type type fit statistic compute. Options \"M2\", \"M2*\" univariate bivariate collapsed version M2 statistic (\"M2\" currently limited dichotomous response data ), \"C2\" hybrid M2 M2* bivariate moments collapsed calcNull logical; calculate statistics null model well? Allows statistics limited information TLI CFI. valid items suitable null model (e.g., created via createItem ) quadpts number quadrature points use estimation. NULL, suitable value chosen based rubric found fscores theta_lim lower upper range evaluate latent trait integral dimension CI numeric value 0 1 indicating range confidence interval RMSEA. Default returns 90% interval residmat logical; return residual matrix used compute SRMSR statistic? lower triangle residual correlation matrix returned (upper triangle filled NA's) QMC logical; use quasi-Monte Carlo integration? Useful higher dimensional models. quadpts specified, 5000 nodes used default suppress numeric value indicating parameter residual dependency combinations flag high. Absolute values standardized residuals greater value returned, values less value set NA. Must used conjunction argument residmat = TRUE ... additional arguments pass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the M2 model fit statistic — M2","text":"Returns data.frame object M2-type statistic, along degrees freedom,   p-value, RMSEA (90% confidence interval), SRMSR group,   optionally TLI CFI model fit statistics calcNull = TRUE.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the M2 model fit statistic — M2","text":"Cai, L. & Hansen, M. (2013). Limited-information goodness--fit testing hierarchical item factor models. British Journal Mathematical Statistical Psychology, 66, 245-276. Cai, L. & Monro, S. (2014). new statistic evaluating item response theory models ordinal data. National Center Research Evaluation, Standards, & Student Testing. Technical Report. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Maydeu-Olivares, . & Joe, H. (2006). Limited information goodness--fit testing multidimensional contingency tables. Psychometrika, 71, 713-732.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the M2 model fit statistic — M2","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the M2 model fit statistic — M2","text":"","code":"if (FALSE) { # \\dontrun{ dat <- as.matrix(expand.table(LSAT7)) (mod1 <- mirt(dat, 1)) M2(mod1) resids <- M2(mod1, residmat=TRUE) #lower triangle of residual correlation matrix resids summary(resids[lower.tri(resids)])  # M2 with missing data present dat[sample(1:prod(dim(dat)), 250)] <- NA mod2 <- mirt(dat, 1) M2(mod2)  # C2 statistic (useful when polytomous IRT models have too few df) pmod <- mirt(Science, 1) # This fails with too few df: # M2(pmod) # This, however, works: M2(pmod, type = 'C2')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute multidimensional difficulty index — MDIFF","title":"Compute multidimensional difficulty index — MDIFF","text":"Returns matrix containing MDIFF values (Reckase, 2009). supported items class 'dich' 'graded'.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute multidimensional difficulty index — MDIFF","text":"","code":"MDIFF(x, which.items = NULL, group = NULL)"},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute multidimensional difficulty index — MDIFF","text":"x object class 'SingleGroupClass', object class 'MultipleGroupClass' suitable group input supplied .items vector indicating items select. NULL used (default) MDISC computed items group group argument pass extract.group function. Required input object multiple-group model","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute multidimensional difficulty index — MDIFF","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Reckase, M. D. (2009). Multidimensional Item Response Theory. Springer.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute multidimensional difficulty index — MDIFF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute multidimensional difficulty index — MDIFF","text":"","code":"if (FALSE) { # \\dontrun{  mod <- mirt(Science, 2) MDIFF(mod)  mod <- mirt(expand.table(LSAT7), 2) MDIFF(mod)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute multidimensional discrimination index — MDISC","title":"Compute multidimensional discrimination index — MDISC","text":"Returns vector containing MDISC values item model input object (Reckase, 2009).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute multidimensional discrimination index — MDISC","text":"","code":"MDISC(x, group = NULL)"},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute multidimensional discrimination index — MDISC","text":"x object class 'SingleGroupClass', object class 'MultipleGroupClass' suitable group input supplied group group argument pass extract.group function. Required input object multiple-group model","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute multidimensional discrimination index — MDISC","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Reckase, M. D. (2009). Multidimensional Item Response Theory. Springer.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute multidimensional discrimination index — MDISC","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute multidimensional discrimination index — MDISC","text":"","code":"if (FALSE) { # \\dontrun{  mod <- mirt(Science, 2) MDISC(mod)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned mixedmirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"coef signature(object = \"MixedClass\") print signature(x = \"MixedClass\") residuals signature(object = \"MixedClass\") show signature(object = \"MixedClass\") summary signature(object = \"MixedClass\") logLik signature(object = \"MixedClass\") anova signature(object = \"MixedClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned multipleGroup estimated mixture distributions.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"coef signature(object = \"MixtureClass\") print signature(x = \"MixtureClass\") show signature(object = \"MixtureClass\") anova signature(object = \"MixtureClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned multipleGroup.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"coef signature(object = \"MultipleGroupClass\") print signature(x = \"MultipleGroupClass\") show signature(object = \"MultipleGroupClass\") anova signature(object = \"MultipleGroupClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"Computes profiled-likelihood based confidence intervals. Supports inclusion equality constraints. Object returns confidence intervals whether respective interval found.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"","code":"PLCI.mirt(   mod,   parnum = NULL,   alpha = 0.05,   search_bound = TRUE,   step = 0.5,   lower = TRUE,   upper = TRUE,   inf2val = 30,   NealeMiller = FALSE,   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"mod converged mirt model parnum numeric vector indicating parameters estimate. Use mod2values determine parameter numbers. NULL, possible parameters used alpha two-tailed alpha critical level search_bound logical; use fixed grid values around ML estimate determine suitable optimization bounds? Using much better behaviour setting fixed upper/lower bound values searching extreme ends step magnitude steps used search_bound TRUE. Smaller values create points search suitable bound (lower bound value visible mod2values). upper/lower bounds detected value adjusted accordingly lower logical; search lower CI? upper logical; search upper CI? inf2val numeric used change parameter bounds infinity finite number. Decreasing much may allow suitable bound located. Default 30 NealeMiller logical; use Neale Miller 1997 approximation? Default FALSE verbose logical; include additional information console? ... additional arguments pass estimation functions","code":""},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P., Pek, J., & Liu, Y. (2017). Profile-likelihood Confidence Intervals Item Response Theory Models. Multivariate Behavioral Research, 52, 533-550. doi:10.1080/00273171.2017.1329082 Neale, M. C. & Miller, M. B. (1997). use likelihood-based confidence intervals genetic models. Behavior Genetics, 27, 113-120.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"","code":"if (FALSE) { # \\dontrun{ if(interactive()) mirtCluster() #use all available cores to estimate CI's in parallel dat <- expand.table(LSAT7) mod <- mirt(dat, 1)  result <- PLCI.mirt(mod) result  # model with constraints mod <- mirt(dat, 'F = 1-5                   CONSTRAIN = (1-5, a1)')  result <- PLCI.mirt(mod) result  mod2 <- mirt(Science, 1) result2 <- PLCI.mirt(mod2) result2  # only estimate CI's slopes sv <- mod2values(mod2) parnum <- sv$parnum[sv$name == 'a1'] result3 <- PLCI.mirt(mod2, parnum) result3  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-based Reliable Change Index — RCI","title":"Model-based Reliable Change Index — RCI","text":"Computes IRT version \"reliable change index\" (RCI) proposed Jacobson Traux (1991) modified use IRT information scores measurement error (see Jabrayilov, Emons, Sijtsma (2016). Main benefit IRT approach inclusion response pattern information pre/post data score estimates, well conditional standard error measurement information.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-based Reliable Change Index — RCI","text":"","code":"RCI(   mod_pre,   predat,   postdat,   mod_post = mod_pre,   cutoffs = NULL,   SEM.pre = NULL,   SEM.post = NULL,   Fisher = FALSE,   shiny = FALSE,   main = \"Test Scores\",   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-based Reliable Change Index — RCI","text":"mod_pre single-group model fitted mirt. supplied information extracted data input objects compute classical test theory version RCI statistics predat vector (one individual) matrix/data.frame response data scored, individuals' responses included exactly one row postdat predat, respect post/follow-measurement mod_post (optional) IRT model post-test different pre-test; otherwise, pre-test model used cutoffs optional vector length 2 indicating type cut-offs report (e.g., c(-1.96, 1.96) reflects 95 percent z-score type cut-) SEM.pre standard error measurement pretest. can used instead rxx.pre SD.pre SEM.post (optional) standard error measurement post-test. Using create pooled version SEM; otherwise, SEM.post = SEM.pre Fisher logical; use Fisher/expected information function compute SE terms? FALSE SE information extracted select fscores method (default). applicable unidimensional models shiny logical; launch interactive shiny applications real-time scoring supplied total-scores response vectors? requires mod_pre (optional) mod_post inputs main main label use shiny=TRUE ... additional arguments passed fscores","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model-based Reliable Change Index — RCI","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Jacobson, N. S., & Truax, P. (1991). Clinical significance: statistical approach defining meaningful change psychotherapy research. Journal Consulting Clinical Psychology, 59, 12-19. Jabrayilov, R. , Emons, W. H. M., & Sijtsma, K. (2016). Comparison Classical Test Theory Item Response Theory Individual Change Assessment. Applied Psychological Measurement, 40 (8), 559-572.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model-based Reliable Change Index — RCI","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-based Reliable Change Index — RCI","text":"","code":"if (FALSE) { # \\dontrun{  # simulate some data N <- 1000 J <- 20     # number of items a <- matrix(rlnorm(J,.2,.3)) d <- rnorm(J)  theta <- matrix(rnorm(N)) dat_pre <- simdata(a, d, itemtype = '2PL', Theta = theta)  # first 3 cases decrease by 1/2 theta2 <- theta - c(1/2, 1/2, 1/2, numeric(N-3)) dat_post <- simdata(a, d, itemtype = '2PL', Theta = theta2)  mod <- mirt(dat_pre)  # all changes using fitted model from pre data RCI(mod, predat=dat_pre, postdat=dat_post)  # single response pattern change using EAP information RCI(mod, predat=dat_pre[1,], postdat=dat_post[1,])  # WLE estimator with Fisher information for SE (see Jabrayilov et al. 2016) RCI(mod, predat = dat_pre[1,], postdat = dat_post[1,],     method = 'WLE', Fisher = TRUE)  # multiple respondents RCI(mod, predat = dat_pre[1:6,], postdat = dat_post[1:6,])  # include large-sample z-type cutoffs RCI(mod, predat = dat_pre[1:6,], postdat = dat_post[1:6,],     cutoffs = c(-1.96, 1.96))  ###### # CTT version by omitting IRT model     # Requires either sample or population SEM's as input (istats <- itemstats(dat_pre)$overall) SEM.alpha <- istats$SEM.alpha    # SEM estimate of dat_pre  # assumes SEM.post = SEM.pre RCI(predat = dat_pre, postdat = dat_post, SEM.pre=SEM.alpha)  # include cutoffs RCI(predat = dat_pre, postdat = dat_post, SEM.pre=SEM.alpha,     cutoffs=c(-1.96, 1.96))  # allows SEM.post != SEM.pre (istats.post <- itemstats(dat_post)$overall) SEM.alpha.post <- istats.post$SEM.alpha  RCI(predat = dat_pre, postdat = dat_post,    SEM.pre=SEM.alpha, SEM.post=SEM.alpha.post)  ######  # interactive shiny interfaces for live scoring mod_pre <- mirt(Science)  # (optional) setup mod_post to have medium effect size change (d = 0.5) sv <- mod2values(mod_pre) sv$value[sv$name == 'MEAN_1'] <- 0.5 mod_post <- mirt(Science, pars=sv, TOL=NA)  # only use pre-test model for scoring if(interactive()){     RCI(mod_pre=mod_pre, shiny=TRUE)      # use both pre-test and post-test models for including empirical priors     RCI(mod_pre=mod_pre, mod_post=mod_post, shiny=TRUE,         main='Perceptions of Science and Technology')  }   ############################ # Example where individuals take completely different item set pre-post #   but prior calibration has been performed to equate the items  dat <- key2binary(SAT12,   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  mod <- mirt(dat)  # with N=5 individuals under investigation predat <- postdat <- dat[1:5,] predat[, 17:32] <- NA postdat[, 1:16] <- NA  head(predat) head(postdat)  RCI(mod, predat, postdat)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":null,"dir":"Reference","previous_headings":"","what":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"function computes set RMSD \"badness--fit\" statistics investing DIF across set grouping variables. first step, (potentially highly constrained) multiple group model fitted, second step item (person) parameters estimated based examines across groups. Category level DIF assessed based well pseudo-table counts match (constrained) probability functions implied original multiple group model (also weighing across implied density function latent traits). RSMD fit poor, indicating non-ignorable DIF, multiple-group model adjusted better account large response bias due using pooled model. See Lee von Davier (2020) Buchholz Hartig (2019) details.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"","code":"RMSD_DIF(pooled_mod, flag = 0, probfun = TRUE, dentype = \"norm\")"},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"pooled_mod multiple-group model (used compute model-implied probability goodness--fit test) flag numeric value used cut-help flag larger RMSD values (e.g., flag = .03 highlight categories RMSD values greater .03) probfun logical; use probability functions compute RMSD? FALSE, expected score functions integrated instead, may useful collapsing across categories polytomous items dentype density use latent trait. Can 'norm' use normal Gaussian density mean/variance extracted model object(default), 'snorm' standard normal distribution, 'empirical' use density estimate obtained via E-table","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"Buchholz, J., Hartig, J. (2019). Comparing Attitudes Across Groups: IRT-Based Item-Fit Statistic   Analysis Measurement Invariance. Applied Psychological Measurement, 43(3), 241-250.   doi:10.1177/0146621617748323 Lee, S. S., von Davier, M. (2020). Improving measurement properties PISA home   possessions scale partial invariance modeling.   Psychological test assessment modeling, 62(1):55-83.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"","code":"if (FALSE) { # \\dontrun{  #----- generate some data set.seed(12345) a <- a2 <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- d2 <- matrix(rnorm(15,0,.7),ncol=1)  # item 1 has DIF d2[1] <- d[1] - .5 a2[1] <- a[1] + 1  itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  #-----  # fully pooled model pooled_mod <- multipleGroup(dat, 1, group=group,    invariance = c(colnames(dat), 'free_mean', 'free_var')) coef(pooled_mod, simplify=TRUE)  RMSD_DIF(pooled_mod) RMSD_DIF(pooled_mod, dentype = 'empirical') RMSD_DIF(pooled_mod, flag = .03)  # more freely estimated model (item 1 has 2 parameters estimated) MGmod <- multipleGroup(dat, 1, group=group,                        invariance = c(colnames(dat)[-1], 'free_mean', 'free_var')) coef(MGmod, simplify=TRUE)  # RMSD in item.1 now reduced (MG model accounts for DIF) RMSD_DIF(MGmod) RMSD_DIF(MGmod, flag = .03)  ################# # NA placeholders included when groups do not respond to specific items  a1 <- a2 <- rlnorm(20) d <- d2 <- rnorm(20) # item 5 contains DIF a2[5] <- a1[5] + 1 d2[5] <- d[5] - 1/2 g <- rbeta(20, 5, 17)  dat1 <- simdata(a1, d, guess = g, N=1000, itemtype = '3PL') dat1[, 11:13] <- NA  # items 11:13 items NA for g1 dat2 <- simdata(a2, d2, guess = g, N=1000, itemtype = '3PL',    mu=1/4, sigma=matrix(.75)) dat2[,1:3] <- NA # items 1:3 items NA for g2 dat <- rbind(dat1, dat2) group <- c(rep('g1', 1000), rep('g2', 1000))  mod <- multipleGroup(dat, \"Theta = 1-20                             PRIOR = (1-20, g, norm, -1, 0.5)\",                      group=group, itemtype='3PL',                      invariance = c(colnames(dat), 'free_mean', 'free_var')) coef(mod, simplify = TRUE)  RMSD_DIF(mod) RMSD_DIF(mod, flag = .03)  ################# # polytomous example set.seed(12345) a <- a2 <- matrix(rlnorm(20,.2,.3))  # for the graded model, ensure that there is enough space between the intercepts, # otherwise closer categories will not be selected often (minimum distance of 0.3 here) diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d <- d2 <- diffs + rnorm(20)  # item 1 has slope + dif for first intercept parameter d2[1] <- d[1] - .5 a2[1] <- a[1] + 1  itemtype <- rep('graded', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  #-----  # fully pooled model pooled_mod <- multipleGroup(dat, 1, group=group,          invariance = c(colnames(dat), 'free_mean', 'free_var')) coef(pooled_mod, simplify=TRUE)  # Item_1 fits poorly in several categories (RMSD > .05) RMSD_DIF(pooled_mod) RMSD_DIF(pooled_mod, flag = .05) RMSD_DIF(pooled_mod, flag = .1, probfun = FALSE) # use expected score function  # more freely estimated model (item 1 has more parameters estimated) MGmod <- multipleGroup(dat, 1, group=group,                        invariance = c(colnames(dat)[-1], 'free_mean', 'free_var')) coef(MGmod, simplify=TRUE)  # RMSDs in Item_1 now reduced (MG model better accounts for DIF) RMSD_DIF(MGmod) RMSD_DIF(MGmod, flag = .05) RMSD_DIF(MGmod, probfun = FALSE, flag = .1) # use expected score function  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/SAT12.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of SAT12 data — SAT12","title":"Description of SAT12 data — SAT12","text":"Data obtained TESTFACT (Woods et al., 2003) manual, 32 response pattern scored items grade 12 science assessment test (SAT) measuring topics chemistry, biology, physics. scoring key data [1, 4, 5, 2, 3, 1, 2, 1, 3, 1, 2, 4, 2, 1, 5, 3, 4, 4, 1, 4, 3, 3, 4, 1, 3, 5, 1, 3, 1, 5, 4, 5], respectively. However, careful analysis using nominal response model suggests scoring key item 32 may incorrect, changed 5 3.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SAT12.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of SAT12 data — SAT12","text":"Wood, R., Wilson, D. T., Gibbons, R. D., Schilling, S. G., Muraki, E., & Bock, R. D. (2003). TESTFACT 4 Windows: Test Scoring, Item Statistics, Full-information Item Factor Analysis [Computer software]. Lincolnwood, IL: Scientific Software International.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SAT12.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of SAT12 data — SAT12","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SAT12.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of SAT12 data — SAT12","text":"","code":"if (FALSE) { # \\dontrun{  itemstats(SAT12, use_ts = FALSE)  # score the data (missing scored as 0) head(SAT12) dat <- key2binary(SAT12,     key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) head(dat) itemstats(dat)  # score the data, missing (value of 8) treated as NA SAT12missing <- SAT12 SAT12missing[SAT12missing == 8] <- NA dat <- key2binary(SAT12missing,     key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) head(dat)  # potentially better scoring for item 32 (based on nominal model finding) dat <- key2binary(SAT12,     key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,3)) } # }"},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":null,"dir":"Reference","previous_headings":"","what":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"Classical test theory approach detecting unidirectional bidirectional (one crossing location) DIF. family statistics intended unidimensional tests, applies regression-corrected matched-total score approach quantify response bias two groups. Can used DIF, DBF, DTF testing two discrete groups.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"","code":"SIBTEST(   dat,   group,   suspect_set,   match_set,   focal_name = unique(group)[2],   guess_correction = 0,   Jmin = 5,   na.rm = FALSE,   randomize = FALSE,   C = cbind(1, -diag(length(unique(group)) - 1L)),   pairwise = FALSE,   DIF = FALSE,   p.adjust.method = \"none\",   permute = 1000,   pk_focal = FALSE,   correction = TRUE,   remove_cross = FALSE,   details = FALSE,   plot = \"none\",   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"dat integer-based dataset tested, containing dichotomous polytomous responses group (factor) vector indicating group membership length number rows dat suspect_set integer vector indicating items inspect SIBTEST. Including one value perform DIF test, including one perform simultaneous bundle test (DBF); including non-matched items perform DTF. missing, simultaneous test using items listed match_set used (.e., DTF) match_set integer vector indicating items use items matched (.e., contain DIF). analogous 'anchor' items likelihood method locate DIF. missing, items items found suspect_set used focal_name name focal group; e.g., 'focal'. specified one selected automatically using unique(group)[2] guess_correction vector numbers 0 1 indicating much correct items guessing. length ncol(dat) Jmin minimum number observations required splitting data focal reference groups conditioned matched set na.rm logical; remove rows dat missing values? TRUE, rows missing data removed, well corresponding elements group input randomize logical; perform crossing test non-compensatory bias using Li Stout's (1996) permutation approach? Default FALSE, uses ad-hoc mixed degrees freedom method suggested Chalmers (2018) C contrast matrix use pooled testing two groups. Default uses effects coding approach, last group (last column matrix) treated reference group, column associated respective name via unique(group) (.e., first column coefficient unique(group)[1], second column unique(group)[2], ) pairwise logical; perform pairwise comparisons multi-group applications? DIF logical; elements suspect_set treated one time test DIF? Use logical treat items part match_set unless input provided explicitly. Default FALSE allow DBF DTF tests p.adjust.method character input dictating method use p.adjust. studying two groups. Default present p-value adjustments permute number permutations perform randomize = TRUE. Default 1000 pk_focal logical; using group weights focal group instead total sample? Default FALSE per Shealy Stout's recommendation correction logical; apply composite correction difference focal composite scores using true-score regression technique? Default TRUE, reflecting Shealy Stout's linear extrapolation method remove_cross logical; remove subtest information associated approximate crossing location? TRUE reflects CSIBTEST definition Li Stout (1996); FALSE, reflects version CSIBTEST utilized Chalmers (2018). applicable two-group settings (multi-group fixed FALSE) details logical; return data.frame containing details required compute SIBTEST? plot character input indicating type plot construct. Options 'none' (default), 'observed' scaled focal subtest scores matched subtest scores, 'weights' proportion weights used (.e., proportion observations matched score), 'difference' difference scaled focal subtest scores matched subtest scores, 'wdifference' conditional differences multiplied respective weight. Note last plot reflects components used SIBTEST, therefore sum plotted observations equal beta coefficient SIBTEST ... additional plotting arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"SIBTEST similar Mantel-Haenszel approach detecting DIF uses regression correction based KR-20/coefficient alpha reliability index correct observed differences latent trait distributions equal. Function supports standard SIBTEST dichotomous polytomous data (compensatory) supports crossing DIF testing (.e., non-compensatory/non-uniform) using asymptotic sampling distribution version Crossing-SIBTEST (CSIBTEST) statistic described Chalmers (2018) permutation method described Li Stout (1996). function also supports multi-group generalizations (GSIBTEST GCSIBTEST) proposed Chalmers Zheng (2023), users may specify alternative contrast matrices evaluate specific comparisons groups well perform joint hypothesis tests.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"Chalmers, R. P. (2018). Improving Crossing-SIBTEST statistic detecting non-uniform DIF. Psychometrika, 83, 2, 376-386. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. & Zheng, G. (2023). Multi-group Generalizations SIBTEST Crossing-SIBTEST. Applied Measurement Education, 36(2), 171-191, doi:10.1080/08957347.2023.2201703 . Chang, H. H., Mazzeo, J. & Roussos, L. (1996). DIF Polytomously Scored Items: Adaptation   SIBTEST Procedure. Journal Educational Measurement, 33, 333-353. Li, H.-H. & Stout, W. (1996). new procedure detection crossing DIF. Psychometrika, 61, 647-677. Shealy, R. & Stout, W. (1993). model-based standardization approach separates true   bias/DIF group ability differences detect test bias/DTF well item bias/DIF.   Psychometrika, 58, 159-194.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"","code":"if (FALSE) { # \\dontrun{  set.seed(1234) n <- 30 N <- 500 a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('reference', N), rep('focal', N*2))  ## ------------- # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N*2, itemtype = 'dich') dat <- rbind(dat1, dat2)  # DIF (all other items as anchors) SIBTEST(dat, group, suspect_set = 6)  # Some plots depicting the above tests SIBTEST(dat, group, suspect_set = 6, plot = 'observed') SIBTEST(dat, group, suspect_set = 6, plot = 'weights') SIBTEST(dat, group, suspect_set = 6, plot = 'wdifference')  # Include CSIBTEST with randomization method SIBTEST(dat, group, suspect_set = 6, randomize = TRUE)  # remove crossing-location (identical to Li and Stout 1996 definition of CSIBTEST) SIBTEST(dat, group, suspect_set = 6, randomize = TRUE, remove_cross=TRUE)  # DIF (specific anchors) SIBTEST(dat, group, match_set = 1:5, suspect_set = 6) SIBTEST(dat, group, match_set = 1:5, suspect_set = 6, randomize=TRUE)  # DBF (all and specific anchors, respectively) SIBTEST(dat, group, suspect_set = 11:30) SIBTEST(dat, group, match_set = 1:5, suspect_set = 11:30)  # DTF SIBTEST(dat, group, suspect_set = 11:30) SIBTEST(dat, group, match_set = 1:10) #equivalent  # different hyper pars dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N*2, itemtype = 'dich', mu = .5, sigma = matrix(1.5)) dat <- rbind(dat1, dat2) SIBTEST(dat, group, 6:30) SIBTEST(dat, group, 11:30)  # DIF testing with anchors 1 through 5 SIBTEST(dat, group, 6, match_set = 1:5) SIBTEST(dat, group, 7, match_set = 1:5) SIBTEST(dat, group, 8, match_set = 1:5)  # DIF testing with all other items as anchors SIBTEST(dat, group, 6) SIBTEST(dat, group, 7) SIBTEST(dat, group, 8)  ## ------------- ## systematic differing slopes and intercepts (clear DTF) dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)), d + c(numeric(15), rnorm(n-15, 1, 1)),   N*2, itemtype = 'dich') dat <- rbind(dat1, dat2) SIBTEST(dat, group, 6:30) SIBTEST(dat, group, 11:30)  # Some plots depicting the above tests SIBTEST(dat, group, suspect_set = 11:30, plot = 'observed') SIBTEST(dat, group, suspect_set = 11:30, plot = 'weights') SIBTEST(dat, group, suspect_set = 11:30, plot = 'wdifference')  # DIF testing using valid anchors SIBTEST(dat, group, suspect_set = 6, match_set = 1:5) SIBTEST(dat, group, suspect_set = 7, match_set = 1:5) SIBTEST(dat, group, suspect_set = 30, match_set = 1:5)  # test DIF using specific match_set SIBTEST(dat, group, suspect_set = 6:30, match_set = 1:5, DIF=TRUE)  # test DIF using all-other-as-anchors method (not typically recommended) SIBTEST(dat, group, suspect_set = 1:30, DIF=TRUE)  # randomization method is fairly poor when smaller matched-set used SIBTEST(dat, group, suspect_set = 30, match_set = 1:5, randomize=TRUE) SIBTEST(dat, group, suspect_set = 30, randomize=TRUE)  ## ---------------------------------- # three group SIBTEST test set.seed(1234) n <- 30 N <- 1000 a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('group1', N), rep('group2', N), rep('group3', N))  # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N, itemtype = 'dich') dat3 <- simdata(a, d, N, itemtype = 'dich') dat <- rbind(dat1, dat2, dat3)  # omnibus test using effects-coding contrast matrix (default) SIBTEST(dat, group, suspect_set = 6) SIBTEST(dat, group, suspect_set = 6, randomize=TRUE)  # explicit contrasts SIBTEST(dat, group, suspect_set = 6, randomize=TRUE,         C = matrix(c(1,-1,0), 1))  # test all items for DIF SIBTEST(dat, group, suspect_set = 1:ncol(dat), DIF=TRUE) SIBTEST(dat, group, suspect_set = 16:ncol(dat), DIF=TRUE,         match_set = 1:15) # specific anchors  # post-hoc between two groups only pick <- group %in% c('group1', 'group2') SIBTEST(subset(dat, pick), group[pick], suspect_set = 1:ncol(dat), DIF=TRUE)  # post-hoc pairwise comparison for all groups SIBTEST(dat, group, suspect_set = 1:ncol(dat), DIF=TRUE, pairwise = TRUE)  ## systematic differing slopes and intercepts dat2 <- simdata(a + c(numeric(15), .5,.5,.5,.5,.5, numeric(10)),         d + c(numeric(15), 0,.6,.7,.8,.9, numeric(10)),         N, itemtype = 'dich') dat <- rbind(dat1, dat2, dat3)  SIBTEST(dat, group, suspect_set = 16) SIBTEST(dat, group, suspect_set = 16, randomize=TRUE)  SIBTEST(dat, group, suspect_set = 19) SIBTEST(dat, group, suspect_set = 19, randomize=TRUE)  SIBTEST(dat, group, suspect_set = c(16, 19), DIF=TRUE) SIBTEST(dat, group, suspect_set = c(16, 19), DIF=TRUE, pairwise=TRUE)   } # }"},{"path":"https://philchalmers.github.io/mirt/reference/SLF.html","id":null,"dir":"Reference","previous_headings":"","what":"Social Life Feelings Data — SLF","title":"Social Life Feelings Data — SLF","text":"5-item data set analyzed Bartholomew (1998). Data contains dichotomous responses (endorsement vs non-endorsement) 1490 German respondents five statements perceptions social life.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SLF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Social Life Feelings Data — SLF","text":"Bartholomew, D., J. (1998). Scaling unobservable constructs social science. Journal Royal Statistical Society - Series C, 47, 1-13.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SLF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Social Life Feelings Data — SLF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SLF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Social Life Feelings Data — SLF","text":"","code":"if (FALSE) { # \\dontrun{ # tabular format data(SLF) SLF  # full dataset full <- expand.table(SLF) itemstats(full)  mod <- mirt(full) plot(mod, type = 'trace')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/Science.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of Science data — Science","title":"Description of Science data — Science","text":"4-item data set borrowed ltm package R, first example grm() function. See complete documentation therein, well Karlheinz Melich (1992).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Science.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of Science data — Science","text":"Karlheinz, R. Melich, . (1992). Euro-Barometer 38.1: Consumer Protection Perceptions Science Technology. INRA (Europe), Brussels. [computer file]","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Science.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of Science data — Science","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Science.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of Science data — Science","text":"","code":"if (FALSE) { # \\dontrun{ itemstats(Science)  mod <- mirt(Science, 1) plot(mod, type = 'trace') } # }"},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned mirt model exploratory.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"anova signature(object = \"SingleGroupClass\") coef signature(object = \"SingleGroupClass\") plot signature(x = \"SingleGroupClass\", y = \"missing\") print signature(x = \"SingleGroupClass\") residuals signature(object = \"SingleGroupClass\") show signature(object = \"SingleGroupClass\") summary signature(object = \"SingleGroupClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare nested models with likelihood-based statistics — anova-method","title":"Compare nested models with likelihood-based statistics — anova-method","text":"Compare nested models using likelihood ratio test (X2), Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), Sample-Size Adjusted BIC (SABIC), Hannan-Quinn (HQ) Criterion. given sequence objects, anova tests models one another order specified. Note object inputs ordered terms constrained model least constrained.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare nested models with likelihood-based statistics — anova-method","text":"","code":"# S4 method for class 'SingleGroupClass' anova(   object,   object2,   ...,   bounded = FALSE,   mix = 0.5,   frame = 1,   verbose = FALSE )"},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare nested models with likelihood-based statistics — anova-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass, reflecting constrained model fitted object2 second model estimated mirt package estimation methods ... additional less constrained model objects compared sequentially previous model bounded logical; two models comparing bounded parameter (e.g., comparing single 2PL 3PL model 1 df)? TRUE 50:50 mix chi-squared distributions used obtain p-value mix proportion chi-squared mixtures. Default 0.5 frame (internal parameter standard use) verbose (deprecated argument)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare nested models with likelihood-based statistics — anova-method","text":"data.frame/mirt_df object","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compare nested models with likelihood-based statistics — anova-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare nested models with likelihood-based statistics — anova-method","text":"","code":"if (FALSE) { # \\dontrun{ x <- mirt(Science, 1) x2 <- mirt(Science, 2) anova(x, x2)  # compare three models sequentially (X2 not always meaningful) x3 <- mirt(Science, 1, 'gpcm') x4 <- mirt(Science, 1, 'nominal') anova(x, x2, x3, x4)  # in isolation anova(x)  # with priors on first model model <- \"Theta = 1-4           PRIOR = (1-4, a1, lnorm, 0, 10)\" xp <- mirt(Science, model) anova(xp, x2) anova(xp)  # bounded parameter dat <- expand.table(LSAT7) mod <- mirt(dat, 1) mod2 <- mirt(dat, 1, itemtype = c(rep('2PL', 4), '3PL')) anova(mod, mod2) #unbounded test anova(mod, mod2, bounded = TRUE) #bounded  # priors model <- 'F = 1-5           PRIOR = (5, g, norm, -1, 1)' mod1b <- mirt(dat, model, itemtype = c(rep('2PL', 4), '3PL')) anova(mod1b)  model2 <- 'F = 1-5           PRIOR = (1-5, g, norm, -1, 1)' mod2b <- mirt(dat, model2, itemtype = '3PL') anova(mod1b, mod2b)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate the area under a selection of information curves — areainfo","title":"Function to calculate the area under a selection of information curves — areainfo","text":"Compute area test item information function definite integral range.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate the area under a selection of information curves — areainfo","text":"","code":"areainfo(   x,   theta_lim,   which.items = 1:extract.mirt(x, \"nitems\"),   group = NULL,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate the area under a selection of information curves — areainfo","text":"x object class 'SingleGroupClass', object class 'MultipleGroupClass' suitable group input supplied theta_lim range integration computed .items integer vector indicating items include expected information function. Default uses possible items group group argument pass extract.group function. Required input object multiple-group model ... additional arguments passed integrate","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to calculate the area under a selection of information curves — areainfo","text":"data.frame lower upper integration range, information area   within range (Info), information area range -10 10 (Total.Info), proportion   total information given integration range (Info.Proportion), number items included (nitems)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate the area under a selection of information curves — areainfo","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate the area under a selection of information curves — areainfo","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate the area under a selection of information curves — areainfo","text":"","code":"dat <- expand.table(LSAT7) mod <- mirt(dat, 1) #>  Iteration: 1, Log-Lik: -2668.786, Max-Change: 0.18243 Iteration: 2, Log-Lik: -2663.691, Max-Change: 0.13637 Iteration: 3, Log-Lik: -2661.454, Max-Change: 0.10231 Iteration: 4, Log-Lik: -2659.430, Max-Change: 0.04181 Iteration: 5, Log-Lik: -2659.241, Max-Change: 0.03417 Iteration: 6, Log-Lik: -2659.113, Max-Change: 0.02911 Iteration: 7, Log-Lik: -2658.812, Max-Change: 0.00456 Iteration: 8, Log-Lik: -2658.809, Max-Change: 0.00363 Iteration: 9, Log-Lik: -2658.808, Max-Change: 0.00273 Iteration: 10, Log-Lik: -2658.806, Max-Change: 0.00144 Iteration: 11, Log-Lik: -2658.806, Max-Change: 0.00118 Iteration: 12, Log-Lik: -2658.806, Max-Change: 0.00101 Iteration: 13, Log-Lik: -2658.805, Max-Change: 0.00042 Iteration: 14, Log-Lik: -2658.805, Max-Change: 0.00025 Iteration: 15, Log-Lik: -2658.805, Max-Change: 0.00026 Iteration: 16, Log-Lik: -2658.805, Max-Change: 0.00023 Iteration: 17, Log-Lik: -2658.805, Max-Change: 0.00023 Iteration: 18, Log-Lik: -2658.805, Max-Change: 0.00021 Iteration: 19, Log-Lik: -2658.805, Max-Change: 0.00019 Iteration: 20, Log-Lik: -2658.805, Max-Change: 0.00017 Iteration: 21, Log-Lik: -2658.805, Max-Change: 0.00017 Iteration: 22, Log-Lik: -2658.805, Max-Change: 0.00015 Iteration: 23, Log-Lik: -2658.805, Max-Change: 0.00015 Iteration: 24, Log-Lik: -2658.805, Max-Change: 0.00013 Iteration: 25, Log-Lik: -2658.805, Max-Change: 0.00013 Iteration: 26, Log-Lik: -2658.805, Max-Change: 0.00011 Iteration: 27, Log-Lik: -2658.805, Max-Change: 0.00011 Iteration: 28, Log-Lik: -2658.805, Max-Change: 0.00010  areainfo(mod, c(-2,0), which.items = 1) #item 1 #>  LowerBound UpperBound      Info TotalInfo Proportion nitems #>          -2          0 0.3899825 0.9879254  0.3947489      1 if (FALSE) { # \\dontrun{ areainfo(mod, c(-2,0), which.items = 1:3) #items 1 to 3 areainfo(mod, c(-2,0)) # all items (total test information)  # plot the area area <- areainfo(mod, c(-2,0)) Theta <- matrix(seq(-3,3, length.out=1000)) info <- testinfo(mod, Theta) plot(info ~ Theta, type = 'l')  pick <- Theta >= -2 & Theta <=0 polygon(c(-2, Theta[pick], 0), c(0, info[pick], 0), col='lightblue') text(x = 2, y = 0.5, labels = paste(\"Total Information:\", round(area$TotalInfo, 3),            \"\\n\\nInformation in (-2, 0):\", round(area$Info, 3),            paste(\"(\", round(100 * area$Proportion, 2), \"%)\", sep = \"\")), cex = 1.2)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse values from multiple imputation draws — averageMI","title":"Collapse values from multiple imputation draws — averageMI","text":"function computes updated parameter standard error estimates using multiple imputation methodology. Given set parameter estimates associated standard errors function returns weighted average overall within variability due multiple imputations according Rubin's (1987) methodology.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse values from multiple imputation draws — averageMI","text":"","code":"averageMI(par, SEpar, as.data.frame = TRUE)"},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse values from multiple imputation draws — averageMI","text":"par list containing parameter estimates computed imputed datasets SEpar list containing standard errors associated par .data.frame logical; return data.frame instead list? Default TRUE","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse values from multiple imputation draws — averageMI","text":"returns list data.frame containing updated averaged parameter estimates,   standard errors, t-values associated degrees freedom two tailed p-values","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Collapse values from multiple imputation draws — averageMI","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Rubin, D.B. (1987) Multiple Imputation Nonresponse Surveys. Wiley & Sons, New York.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Collapse values from multiple imputation draws — averageMI","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collapse values from multiple imputation draws — averageMI","text":"","code":"if (FALSE) { # \\dontrun{  # simulate data set.seed(1234) N <- 1000  # covariates X1 <- rnorm(N); X2 <- rnorm(N) covdata <- data.frame(X1, X2) Theta <- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))  # items and response data a <- matrix(1, 20); d <- matrix(rnorm(20)) dat <- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)  mod1 <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2) coef(mod1, simplify=TRUE)  # draw plausible values for secondary analyses pv <- fscores(mod1, plausible.draws = 10) pvmods <- lapply(pv, function(x, covdata) lm(x ~ covdata$X1 + covdata$X2),                  covdata=covdata)  # compute Rubin's multiple imputation average so <- lapply(pvmods, summary) par <- lapply(so, function(x) x$coefficients[, 'Estimate']) SEpar <- lapply(so, function(x) x$coefficients[, 'Std. Error']) averageMI(par, SEpar)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"bfactor fits confirmatory maximum likelihood two-tier/bifactor/testlet model dichotomous polytomous data item response theory paradigm. IRT models fit using dimensional reduction EM algorithm regardless number specific factors estimated model uses number factors second-tier structure plus 1. bifactor model maximum number dimensions 2 since second-tier consists ubiquitous unidimensional factor. See mirt appropriate methods used objects returned estimation.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"","code":"bfactor(   data,   model,   model2 = paste0(\"G = 1-\", ncol(data)),   group = NULL,   quadpts = NULL,   invariance = \"\",   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"data matrix data.frame consists numerically ordered data, organized form integers, missing data coded NA model numeric vector specifying factor loads   item. example, 4 item test two specific factors, first   specific factor loads first two items second specific factor   last two, vector c(1,1,2,2). items load   second-tier factors (specific component) NA values may   used place-holders. numbers translated format suitable   mirt.model(), combined definition model2, letter 'S'   added respective factor number Alternatively, input can specified using mirt.model syntax   restriction item must load exactly one specific factor (specific factors,   predicted general factor specified model2) model2 two-tier model specification object defined mirt.model() string passed mirt.model. default model fit unidimensional model second-tier, therefore equivalent bifactor model group factor variable indicating group membership used multiple group analyses quadpts number quadrature nodes use accounting reduced number dimensions. Scheme one used mirt, however regards reduced dimensions (e.g., bifactor model 2 dimensions integrated) invariance see multipleGroup details, however, specific factor variances means constrained according dimensional reduction algorithm ... additional arguments passed estimation engine. See mirt details examples","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"function returns object class SingleGroupClass   (SingleGroupClass-class) MultipleGroupClass(MultipleGroupClass-class).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"bfactor follows item factor analysis strategy explicated Gibbons Hedeker (1992), Gibbons et al. (2007), Cai (2010). Nested models may compared via approximate chi-squared difference test reduction AIC BIC (accessible via anova). See mirt details regarding IRT estimation approach used package. two-tier model specific block diagonal covariance structure primary secondary latent traits. Namely, secondary latent traits assumed orthogonal traits fixed variance 1, primary traits can organized vary covary primary traits model. $$\\Sigma_{two-tier} = \\left(\\begin{array}{cc} G & 0 \\\\ 0 & diag(S) \\end{array} \\right)$$ bifactor model special case two-tier model \\(G\\) 1x1 matrix, therefore 1 primary factor modeled. Evaluation numerical integrals two-tier model requires \\(ncol(G) + 1\\) dimensions integration since \\(S\\) second order ('specific') factors require 1 integration grid due dimension reduction technique. Note: multiple group two-tier analyses second-tier means variances freed since specific factors treated independently due dimension reduction technique.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"Cai, L. (2010). two-tier full-information item factor analysis model applications. Psychometrika, 75, 581-612. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Bradlow, E.T., Wainer, H., & Wang, X. (1999). Bayesian random effects model testlets. Psychometrika, 64, 153-168. Gibbons, R. D., & Hedeker, D. R. (1992). Full-information Item Bi-Factor Analysis. Psychometrika, 57, 423-436. Gibbons, R. D., Darrell, R. B., Hedeker, D., Weiss, D. J., Segawa, E., Bhaumik, D. K., Kupfer, D. J., Frank, E., Grochocinski, V. J., & Stover, . (2007). Full-Information item bifactor analysis graded response data. Applied Psychological Measurement, 31, 4-19. Wainer, H., Bradlow, E.T., & Wang, X. (2007). Testlet response theory applications. New York, NY: Cambridge University Press.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"","code":"if (FALSE) { # \\dontrun{  ### load SAT12 and compute bifactor model with 3 specific factors data(SAT12) data <- key2binary(SAT12,   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) specific <- c(2,3,2,3,3,2,1,2,1,1,1,3,1,3,1,2,1,1,3,3,1,1,3,1,3,3,1,3,2,3,1,2) mod1 <- bfactor(data, specific) summary(mod1) itemplot(mod1, 18, drop.zeros = TRUE) #drop the zero slopes to allow plotting  # alternative model definition via ?mirt.model syntax specific2 <- \"S1 = 7,9,10,11,13,15,17,18,21,22,24,27,31               S2 = 1,3,6,8,16,29,32               S3 = 2,4,5,12,14,19,20,23,25,26,28,30\" mod2 <- bfactor(data, specific2) anova(mod1, mod2) # same  # also equivalent using item names instead (not run) specific3 <- \"S1 = Item.7, Item.9, Item.10, Item.11, Item.13, Item.15,                 Item.17, Item.18, Item.21, Item.22, Item.24, Item.27, Item.31               S2 = Item.1, Item.3, Item.6, Item.8, Item.16, Item.29, Item.32               S3 = Item.2, Item.4, Item.5, Item.12, Item.14, Item.19,                 Item.20, Item.23, Item.25, Item.26, Item.28, Item.30\" # mod3 <- bfactor(data, specific3) # anova(mod1, mod2, mod3)  # all same  ### Try with fixed guessing parameters added guess <- rep(.1,32) mod2 <- bfactor(data, specific, guess = guess) coef(mod2) anova(mod1, mod2)  ## don't estimate specific factor for item 32 specific[32] <- NA mod3 <- bfactor(data, specific) anova(mod3, mod1)  # same, but with syntax (not run) specific3 <- \"S1 = 7,9,10,11,13,15,17,18,21,22,24,27,31               S2 = 1,3,6,8,16,29               S3 = 2,4,5,12,14,19,20,23,25,26,28,30\" # mod3b <- bfactor(data, specific3) # anova(mod3b)   ######### # mixed itemtype example  # simulate data a <- matrix(c( 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5),ncol=3,byrow=TRUE)  d <- matrix(c( -1.0,NA,NA, -1.5,NA,NA,  1.5,NA,NA,  0.0,NA,NA, 2.5,1.0,-1, 3.0,2.0,-0.5, 3.0,2.0,-0.5, 3.0,2.0,-0.5, 2.5,1.0,-1, 2.0,0.0,NA, -1.0,NA,NA, -1.5,NA,NA,  1.5,NA,NA,  0.0,NA,NA),ncol=3,byrow=TRUE) items <- rep('2PL', 14) items[5:10] <- 'graded'  sigma <- diag(3) dataset <- simdata(a,d,5000,itemtype=items,sigma=sigma) itemstats(dataset)  specific <- \"S1 = 1-7              S2 = 8-14\" simmod <- bfactor(dataset, specific) coef(simmod, simplify=TRUE)   ######### # General testlet response model (Wainer, 2007)  # simulate data set.seed(1234) a <- matrix(0, 12, 4) a[,1] <- rlnorm(12, .2, .3) ind <- 1 for(i in 1:3){    a[ind:(ind+3),i+1] <- a[ind:(ind+3),1]    ind <- ind+4 } print(a) d <- rnorm(12, 0, .5) sigma <- diag(c(1, .5, 1, .5)) dataset <- simdata(a,d,2000,itemtype=rep('2PL', 12),sigma=sigma) itemstats(dataset)  # estimate by applying constraints and freeing the latent variances specific <- \"S1 = 1-4              S2 = 5-8              S3 = 9-12\" model <- \"G = 1-12           CONSTRAIN = (1, a1, a2), (2, a1, a2), (3, a1, a2), (4, a1, a2),             (5, a1, a3), (6, a1, a3), (7, a1, a3), (8, a1, a3),             (9, a1, a4), (10, a1, a4), (11, a1, a4), (12, a1, a4)           COV = S1*S1, S2*S2, S3*S3\"  simmod <- bfactor(dataset, specific, model) coef(simmod, simplify=TRUE)  # Constrained testlet model (Bradlow, 1999) model2 <- \"G = 1-12           CONSTRAIN = (1, a1, a2), (2, a1, a2), (3, a1, a2), (4, a1, a2),             (5, a1, a3), (6, a1, a3), (7, a1, a3), (8, a1, a3),             (9, a1, a4), (10, a1, a4), (11, a1, a4), (12, a1, a4),             (GROUP, COV_22, COV_33, COV_44)           COV = S1*S1, S2*S2, S3*S3\"  simmod2 <- bfactor(dataset, specific, model2) coef(simmod2, simplify=TRUE) anova(simmod2, simmod)   ######### # Two-tier model  # simulate data set.seed(1234) a <- matrix(c(   0,1,0.5,NA,NA,   0,1,0.5,NA,NA,   0,1,0.5,NA,NA,   0,1,0.5,NA,NA,   0,1,0.5,NA,NA,   0,1,NA,0.5,NA,   0,1,NA,0.5,NA,   0,1,NA,0.5,NA,   1,0,NA,0.5,NA,   1,0,NA,0.5,NA,   1,0,NA,0.5,NA,   1,0,NA,NA,0.5,   1,0,NA,NA,0.5,   1,0,NA,NA,0.5,   1,0,NA,NA,0.5,   1,0,NA,NA,0.5),ncol=5,byrow=TRUE)  d <- matrix(rnorm(16)) items <- rep('2PL', 16)  sigma <- diag(5) sigma[1,2] <- sigma[2,1] <- .4 dataset <- simdata(a,d,2000,itemtype=items,sigma=sigma) itemstats(dataset)  specific <- \"S1 = 1-5              S2 = 6-11              S3 = 12-16\" model <- '     G1 = 1-8     G2 = 9-16     COV = G1*G2'  # quadpts dropped for faster estimation, but not as precise simmod <- bfactor(dataset, specific, model, quadpts = 9, TOL = 1e-3) coef(simmod, simplify=TRUE) summary(simmod) itemfit(simmod, QMC=TRUE) M2(simmod, QMC=TRUE) residuals(simmod, QMC=TRUE)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric bootstrap likelihood-ratio test — boot.LR","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"Given two fitted models, compute parametric bootstrap test determine whether less restrictive models fits significantly better restricted model. Note hypothesis test also works prior parameter distributions included either model. Function can run parallel using suitable mirtCluster definition.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"","code":"boot.LR(mod, mod2, R = 1000, verbose = TRUE)"},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"mod estimated model object, constrained mod2 mod2 estimated model object R number parametric bootstraps use. verbose logical; include additional information console?","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"p-value evaluating whether restrictive model fits significantly worse   less restrictive model","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"","code":"if (FALSE) { # \\dontrun{  # standard dat <- expand.table(LSAT7) mod1 <- mirt(dat, 1) mod2 <- mirt(dat, 1, '3PL')  # standard LR test anova(mod1, mod2)  # bootstrap LR test (run in parallel to save time) if(interactive()) mirtCluster() boot.LR(mod1, mod2, R=200)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate bootstrapped standard errors for estimated models — boot.mirt","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"Given internal mirt object estimate bootstrapped standard errors. may beneficial run computations using multi-core architecture (e.g., parallel package). Parameters organized freely estimated values mod2values(x) (equality constraints also returned bootstrapped estimates).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"","code":"boot.mirt(x, R = 100, boot.fun = NULL, technical = NULL, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"x estimated model object R number draws use (passed boot() function) boot.fun user-defined function used extract information bootstrap fitted models. Must form boot.fun(x), x bootstrap fitted model investigation, return must numeric vector. omitted default function defined internally returns estimated parameters mod object, resulting bootstrapped parameter estimate results technical technical arguments passed estimation engine. See mirt details ... additional arguments passed boot(...) mirt's estimation engine","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"","code":"if (FALSE) { # \\dontrun{  # standard mod <- mirt(Science, 1) booted <- boot.mirt(mod, R=20) plot(booted) booted  #run in parallel using snow back-end using all available cores mod <- mirt(Science, 1) booted <- boot.mirt(mod, parallel = 'snow', ncpus = parallel::detectCores()) booted  #### # bootstrapped CIs for standardized factor loadings boot.fun <- function(mod){   so <- summary(mod, verbose=FALSE)   as.vector(so$rotF) }  # test to see if it works before running boot.fun(mod)  # run booted.loads <- boot.mirt(mod, boot.fun=boot.fun) booted.loads  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract raw coefs from model object — coef-method","title":"Extract raw coefs from model object — coef-method","text":"Return list (data.frame) raw item group level coefficients. Note output console rounded three digits, returned list objects . Hence, elements cfs <- coef(mod); cfs[[1]] contain non-rounded results (useful simulations).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract raw coefs from model object — coef-method","text":"","code":"# S4 method for class 'SingleGroupClass' coef(   object,   CI = 0.95,   printSE = FALSE,   rotate = \"none\",   Target = NULL,   IRTpars = FALSE,   rawug = FALSE,   as.data.frame = FALSE,   simplify = FALSE,   unique = FALSE,   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract raw coefs from model object — coef-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass CI amount converged used compute confidence intervals; default 95 percent confidence intervals printSE logical; print standard errors instead confidence intervals? IRTpars = TRUE delta method used compute associated standard errors mirt's default slope-intercept form rotate see summary method details. default rotation 'none' Target dummy variable matrix indicting target rotation pattern IRTpars logical; convert slope intercept parameters traditional IRT parameters? applicable unidimensional models models simple structure (.e., one non-zero slope). suitable ACOV estimate computed fitted model, printSE = FALSE, suitable CIs included based delta method (applicable) rawug logical; return untransformed internal g u parameters? FALSE, g u's converted original format along delta standard errors .data.frame logical; convert list output data.frame instead? simplify logical; items parameter names (indicating class) collapsed matrix, list length 2 returned containing matrix item parameters group-level estimates unique return vector uniquely estimated parameters verbose logical; allow information printed console? ... additional arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract raw coefs from model object — coef-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract raw coefs from model object — coef-method","text":"","code":"if (FALSE) { # \\dontrun{ dat <- expand.table(LSAT7) x <- mirt(dat, 1) coef(x) coef(x, IRTpars = TRUE) coef(x, simplify = TRUE)  #with computed information matrix x <- mirt(dat, 1, SE = TRUE) coef(x) coef(x, printSE = TRUE) coef(x, as.data.frame = TRUE)  #two factors x2 <- mirt(Science, 2) coef(x2) coef(x2, rotate = 'varimax')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a user defined group-level object with correct generic functions — createGroup","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"Initializes proper S4 class methods necessary mirt functions use estimation defining customized group-level functions. use defined objects pass mirt(..., customGroup = OBJECT) command, ensure class parameters properly labelled.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"","code":"createGroup(   par,   est,   den,   nfact,   standardize = FALSE,   gr = NULL,   hss = NULL,   gen = NULL,   lbound = NULL,   ubound = NULL,   derivType = \"Richardson\" )"},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"par named vector starting values parameters est logical vector indicating parameters freely estimated default den probability density function given Theta/ability values. First input contains vector defined parameters second input must matrix called Theta. Function also must return numeric vector object corresponding associated densities row Theta input nfact number factors required model. E.g., unidimensional models one dimension integration nfact = 1 standardize logical; use standardization quadrature table method proposed Woods Thissen (2006)? TRUE, logical elements named 'MEAN_1' 'COV_11' can included parameter vector, values set FALSE est input E-table standardized fixed values (e.g., par <- c(a1=1, d=0, MEAN_1=0, COV_11=1) est <- c(TRUE, TRUE, FALSE, FALSE) standardize E-table 0 mean unit variance) gr gradient function (vector first derivatives) log-likelihood used estimation. function must form gr(x, Theta), x object defined createGroup() Theta matrix latent trait parameters hss Hessian function (matrix second derivatives) log-likelihood used estimation. specified numeric approximation used. input identical gr argument gen function used GenRandomPars = TRUE passed estimation function generate random starting values. Function must form function(object) ... must return vector properties equivalent par object. NULL, parameters remain defined starting values default lbound optional vector indicating lower bounds parameters. specified bounds set -Inf ubound optional vector indicating lower bounds parameters. specified bounds set Inf derivType gr hss terms specified type used obtain numerically. Default 'Richardson'","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"","code":"# normal density example, N(mu, sigma^2) den <- function(obj, Theta) dnorm(Theta, obj@par[1], sqrt(obj@par[2])) par <- c(mu = 0, sigma2 = .5) est <- c(FALSE, TRUE) lbound <- c(-Inf, 0) grp <- createGroup(par, est, den, nfact = 1, lbound=lbound)  dat <- expand.table(LSAT6) mod <- mirt(dat, 1, 'Rasch') #>  Iteration: 1, Log-Lik: -2473.219, Max-Change: 0.05796 Iteration: 2, Log-Lik: -2471.905, Max-Change: 0.03951 Iteration: 3, Log-Lik: -2471.040, Max-Change: 0.03366 Iteration: 4, Log-Lik: -2470.482, Max-Change: 0.03644 Iteration: 5, Log-Lik: -2469.693, Max-Change: 0.02589 Iteration: 6, Log-Lik: -2469.238, Max-Change: 0.02212 Iteration: 7, Log-Lik: -2468.875, Max-Change: 0.01999 Iteration: 8, Log-Lik: -2468.573, Max-Change: 0.01718 Iteration: 9, Log-Lik: -2468.329, Max-Change: 0.01528 Iteration: 10, Log-Lik: -2468.157, Max-Change: 0.01747 Iteration: 11, Log-Lik: -2467.932, Max-Change: 0.01255 Iteration: 12, Log-Lik: -2467.788, Max-Change: 0.01111 Iteration: 13, Log-Lik: -2467.669, Max-Change: 0.01035 Iteration: 14, Log-Lik: -2467.565, Max-Change: 0.00911 Iteration: 15, Log-Lik: -2467.480, Max-Change: 0.00826 Iteration: 16, Log-Lik: -2467.417, Max-Change: 0.00959 Iteration: 17, Log-Lik: -2467.338, Max-Change: 0.00701 Iteration: 18, Log-Lik: -2467.285, Max-Change: 0.00633 Iteration: 19, Log-Lik: -2467.240, Max-Change: 0.00600 Iteration: 20, Log-Lik: -2467.199, Max-Change: 0.00534 Iteration: 21, Log-Lik: -2467.166, Max-Change: 0.00490 Iteration: 22, Log-Lik: -2467.141, Max-Change: 0.00570 Iteration: 23, Log-Lik: -2467.109, Max-Change: 0.00424 Iteration: 24, Log-Lik: -2467.088, Max-Change: 0.00387 Iteration: 25, Log-Lik: -2467.069, Max-Change: 0.00370 Iteration: 26, Log-Lik: -2467.052, Max-Change: 0.00332 Iteration: 27, Log-Lik: -2467.038, Max-Change: 0.00307 Iteration: 28, Log-Lik: -2467.027, Max-Change: 0.00356 Iteration: 29, Log-Lik: -2467.014, Max-Change: 0.00269 Iteration: 30, Log-Lik: -2467.005, Max-Change: 0.00247 Iteration: 31, Log-Lik: -2466.997, Max-Change: 0.00238 Iteration: 32, Log-Lik: -2466.989, Max-Change: 0.00214 Iteration: 33, Log-Lik: -2466.983, Max-Change: 0.00199 Iteration: 34, Log-Lik: -2466.978, Max-Change: 0.00231 Iteration: 35, Log-Lik: -2466.973, Max-Change: 0.00176 Iteration: 36, Log-Lik: -2466.968, Max-Change: 0.00162 Iteration: 37, Log-Lik: -2466.965, Max-Change: 0.00157 Iteration: 38, Log-Lik: -2466.961, Max-Change: 0.00141 Iteration: 39, Log-Lik: -2466.959, Max-Change: 0.00132 Iteration: 40, Log-Lik: -2466.956, Max-Change: 0.00153 Iteration: 41, Log-Lik: -2466.954, Max-Change: 0.00117 Iteration: 42, Log-Lik: -2466.952, Max-Change: 0.00108 Iteration: 43, Log-Lik: -2466.950, Max-Change: 0.00105 Iteration: 44, Log-Lik: -2466.949, Max-Change: 0.00095 Iteration: 45, Log-Lik: -2466.947, Max-Change: 0.00089 Iteration: 46, Log-Lik: -2466.946, Max-Change: 0.00108 Iteration: 47, Log-Lik: -2466.945, Max-Change: 0.00079 Iteration: 48, Log-Lik: -2466.944, Max-Change: 0.00073 Iteration: 49, Log-Lik: -2466.944, Max-Change: 0.00070 Iteration: 50, Log-Lik: -2466.943, Max-Change: 0.00065 Iteration: 51, Log-Lik: -2466.942, Max-Change: 0.00060 Iteration: 52, Log-Lik: -2466.942, Max-Change: 0.00071 Iteration: 53, Log-Lik: -2466.941, Max-Change: 0.00054 Iteration: 54, Log-Lik: -2466.941, Max-Change: 0.00050 Iteration: 55, Log-Lik: -2466.940, Max-Change: 0.00048 Iteration: 56, Log-Lik: -2466.940, Max-Change: 0.00044 Iteration: 57, Log-Lik: -2466.940, Max-Change: 0.00041 Iteration: 58, Log-Lik: -2466.940, Max-Change: 0.00053 Iteration: 59, Log-Lik: -2466.939, Max-Change: 0.00037 Iteration: 60, Log-Lik: -2466.939, Max-Change: 0.00034 Iteration: 61, Log-Lik: -2466.939, Max-Change: 0.00033 Iteration: 62, Log-Lik: -2466.939, Max-Change: 0.00030 Iteration: 63, Log-Lik: -2466.939, Max-Change: 0.00028 Iteration: 64, Log-Lik: -2466.939, Max-Change: 0.00032 Iteration: 65, Log-Lik: -2466.938, Max-Change: 0.00025 Iteration: 66, Log-Lik: -2466.938, Max-Change: 0.00023 Iteration: 67, Log-Lik: -2466.938, Max-Change: 0.00022 Iteration: 68, Log-Lik: -2466.938, Max-Change: 0.00020 Iteration: 69, Log-Lik: -2466.938, Max-Change: 0.00019 Iteration: 70, Log-Lik: -2466.938, Max-Change: 0.00024 Iteration: 71, Log-Lik: -2466.938, Max-Change: 0.00017 Iteration: 72, Log-Lik: -2466.938, Max-Change: 0.00016 Iteration: 73, Log-Lik: -2466.938, Max-Change: 0.00016 Iteration: 74, Log-Lik: -2466.938, Max-Change: 0.00014 Iteration: 75, Log-Lik: -2466.938, Max-Change: 0.00013 Iteration: 76, Log-Lik: -2466.938, Max-Change: 0.00017 Iteration: 77, Log-Lik: -2466.938, Max-Change: 0.00012 Iteration: 78, Log-Lik: -2466.938, Max-Change: 0.00011 Iteration: 79, Log-Lik: -2466.938, Max-Change: 0.00011 Iteration: 80, Log-Lik: -2466.938, Max-Change: 0.00010 modcustom <- mirt(dat, 1, 'Rasch', customGroup=grp) #>  Iteration: 1, Log-Lik: -2469.780, Max-Change: 0.11152 Iteration: 2, Log-Lik: -2467.243, Max-Change: 0.01652 Iteration: 3, Log-Lik: -2467.096, Max-Change: 0.00440 Iteration: 4, Log-Lik: -2467.075, Max-Change: 0.00328 Iteration: 5, Log-Lik: -2467.057, Max-Change: 0.00264 Iteration: 6, Log-Lik: -2467.044, Max-Change: 0.00248 Iteration: 7, Log-Lik: -2467.033, Max-Change: 0.00237 Iteration: 8, Log-Lik: -2467.023, Max-Change: 0.00224 Iteration: 9, Log-Lik: -2467.014, Max-Change: 0.00212 Iteration: 10, Log-Lik: -2467.007, Max-Change: 0.00268 Iteration: 11, Log-Lik: -2466.998, Max-Change: 0.00195 Iteration: 12, Log-Lik: -2466.992, Max-Change: 0.00183 Iteration: 13, Log-Lik: -2466.986, Max-Change: 0.00180 Iteration: 14, Log-Lik: -2466.981, Max-Change: 0.00166 Iteration: 15, Log-Lik: -2466.976, Max-Change: 0.00157 Iteration: 16, Log-Lik: -2466.973, Max-Change: 0.00175 Iteration: 17, Log-Lik: -2466.968, Max-Change: 0.00142 Iteration: 18, Log-Lik: -2466.965, Max-Change: 0.00133 Iteration: 19, Log-Lik: -2466.962, Max-Change: 0.00131 Iteration: 20, Log-Lik: -2466.959, Max-Change: 0.00120 Iteration: 21, Log-Lik: -2466.957, Max-Change: 0.00113 Iteration: 22, Log-Lik: -2466.955, Max-Change: 0.00130 Iteration: 23, Log-Lik: -2466.953, Max-Change: 0.00102 Iteration: 24, Log-Lik: -2466.951, Max-Change: 0.00096 Iteration: 25, Log-Lik: -2466.950, Max-Change: 0.00093 Iteration: 26, Log-Lik: -2466.948, Max-Change: 0.00085 Iteration: 27, Log-Lik: -2466.947, Max-Change: 0.00080 Iteration: 28, Log-Lik: -2466.946, Max-Change: 0.00095 Iteration: 29, Log-Lik: -2466.945, Max-Change: 0.00073 Iteration: 30, Log-Lik: -2466.944, Max-Change: 0.00068 Iteration: 31, Log-Lik: -2466.943, Max-Change: 0.00066 Iteration: 32, Log-Lik: -2466.943, Max-Change: 0.00060 Iteration: 33, Log-Lik: -2466.942, Max-Change: 0.00057 Iteration: 34, Log-Lik: -2466.942, Max-Change: 0.00071 Iteration: 35, Log-Lik: -2466.941, Max-Change: 0.00051 Iteration: 36, Log-Lik: -2466.941, Max-Change: 0.00047 Iteration: 37, Log-Lik: -2466.940, Max-Change: 0.00046 Iteration: 38, Log-Lik: -2466.940, Max-Change: 0.00043 Iteration: 39, Log-Lik: -2466.940, Max-Change: 0.00040 Iteration: 40, Log-Lik: -2466.940, Max-Change: 0.00042 Iteration: 41, Log-Lik: -2466.939, Max-Change: 0.00036 Iteration: 42, Log-Lik: -2466.939, Max-Change: 0.00034 Iteration: 43, Log-Lik: -2466.939, Max-Change: 0.00033 Iteration: 44, Log-Lik: -2466.939, Max-Change: 0.00030 Iteration: 45, Log-Lik: -2466.939, Max-Change: 0.00028 Iteration: 46, Log-Lik: -2466.939, Max-Change: 0.00041 Iteration: 47, Log-Lik: -2466.938, Max-Change: 0.00025 Iteration: 48, Log-Lik: -2466.938, Max-Change: 0.00023 Iteration: 49, Log-Lik: -2466.938, Max-Change: 0.00022 Iteration: 50, Log-Lik: -2466.938, Max-Change: 0.00021 Iteration: 51, Log-Lik: -2466.938, Max-Change: 0.00019 Iteration: 52, Log-Lik: -2466.938, Max-Change: 0.00025 Iteration: 53, Log-Lik: -2466.938, Max-Change: 0.00018 Iteration: 54, Log-Lik: -2466.938, Max-Change: 0.00016 Iteration: 55, Log-Lik: -2466.938, Max-Change: 0.00016 Iteration: 56, Log-Lik: -2466.938, Max-Change: 0.00014 Iteration: 57, Log-Lik: -2466.938, Max-Change: 0.00013 Iteration: 58, Log-Lik: -2466.938, Max-Change: 0.00013 Iteration: 59, Log-Lik: -2466.938, Max-Change: 0.00012 Iteration: 60, Log-Lik: -2466.938, Max-Change: 0.00011 Iteration: 61, Log-Lik: -2466.938, Max-Change: 0.00011 Iteration: 62, Log-Lik: -2466.938, Max-Change: 0.00010  coef(mod) #> $Item_1 #>     a1     d g u #> par  1 2.731 0 1 #>  #> $Item_2 #>     a1     d g u #> par  1 0.999 0 1 #>  #> $Item_3 #>     a1    d g u #> par  1 0.24 0 1 #>  #> $Item_4 #>     a1     d g u #> par  1 1.307 0 1 #>  #> $Item_5 #>     a1   d g u #> par  1 2.1 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0  0.572 #>  coef(modcustom) #> $Item_1 #>     a1     d g u #> par  1 2.729 0 1 #>  #> $Item_2 #>     a1     d g u #> par  1 0.998 0 1 #>  #> $Item_3 #>     a1    d g u #> par  1 0.24 0 1 #>  #> $Item_4 #>     a1     d g u #> par  1 1.306 0 1 #>  #> $Item_5 #>     a1     d g u #> par  1 2.099 0 1 #>  #> $GroupPars #>     mu sigma2 #> par  0  0.569 #>"},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a user defined item with correct generic functions — createItem","title":"Create a user defined item with correct generic functions — createItem","text":"Initializes proper S4 class methods necessary mirt functions use estimation. use defined objects pass mirt(..., customItems = list()) command, ensure classes properly labelled unique list. Additionally, input mirt(..., customItemsData = list()) can also included specify additional item-level information better recycle custom-item definitions (e.g., supplying varying Q-matrices), list input must length number items. examples regarding function can used fitting unfolding-type models see Liu Chalmers (2018).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a user defined item with correct generic functions — createItem","text":"","code":"createItem(   name,   par,   est,   P,   gr = NULL,   hss = NULL,   gen = NULL,   lbound = NULL,   ubound = NULL,   derivType = \"Richardson\",   derivType.hss = \"Richardson\",   bytecompile = TRUE )"},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a user defined item with correct generic functions — createItem","text":"name character indicating item class name defined par named vector starting values parameters est logical vector indicating parameters freely estimated default P probability trace function categories (first column category 1, second   category two, etc). First input contains vector item parameters, second input   must matrix called Theta, third input must number categories   called ncat, (optionally) fourth argument termed itemdata   may included containing  users specification information.   last optional input utilized within estimation functions   mirt via list input customItemsData   naturally recycle custom-item definitions. Therefore, inputs must form function(par, Theta, ncat){...} function(par, Theta, ncat, itemdata){...} valid; however, names arguements relavent. Finally, function must return matrix object category probabilities,   columns represent respective category gr gradient function (vector first derivatives) log-likelihood used estimation. function must form gr(x, Theta), x object defined createItem() Theta matrix latent trait parameters. Tabulated (EM) raw (MHRM) data located x@dat slot, used form complete data log-likelihood. specified numeric approximation used hss Hessian function (matrix second derivatives) log-likelihood used estimation. specified numeric approximation used (required MH-RM algorithm ). input identical gr argument gen function used GenRandomPars = TRUE passed estimation function generate random starting values. Function must form function(object) ... must return vector properties equivalent par object. NULL, parameters remain defined starting values default lbound optional vector indicating lower bounds parameters. specified bounds set -Inf ubound optional vector indicating lower bounds parameters. specified bounds set Inf derivType gr term specified type used obtain gradient numerically symbolically. Default 'Richardson' extrapolation method; see numerical_deriv details options. 'symbolic' supplied gradient computed using symbolical approach (potentially accurate method, though may fail depending P function defined) derivType.hss hss term specified type used obtain Hessian numerically. Default 'Richardson' extrapolation method; see numerical_deriv details options. 'symbolic' supplied Hessian computed using symbolical approach (potentially accurate method, though may fail depending P function defined) bytecompile logical; applicable, byte compile functions provided? Default TRUE provide","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a user defined item with correct generic functions — createItem","text":"summary() function return proper standardized loadings since function sure handle (slopes defined !). Instead loadings .001 filled place-holders.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a user defined item with correct generic functions — createItem","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Liu, C.-W. Chalmers, R. P. (2018). Fitting item response unfolding models   Likert-scale data using mirt R. PLoS ONE, 13, 5.   doi:10.1371/journal.pone.0196292","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a user defined item with correct generic functions — createItem","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a user defined item with correct generic functions — createItem","text":"","code":"if (FALSE) { # \\dontrun{  name <- 'old2PL' par <- c(a = .5, b = -2) est <- c(TRUE, TRUE) P.old2PL <- function(par,Theta, ncat){      a <- par[1]      b <- par[2]      P1 <- 1 / (1 + exp(-1*a*(Theta - b)))      cbind(1-P1, P1) }  x <- createItem(name, par=par, est=est, P=P.old2PL)  # So, let's estimate it! dat <- expand.table(LSAT7) sv <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x), pars = 'values') tail(sv) #looks good mod <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x)) coef(mod) mod2 <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x), method = 'MHRM') coef(mod2)  # same definition as above, but using symbolic derivative computations # (can be more accurate/stable) xs <- createItem(name, par=par, est=est, P=P.old2PL, derivType = 'symbolic') mod <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=xs)) coef(mod, simplify=TRUE)  # several secondary functions supported M2(mod, calcNull=FALSE) itemfit(mod) fscores(mod, full.scores=FALSE) plot(mod)  # fit the same model, but specify gradient function explicitly (use of a browser() may be helpful) gr <- function(x, Theta){      # browser()      a <- x@par[1]      b <- x@par[2]      P <- probtrace(x, Theta)      PQ <- apply(P, 1, prod)      r_P <- x@dat / P      grad <- numeric(2)      grad[2] <- sum(-a * PQ * (r_P[,2] - r_P[,1]))      grad[1] <- sum((Theta - b) * PQ * (r_P[,2] - r_P[,1]))       ## check with internal numerical form to be safe      # numerical_deriv(x@par[x@est], mirt:::EML, obj=x, Theta=Theta)      grad }  x <- createItem(name, par=par, est=est, P=P.old2PL, gr=gr) mod <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x)) coef(mod, simplify=TRUE)  ### non-linear name <- 'nonlin' par <- c(a1 = .5, a2 = .1, d = 0) est <- c(TRUE, TRUE, TRUE) P.nonlin <- function(par,Theta, ncat=2){      a1 <- par[1]      a2 <- par[2]      d <- par[3]      P1 <- 1 / (1 + exp(-1*(a1*Theta + a2*Theta^2 + d)))      cbind(1-P1, P1) }  x2 <- createItem(name, par=par, est=est, P=P.nonlin)  mod <- mirt(dat, 1, c(rep('2PL',4), 'nonlin'), customItems=list(nonlin=x2)) coef(mod)  ### nominal response model (Bock 1972 version) Tnom.dev <- function(ncat) {    T <- matrix(1/ncat, ncat, ncat - 1)    diag(T[-1, ]) <-  diag(T[-1, ]) - 1    return(T) }  name <- 'nom' par <- c(alp=c(3,0,-3),gam=rep(.4,3)) est <- rep(TRUE, length(par)) P.nom <- function(par, Theta, ncat){    alp <- par[1:(ncat-1)]    gam <- par[ncat:length(par)]    a <- Tnom.dev(ncat) %*% alp    c <- Tnom.dev(ncat) %*% gam    z <- matrix(0, nrow(Theta), ncat)    for(i in 1:ncat)        z[,i] <- a[i] * Theta + c[i]    P <- exp(z) / rowSums(exp(z))    P }  nom1 <- createItem(name, par=par, est=est, P=P.nom) nommod <- mirt(Science, 1, 'nom1', customItems=list(nom1=nom1)) coef(nommod) Tnom.dev(4) %*% coef(nommod)[[1]][1:3] #a Tnom.dev(4) %*% coef(nommod)[[1]][4:6] #d  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/deAyala.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of deAyala data — deAyala","title":"Description of deAyala data — deAyala","text":"Mathematics data de Ayala (2009; pg. 14); 5 item dataset table format.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/deAyala.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of deAyala data — deAyala","text":"de Ayala, R. J. (2009). theory practice item response theory. Guilford Press.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/deAyala.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of deAyala data — deAyala","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/deAyala.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of deAyala data — deAyala","text":"","code":"if (FALSE) { # \\dontrun{ dat <- expand.table(deAyala) head(dat) itemstats(dat)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw plausible parameter instantiations from a given model — draw_parameters","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"Draws plausible parameters model using parametric sampling (information matrix computed) via bootstrap sampling. Primarily use DRF function.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"","code":"draw_parameters(   mod,   draws,   method = c(\"parametric\", \"boostrap\"),   redraws = 20,   verbose = FALSE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"mod estimated single multiple-group model draws number draws obtain method type plausible values obtain. Can 'parametric', parametric sampling scheme uses estimated information matrix, 'boostrap' obtain values boot function. Default 'parametric' redraws number redraws perform given parameteric sample satisfy upper lower parameter bounds. valid set found within number draws error thrown verbose logical; include additional information console? ... additional arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"returns draws x p matrix plausible parameters, row correspeonds single   set","code":""},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1234) n <- 40 N <- 500  # only first 5 items as anchors model <- 'F = 1-40           CONSTRAINB = (1-5, a1), (1-5, d)'  a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('Group_1', N), rep('Group_2', N))  ## ------------- # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N, itemtype = 'dich') dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var'))  param_set <- draw_parameters(mod, 100) head(param_set) } # }"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":null,"dir":"Reference","previous_headings":"","what":"Empirical effect sizes based on latent trait estimates — empirical_ES","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"Computes effect size measures differential item functioning differential test/bundle functioning based expected scores Meade (2010). Item parameters reference focal group used conjunction focal group empirical theta estimates (assumed normally distributed theta) compute expected scores.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"","code":"empirical_ES(   mod,   Theta.focal = NULL,   focal_items = 1L:extract.mirt(mod, \"nitems\"),   DIF = TRUE,   npts = 61,   theta_lim = c(-6, 6),   plot = FALSE,   type = \"b\",   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"mod multipleGroup object estimated 2 groups. first group object assumed reference group default (.e., ref.group = 1), conforms  invariance arguments multipleGroup Theta.focal optional matrix Theta values focal group evaluated. supplied default values fscores used conjunction ... arguments passed focal_items numeric vector indicating items include tests. default uses items. Selecting fewer items result tests 'differential bundle functioning' DIF = FALSE DIF logical; return data.frame item-level imputation properties? FALSE, DBF DTF statistics reported npts number points use integration. Default 61 theta_lim lower upper limits latent trait (theta) evaluated, used conjunction npts plot logical; plot expected scores items/test expected scores computed using focal group thetas focal reference group item parameters type type objects draw lattice; default plots points lines par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice ... additional arguments passed fscores xyplot","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"dif","dir":"Reference","previous_headings":"","what":"DIF","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"default DIF = TRUE produces several effect sizes indices item level. Signed indices allow DIF favoring focal group one point theta distribution cancel DIF favoring reference group another point theta distribution. Unsigned indices take absolute value summing averaging, thus allowing cancellation DIF across theta. SIDS Signed Item Difference Sample. average difference expected scores across focal sample using focal reference group item parameters. UIDS Unsigned Item Difference Sample. SIDS except absolute value expected scores taken prior averaging across sample. D-Max maximum difference expected scores sample. ESSD Expected Score Standardized Difference. Cohen's D difference expected scores. SIDN Signed Item Difference Normal distribution. Identical SIDS averaged across normal distribution rather sample. UIDN Unsigned Item Difference Normal distribution. Identical UIDS averaged across normal distribution rather sample.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"dbf-dtf","dir":"Reference","previous_headings":"","what":"DBF/DTF","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"DIF = FALSE produces series test/bundle-level indices based item-level indices. STDS Signed Test Differences Sample. sum SIDS across items. UTDS Unsigned Test Differences Sample. sum UIDS across items. Stark's DTFR Stark's version STDS using normal distribution rather sample estimated thetas. UDTFR Unsigned Expected Test Scores Differences Sample. difference observed summed scale scores expected, average, across hypothetical focal group normally distributed theta, DF uniform nature items UETSDS Unsigned Expected Test Score Differences Sample. hypothetical difference expected scale scores present scale-level DF uniform across respondents (.e., always favoring focal group). UETSDN Identical UETSDS computed using normal distribution. Test D-Max Maximum expected test score differences sample. ETSSD Expected Test Score Standardized Difference. Cohen's D expected test scores.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Meade, . W. (2010). taxonomy effect size measures differential functioning items scales. Journal Applied Psychology, 95, 728-743.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"Adam Meade, contributions Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"","code":"if (FALSE) { # \\dontrun{  # no DIF set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2)  # ensure 'Ref' is the first group (and therefore reference group during estimation) group <- factor(c(rep('Ref', N), rep('Focal', N)), levels = c('Ref', 'Focal'))  mod <- multipleGroup(dat, 1, group = group,    invariance = c(colnames(dat)[1:5], 'free_means', 'free_var')) coef(mod, simplify=TRUE)  empirical_ES(mod) empirical_ES(mod, DIF=FALSE) empirical_ES(mod, DIF=FALSE, focal_items = 10:15)  empirical_ES(mod, plot=TRUE) empirical_ES(mod, plot=TRUE, DIF=FALSE)  ###--------------------------------------------- # DIF set.seed(12345) a1 <- a2 <- matrix(abs(rnorm(15,1,.3)), ncol=1) d1 <- d2 <- matrix(rnorm(15,0,.7),ncol=1) a2[10:15,] <- a2[10:15,] + rnorm(6, 0, .3) d2[10:15,] <- d2[10:15,] + rnorm(6, 0, .3) itemtype <- rep('dich', nrow(a1)) N <- 1000 dataset1 <- simdata(a1, d1, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- factor(c(rep('Ref', N), rep('Focal', N)), levels = c('Ref', 'Focal'))  mod <- multipleGroup(dat, 1, group = group,    invariance = c(colnames(dat)[1:5], 'free_means', 'free_var')) coef(mod, simplify=TRUE)  empirical_ES(mod) empirical_ES(mod, DIF = FALSE) empirical_ES(mod, plot=TRUE) empirical_ES(mod, plot=TRUE, DIF=FALSE)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to generate empirical unidimensional item and test plots — empirical_plot","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"Given dataset containing item responses function construct empirical graphics using observed responses item conditioned total score. individual item plots requested total score formed without item interest (.e., total score without item).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"","code":"empirical_plot(   data,   which.items = NULL,   type = \"prop\",   smooth = FALSE,   formula = resp ~ s(TS, k = 5),   main = NULL,   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"data data.frame matrix item responses (see mirt typical input) .items numeric vector indicating items plot faceted image plot. NULL empirical test plots constructed instead type character vector specifying type plot draw. .item NULL can 'prop' (default) 'hist', otherwise can 'prop' (default) 'boxplot' smooth logical; include GAM smoother instead raw proportions? Default FALSE formula formula used GAM smoother main main title plot. NULL internal default used par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice ... additional arguments passed lattice coef()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"Note types plots used unidimensional tests monotonically increasing item response functions. monotonicity true items, however, plots may serve visual diagnostic tool long majority items indeed monotonic.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"","code":"if (FALSE) { # \\dontrun{  SAT12[SAT12 == 8] <- NA data <- key2binary(SAT12,    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  # test plot empirical_plot(data) empirical_plot(data, type = 'hist') empirical_plot(data, type = 'hist', breaks=20)  # items 1, 2 and 5 empirical_plot(data, c(1, 2, 5)) empirical_plot(data, c(1, 2, 5), smooth = TRUE) empirical_plot(data, c(1, 2, 5), type = 'boxplot')  # replace weird looking items with unscored versions for diagnostics empirical_plot(data, 32) data[,32] <- SAT12[,32] empirical_plot(data, 32) empirical_plot(data, 32, smooth = TRUE)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate the empirical (marginal) reliability — empirical_rxx","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"Given secondary latent trait estimates associated standard errors returned fscores, compute empirical reliability.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"","code":"empirical_rxx(Theta_SE, T_as_X = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"Theta_SE matrix latent trait estimates returned fscores options full.scores = TRUE full.scores.SE = TRUE T_as_X logical; observed variance equal var(X) = var(T) + E(E^2) var(X) = var(T) computing empirical reliability estimates? Default (FALSE) uses former","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"","code":"if (FALSE) { # \\dontrun{  dat <- expand.table(deAyala) itemstats(dat) mod <- mirt(dat)  theta_se <- fscores(mod, full.scores.SE = TRUE) empirical_rxx(theta_se)  theta_se <- fscores(mod, full.scores.SE = TRUE, method = 'ML') empirical_rxx(theta_se) empirical_rxx(theta_se, T_as_X = TRUE)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Empirical Estimating Functions — estfun.AllModelClass","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"function extracting empirical estimating functions fitted mirt, multipleGroup, bfactor, mdirt model. derivative log-likelihood respect parameter vector, evaluated observed (case-wise) data. words, function returns case-wise scores, evaluated fitted model parameters. Currently, models fitted via EM BL method supported. computations, internal Theta grid model used already used estimation model along matching normalized density.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"","code":"estfun.AllModelClass(   x,   weights = extract.mirt(x, \"survey.weights\"),   centering = FALSE )"},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"x fitted model object class SingleGroupClass, MultipleGroupClass, DiscreteClass weights default, survey.weights (optionally) specified fitting model included calculate scores. specified user, numeric vector length equal total sample size. Note cases weighted equally fitting model, weights must corrected taking square root scores used compute outer product gradients (OPG) estimate variance-covariance matrix (see examples ). centering boolean variable allows centering case-wise scores (.e., setting expected values 0). case-wise scores obtained maximum likelihood estimates, setting affect result.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"n x k matrix corresponding n observations k parameters","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"Lennart Schneider lennart.sch@web.de Phil Chalmers; centering argument contributed Rudolf Debelak (rudolf.debelak@psychologie.uzh.ch)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"","code":"if (FALSE) { # \\dontrun{ # fit a 2PL on the LSAT7 data and get the scores mod1 <- mirt(expand.table(LSAT7), 1, SE = TRUE, SE.type = \"crossprod\") sc1 <- estfun.AllModelClass(mod1) # get the gradient colSums(sc1) # calculate the OPG estimate of the variance-covariance matrix \"by hand\" vc1 <- vcov(mod1) all.equal(crossprod(sc1), chol2inv(chol(vc1)), check.attributes = FALSE)  # Discrete group modd <- mdirt(expand.table(LSAT7), 2, SE = TRUE, SE.type = \"crossprod\") sc1 <- estfun.AllModelClass(modd) # get the gradient colSums(sc1) # calculate the OPG estimate of the variance-covariance matrix \"by hand\" vc1 <- vcov(modd) all.equal(crossprod(sc1), chol2inv(chol(vc1)), check.attributes = FALSE)  # fit a multiple group 2PL and do the same as above group <- rep(c(\"G1\", \"G2\"), 500) mod2 <- multipleGroup(expand.table(LSAT7), 1, group, SE = TRUE,   SE.type = \"crossprod\") sc2 <- estfun.AllModelClass(mod2) colSums(sc2) vc2 <- vcov(mod2) all.equal(crossprod(sc2), chol2inv(chol(vc2)), check.attributes = FALSE)  # fit a bifactor model with 2 specific factors and do the same as above mod3 <- bfactor(expand.table(LSAT7), c(2, 2, 1, 1, 2), SE = TRUE,   SE.type = \"crossprod\") sc3 <- estfun.AllModelClass(mod3) colSums(sc3) vc3 <- vcov(mod3) all.equal(crossprod(sc3), chol2inv(chol(vc3)), check.attributes = FALSE)  # fit a 2PL not weighting all cases equally survey.weights <- c(rep(2, sum(LSAT7$freq) / 2), rep(1, sum(LSAT7$freq) / 2)) survey.weights <- survey.weights / sum(survey.weights) * sum(LSAT7$freq) mod4 <- mirt(expand.table(LSAT7), 1, SE = TRUE, SE.type = \"crossprod\",   survey.weights = survey.weights) sc4 <- estfun.AllModelClass(mod4,   weights = extract.mirt(mod4, \"survey.weights\")) # get the gradient colSums(sc4) # to calculate the OPG estimate of the variance-covariance matrix \"by hand\", # the weights must be adjusted by taking their square root sc4_crp <- estfun.AllModelClass(mod4,   weights = sqrt(extract.mirt(mod4, \"survey.weights\"))) vc4 <- vcov(mod4) all.equal(crossprod(sc4_crp), chol2inv(chol(vc4)), check.attributes = FALSE)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand summary table of patterns and frequencies — expand.table","title":"Expand summary table of patterns and frequencies — expand.table","text":"expand.table function expands summary table unique response patterns full sized data-set. default response frequencies assumed rightmost column input data, though can modified.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand summary table of patterns and frequencies — expand.table","text":"","code":"expand.table(tabdata, freq = colnames(tabdata)[ncol(tabdata)], sample = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand summary table of patterns and frequencies — expand.table","text":"tabdata object class data.frame matrix unique response patterns number frequencies rightmost column (though see freq details omit column) freq either character vector specifying column tabdata used frequency count indicator response pattern (defaults right-column) integer vector length nrow(tabdata) specifying frequency counts. using latter approach tabdata input include information regarding counts, instead include unique response patterns sample logical; randomly switch rows expanded table? change expanded data, row locations","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand summary table of patterns and frequencies — expand.table","text":"Returns numeric matrix response patterns.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Expand summary table of patterns and frequencies — expand.table","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Expand summary table of patterns and frequencies — expand.table","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand summary table of patterns and frequencies — expand.table","text":"","code":"data(LSAT7) head(LSAT7) # frequency in right-most column #>   Item.1 Item.2 Item.3 Item.4 Item.5 freq #> 1      0      0      0      0      0   12 #> 2      0      0      0      0      1   19 #> 3      0      0      0      1      0    1 #> 4      0      0      0      1      1    7 #> 5      0      0      1      0      0    3 #> 6      0      0      1      0      1   19 LSAT7full <- expand.table(LSAT7) head(LSAT7full) #>   Item.1 Item.2 Item.3 Item.4 Item.5 #> 1      0      0      0      0      0 #> 2      0      0      0      0      0 #> 3      0      0      0      0      0 #> 4      0      0      0      0      0 #> 5      0      0      0      0      0 #> 6      0      0      0      0      0 dim(LSAT7full) #> [1] 1000    5  # randomly switch rows in the expanded response table LSAT7samp <- expand.table(LSAT7, sample = TRUE) head(LSAT7samp) #>   Item.1 Item.2 Item.3 Item.4 Item.5 #> 1      1      0      0      0      0 #> 2      1      0      1      1      1 #> 3      1      1      0      0      1 #> 4      0      0      1      1      0 #> 5      1      1      0      1      1 #> 6      1      1      1      1      1 colMeans(LSAT7full) #> Item.1 Item.2 Item.3 Item.4 Item.5  #>  0.828  0.658  0.772  0.606  0.843  colMeans(LSAT7samp) #equal #> Item.1 Item.2 Item.3 Item.4 Item.5  #>  0.828  0.658  0.772  0.606  0.843   #--------  if (FALSE) { # \\dontrun{ # Generate data from separate response pattern matrix and freq vector # The following uses Table 2.1 from de Ayala (2009) f <- c(691,2280,242,235,158,184,1685,1053,134,462,92,65,571,79,87,41,1682,702,        370,63,626,412,166,52,28,15,2095,1219,500,187,40,3385)  pat <- matrix(c(    0, 0, 0, 0, 0,    1, 0, 0, 0, 0,    0, 1, 0, 0, 0,    0, 0, 1, 0, 0,    0, 0, 0, 1, 0,    0, 0, 0, 0, 1,    1, 1, 0, 0, 0,    1, 0, 1, 0, 0,    0, 1, 1, 0, 0,    1, 0, 0, 1, 0,    0, 1, 0, 1, 0,    0, 0, 1, 1, 0,    1, 0, 0, 0, 1,    0, 1, 0, 0, 1,    0, 0, 1, 0, 1,    0, 0, 0, 1, 1,    1, 1, 1, 0, 0,    1, 1, 0, 1, 0,    1, 0, 1, 1, 0,    0, 1, 1, 1, 0,    1, 1, 0, 0, 1,    1, 0, 1, 0, 1,    1, 0, 0, 1, 1,    0, 1, 1, 0, 1,    0, 1, 0, 1, 1,    0, 0, 1, 1, 1,    1, 1, 1, 1, 0,    1, 1, 1, 0, 1,    1, 1, 0, 1, 1,    1, 0, 1, 1, 1,    0, 1, 1, 1, 1,    1, 1, 1, 1, 1), ncol=5, byrow=TRUE)  colnames(pat) <- paste0('Item.', 1:5) head(pat)  table2.1 <- expand.table(pat, freq = f) dim(table2.1)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate expected value of item — expected.item","title":"Function to calculate expected value of item — expected.item","text":"Given internal mirt object extracted estimated model compute expected value item given ability parameter(s).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate expected value of item — expected.item","text":"","code":"expected.item(x, Theta, min = 0, include.var = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate expected value of item — expected.item","text":"x extracted internal mirt object containing item information (see extract.item) Theta vector (unidimensional) matrix (multidimensional) latent trait values min constant value added expected values indicating lowest theoretical category. Default 0 include.var logical; include model-implied variance expected scores well? TRUE return list containing expected values (E) variances (VAR)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate expected value of item — expected.item","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate expected value of item — expected.item","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate expected value of item — expected.item","text":"","code":"mod <- mirt(Science, 1) #>  Iteration: 1, Log-Lik: -1629.361, Max-Change: 0.50660 Iteration: 2, Log-Lik: -1617.374, Max-Change: 0.25442 Iteration: 3, Log-Lik: -1612.894, Max-Change: 0.16991 Iteration: 4, Log-Lik: -1610.306, Max-Change: 0.10461 Iteration: 5, Log-Lik: -1609.814, Max-Change: 0.09162 Iteration: 6, Log-Lik: -1609.534, Max-Change: 0.07363 Iteration: 7, Log-Lik: -1609.030, Max-Change: 0.03677 Iteration: 8, Log-Lik: -1608.988, Max-Change: 0.03200 Iteration: 9, Log-Lik: -1608.958, Max-Change: 0.02754 Iteration: 10, Log-Lik: -1608.878, Max-Change: 0.01443 Iteration: 11, Log-Lik: -1608.875, Max-Change: 0.00847 Iteration: 12, Log-Lik: -1608.873, Max-Change: 0.00515 Iteration: 13, Log-Lik: -1608.872, Max-Change: 0.00550 Iteration: 14, Log-Lik: -1608.872, Max-Change: 0.00318 Iteration: 15, Log-Lik: -1608.871, Max-Change: 0.00462 Iteration: 16, Log-Lik: -1608.871, Max-Change: 0.00277 Iteration: 17, Log-Lik: -1608.870, Max-Change: 0.00145 Iteration: 18, Log-Lik: -1608.870, Max-Change: 0.00175 Iteration: 19, Log-Lik: -1608.870, Max-Change: 0.00126 Iteration: 20, Log-Lik: -1608.870, Max-Change: 0.00025 Iteration: 21, Log-Lik: -1608.870, Max-Change: 0.00285 Iteration: 22, Log-Lik: -1608.870, Max-Change: 0.00108 Iteration: 23, Log-Lik: -1608.870, Max-Change: 0.00022 Iteration: 24, Log-Lik: -1608.870, Max-Change: 0.00059 Iteration: 25, Log-Lik: -1608.870, Max-Change: 0.00014 Iteration: 26, Log-Lik: -1608.870, Max-Change: 0.00068 Iteration: 27, Log-Lik: -1608.870, Max-Change: 0.00065 Iteration: 28, Log-Lik: -1608.870, Max-Change: 0.00019 Iteration: 29, Log-Lik: -1608.870, Max-Change: 0.00061 Iteration: 30, Log-Lik: -1608.870, Max-Change: 0.00012 Iteration: 31, Log-Lik: -1608.870, Max-Change: 0.00012 Iteration: 32, Log-Lik: -1608.870, Max-Change: 0.00058 Iteration: 33, Log-Lik: -1608.870, Max-Change: 0.00055 Iteration: 34, Log-Lik: -1608.870, Max-Change: 0.00015 Iteration: 35, Log-Lik: -1608.870, Max-Change: 0.00052 Iteration: 36, Log-Lik: -1608.870, Max-Change: 0.00010 extr.2 <- extract.item(mod, 2) Theta <- matrix(seq(-6,6, length.out=200)) expected <- expected.item(extr.2, Theta, min(Science[,1])) #min() of first item head(data.frame(expected, Theta=Theta)) #>   expected     Theta #> 1 1.013391 -6.000000 #> 2 1.014407 -5.939698 #> 3 1.015498 -5.879397 #> 4 1.016672 -5.819095 #> 5 1.017933 -5.758794 #> 6 1.019289 -5.698492  expected.item(extr.2, Theta, min(Science[,1]), include.var=TRUE) #> $E #>   [1] 1.013391 1.014407 1.015498 1.016672 1.017933 1.019289 1.020744 1.022308 #>   [9] 1.023988 1.025791 1.027727 1.029805 1.032035 1.034427 1.036992 1.039742 #>  [17] 1.042690 1.045848 1.049231 1.052853 1.056729 1.060875 1.065309 1.070047 #>  [25] 1.075108 1.080511 1.086276 1.092422 1.098971 1.105943 1.113361 1.121247 #>  [33] 1.129622 1.138510 1.147932 1.157911 1.168469 1.179625 1.191402 1.203817 #>  [41] 1.216889 1.230634 1.245068 1.260201 1.276046 1.292610 1.309898 1.327913 #>  [49] 1.346654 1.366117 1.386296 1.407180 1.428756 1.451008 1.473916 1.497459 #>  [57] 1.521611 1.546346 1.571635 1.597448 1.623754 1.650519 1.677712 1.705300 #>  [65] 1.733251 1.761532 1.790113 1.818965 1.848058 1.877365 1.906859 1.936516 #>  [73] 1.966312 1.996222 2.026225 2.056299 2.086421 2.116571 2.146726 2.176865 #>  [81] 2.206964 2.237001 2.266952 2.296794 2.326501 2.356050 2.385416 2.414575 #>  [89] 2.443504 2.472180 2.500583 2.528693 2.556494 2.583970 2.611109 2.637904 #>  [97] 2.664348 2.690439 2.716178 2.741571 2.766624 2.791350 2.815763 2.839881 #> [105] 2.863722 2.887310 2.910668 2.933821 2.956795 2.979616 3.002311 3.024906 #> [113] 3.047424 3.069889 3.092321 3.114739 3.137157 3.159587 3.182039 3.204516 #> [121] 3.227018 3.249541 3.272079 3.294617 3.317140 3.339628 3.362056 3.384398 #> [129] 3.406624 3.428701 3.450594 3.472269 3.493688 3.514816 3.535615 3.556050 #> [137] 3.576087 3.595693 3.614838 3.633495 3.651638 3.669246 3.686301 3.702787 #> [145] 3.718692 3.734007 3.748728 3.762852 3.776380 3.789316 3.801665 3.813436 #> [153] 3.824638 3.835286 3.845391 3.854970 3.864039 3.872615 3.880715 3.888358 #> [161] 3.895562 3.902347 3.908731 3.914733 3.920370 3.925662 3.930626 3.935280 #> [169] 3.939639 3.943720 3.947540 3.951112 3.954452 3.957572 3.960487 3.963208 #> [177] 3.965749 3.968118 3.970329 3.972390 3.974312 3.976102 3.977771 3.979325 #> [185] 3.980773 3.982120 3.983375 3.984543 3.985630 3.986642 3.987583 3.988458 #> [193] 3.989273 3.990030 3.990735 3.991390 3.991999 3.992565 3.993092 3.993581 #>  #> $VAR #>   [1] 1.016618 1.017866 1.019207 1.020645 1.022188 1.023843 1.025618 1.027521 #>   [9] 1.029559 1.031743 1.034082 1.036585 1.039263 1.042127 1.045188 1.048457 #>  [17] 1.051948 1.055673 1.059644 1.063876 1.068380 1.073172 1.078265 1.083673 #>  [25] 1.089410 1.095488 1.101921 1.108722 1.115902 1.123471 1.131439 1.139814 #>  [33] 1.148602 1.157807 1.167431 1.177473 1.187930 1.198794 1.210054 1.221698 #>  [41] 1.233706 1.246057 1.258724 1.271677 1.284881 1.298297 1.311884 1.325594 #>  [49] 1.339380 1.353188 1.366966 1.380659 1.394211 1.407567 1.420673 1.433478 #>  [57] 1.445931 1.457987 1.469604 1.480744 1.491375 1.501468 1.511003 1.519961 #>  [65] 1.528331 1.536103 1.543274 1.549843 1.555812 1.561184 1.565964 1.570157 #>  [73] 1.573769 1.576804 1.579266 1.581159 1.582485 1.583244 1.583437 1.583064 #>  [81] 1.582126 1.580625 1.578563 1.575947 1.572785 1.569088 1.564875 1.560165 #>  [89] 1.554985 1.549365 1.543342 1.536957 1.530255 1.523285 1.516100 1.508754 #>  [97] 1.501305 1.493809 1.486322 1.478902 1.471600 1.464468 1.457551 1.450890 #> [105] 1.444522 1.438478 1.432779 1.427443 1.422479 1.417891 1.413671 1.409809 #> [113] 1.406285 1.403072 1.400140 1.397448 1.394955 1.392612 1.390368 1.388168 #> [121] 1.385957 1.383677 1.381273 1.378688 1.375872 1.372773 1.369347 1.365556 #> [129] 1.361365 1.356749 1.351687 1.346169 1.340189 1.333753 1.326870 1.319558 #> [137] 1.311842 1.303752 1.295323 1.286593 1.277605 1.268404 1.259035 1.249544 #> [145] 1.239978 1.230381 1.220797 1.211267 1.201828 1.192517 1.183365 1.174401 #> [153] 1.165650 1.157134 1.148870 1.140874 1.133157 1.125728 1.118592 1.111753 #> [161] 1.105213 1.098969 1.093021 1.087362 1.081989 1.076893 1.072068 1.067505 #> [169] 1.063195 1.059129 1.055297 1.051689 1.048296 1.045106 1.042112 1.039302 #> [177] 1.036667 1.034199 1.031887 1.029723 1.027699 1.025807 1.024039 1.022387 #> [185] 1.020845 1.019406 1.018063 1.016810 1.015642 1.014553 1.013539 1.012593 #> [193] 1.011713 1.010892 1.010129 1.009418 1.008756 1.008140 1.007567 1.007034 #>"},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate expected test score — expected.test","title":"Function to calculate expected test score — expected.test","text":"Given estimated model compute expected test score. Returns expected values form data used estimate model.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate expected test score — expected.test","text":"","code":"expected.test(   x,   Theta,   group = NULL,   mins = TRUE,   individual = FALSE,   which.items = NULL,   probs.only = FALSE )"},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate expected test score — expected.test","text":"x estimated mirt object Theta matrix latent trait values (vector supplied, coerced matrix one column) group number character signifying group item extracted (applies 'MultipleGroupClass' objects ) mins logical; include minimum value constants dataset. FALSE, expected values item determined scoring 0:(ncat-1) individual logical; return tracelines individual items? .items integer vector indicating items include expected test score. Default uses possible items probs.logical; return probability category instead traceline score functions? useful individual=TRUE","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate expected test score — expected.test","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate expected test score — expected.test","text":"","code":"if (FALSE) { # \\dontrun{ dat <- expand.table(deAyala) model <- 'F = 1-5           CONSTRAIN = (1-5, a1)' mod <- mirt(dat, model)  Theta <- matrix(seq(-6,6,.01)) tscore <- expected.test(mod, Theta) tail(cbind(Theta, tscore))  # use only first two items (i.e., a bundle) bscore <- expected.test(mod, Theta, which.items = 1:2) tail(cbind(Theta, bscore))  # more low-level output (score and probabilty elements) expected.test(mod, Theta, individual=TRUE) expected.test(mod, Theta, individual=TRUE, probs.only=TRUE)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract a group from a multiple group mirt object — extract.group","title":"Extract a group from a multiple group mirt object — extract.group","text":"Extract single group object defined multipleGroup.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract a group from a multiple group mirt object — extract.group","text":"","code":"extract.group(x, group)"},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract a group from a multiple group mirt object — extract.group","text":"x mirt model class 'MultipleGroupClass' group name group extract","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract a group from a multiple group mirt object — extract.group","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract a group from a multiple group mirt object — extract.group","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract a group from a multiple group mirt object — extract.group","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N)) models <- 'F1 = 1-15'  mod_configural <- multipleGroup(dat, models, group = group) group.1 <- extract.group(mod_configural, 'D1') #extract first group summary(group.1) plot(group.1) } # }"},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract an item object from mirt objects — extract.item","title":"Extract an item object from mirt objects — extract.item","text":"Extract internal mirt objects estimated model.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract an item object from mirt objects — extract.item","text":"","code":"extract.item(x, item, group = NULL, drop.zeros = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract an item object from mirt objects — extract.item","text":"x mirt model class 'SingleGroupClass' 'MultipleGroupClass' item number character signifying item extract group number signifying group item extracted (applies 'MultipleGroupClass' ) drop.zeros logical; drop slope values numerically close zero reduce dimensionality? Useful objects returned bfactor confirmatory models contain several zero slopes","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract an item object from mirt objects — extract.item","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract an item object from mirt objects — extract.item","text":"","code":"if (FALSE) { # \\dontrun{ mod <- mirt(Science, 1) extr.1 <- extract.item(mod, 1) } # }"},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract various elements from estimated model objects — extract.mirt","title":"Extract various elements from estimated model objects — extract.mirt","text":"generic function extract internal objects estimated models.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract various elements from estimated model objects — extract.mirt","text":"","code":"extract.mirt(x, what, item = 1)"},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract various elements from estimated model objects — extract.mirt","text":"x mirt model class 'SingleGroupClass', 'MultipleGroupClass', 'MixedClass' 'DiscreteGroupClass' string indicating extract item necessary, item extract information . Defaults 1 specified","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract various elements from estimated model objects — extract.mirt","text":"Objects can extracted mirt objects include: logLik observed log-likelihood logPrior log term contributed prior parameter distributions G2 goodness fit statistic df degrees freedom p p-value G2 statistic RMSEA root mean-square error approximation based G2 CFI CFI fit statistic TLI TLI fit statistic AIC AIC BIC BIC SABIC sample size adjusted BIC HQ HQ F unrotated standardized loadings matrix h2 factor communality estimates LLhistory EM log-likelihood history tabdata tabular version raw response data input. Frequencies stored     freq freq frequencies associated tabdata K integer vector indicating number unique elements item mins integer vector indicating lowest category found input data model input model syntax method estimation method used itemtype vector item types respective item (e.g., 'graded', '2PL', etc) itemnames vector item names input data factorNames vector factor names model definition rowID integer vector indicating valid row numbers used model estimation    (cases used 1:nrow(data)) data raw input data item responses covdata raw input data data used covariates tabdatalong similar tabdata, however responses transformed     dummy coded variables fulldatalong analogous tabdatafull, raw input data instead     tabulated frequencies EMhistory saved, extract EM iteration history exp_resp expected probability unique response patterns survey.weights supplied, vector survey weights used estimation (NULL missing) converged logical value indicating whether model terminated within     convergence criteria iterations number iterations took reach convergence criteria nest number freely estimated parameters parvec vector containing uniquely estimated parameters vcov parameter covariance matrix (associated parvec) condnum condition number Hessian (computed). Otherwise NA constrain list item parameter constraints indicate item parameters equal     estimation Prior prior density distribution latent traits thetaPosterior posterior distribution latent traits using EM algorithm key supplied, data scoring key nfact number latent traits/factors nitems number items ngroups number groups groupNames character vector unique group names group character vector indicating group membership invariance character vector indicating invariance input multipleGroup secondordertest logical indicating whether model passed second-order test     based Hessian matrix. Indicates whether model potential local maximum solution SEMconv logical; check whether supplemented EM information matrix converged. NA     applicable time estimation time, broken different sections","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract various elements from estimated model objects — extract.mirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract various elements from estimated model objects — extract.mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract various elements from estimated model objects — extract.mirt","text":"","code":"if (FALSE) { # \\dontrun{ mod <- mirt(Science, 1)  extract.mirt(mod, 'logLik') extract.mirt(mod, 'F')  #multiple group model grp <- rep(c('G1', 'G2'), each = nrow(Science)/2) mod2 <- multipleGroup(Science, 1, grp)  grp1 <- extract.group(mod2, 1) #extract single group model extract.mirt(mod2, 'parvec') extract.mirt(grp1, 'parvec')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":null,"dir":"Reference","previous_headings":"","what":"Fixed-item calibration method — fixedCalib","title":"Fixed-item calibration method — fixedCalib","text":"Implements set fixed-item calibration methods described Kim (2006). initial calibrated model must fitted via mirt, currently limited unidimensional models , utilized new set responses obtained population similar distributional characteristics latent traits. flexible calibration items, including fixed-item calibration variant involving anchor items equating, see multipleGroup.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fixed-item calibration method — fixedCalib","text":"","code":"fixedCalib(   data,   model = 1,   old_mod,   PAU = \"MWU\",   NEMC = \"MEM\",   technical = list(),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fixed-item calibration method — fixedCalib","text":"data new data used calibration. Note consistent mod object, observed responses/NA placeholders must included link item names used original mod definition (.e., extract.mirt(mod, = 'itemnames')) model type model fit complete dataset (fixed items old_mod factor loadings/constraints specified potential mirt.model specification relevant) old_mod model class SingleGroupClass fitted using mirt PAU prior ability update (PAU) approach. Supports none (\"NWU\"), one (\"OWU\"), many (\"MWU\") NEMC number EM cycles (NEMC) use --estimated parameters. Supports one (\"OEM\") many (\"MEM\") technical list technical estimation arguments (see mirt details) ... additional arguments pass mirt","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fixed-item calibration method — fixedCalib","text":"Kim, S. (2006). comparative study IRT fixed parameter calibration methods. Journal Educational Measurement, 4(43), 355-381.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fixed-item calibration method — fixedCalib","text":"","code":"if (FALSE) { # \\dontrun{  # single factor set.seed(12345) J <- 50 a <- matrix(abs(rnorm(J,1,.3)), ncol=1) d <- matrix(rnorm(J,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a))  # calibration data theta ~ N(0,1) N <- 3000 dataset1 <- simdata(a, d, N = N, itemtype=itemtype)  # new data (again, theta ~ N(0,1)) dataset2 <- simdata(a, d, N = 1000, itemtype=itemtype)  # last 40% of experimental items not given to calibration group #     (unobserved; hence removed) dataset1 <- dataset1[,-c(J:(J*.6))] head(dataset1)  #--------------------------------------  # calibrated model from dataset1 only mod <- mirt(dataset1, model = 1) coef(mod, simplify=TRUE)  # No Prior Weights Updating and One EM Cycle (NWU-OEM) NWU_OEM <- fixedCalib(dataset2, model=1, old_mod=mod, PAU='NWU', NEMC='OEM') coef(NWU_OEM, simplify=TRUE) data.frame(coef(NWU_OEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) plot(NWU_OEM, type = 'empiricalhist')  # No Prior Weights Updating and Multiple EM Cycles (NWU-MEM) NWU_MEM <- fixedCalib(dataset2, model = 1, old_mod = mod, PAU = 'NWU') coef(NWU_MEM, simplify=TRUE) data.frame(coef(NWU_MEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) plot(NWU_MEM, type = 'empiricalhist')  # One Prior Weights Updating and One EM Cycle (OWU-OEM) OWU_OEM <- fixedCalib(dataset2, model=1, old_mod=mod, PAU='OWU', NEMC=\"OEM\") coef(OWU_OEM, simplify=TRUE) data.frame(coef(OWU_OEM, simplify=TRUE)$items[,c('a1','d')], pop_a1=a, pop_d=d) plot(OWU_OEM, type = 'empiricalhist')  # One Prior Weights Updating and Multiple EM Cycles (OWU-MEM) OWU_MEM <- fixedCalib(dataset2, model = 1, old_mod = mod, PAU = 'OWU') coef(OWU_MEM, simplify=TRUE) data.frame(coef(OWU_MEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) plot(OWU_MEM, type = 'empiricalhist')  # Multiple Prior Weights Updating and Multiple EM Cycles (MWU-MEM) MWU_MEM <- fixedCalib(dataset2, model = 1, old_mod = mod) coef(MWU_MEM, simplify=TRUE) data.frame(coef(MWU_MEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) plot(MWU_MEM, type = 'empiricalhist')  # factor scores distribution check fs <- fscores(MWU_MEM) hist(fs) c(mean_calib=mean(fs[1:N, ]), sd_calib=sd(fs[1:N, ])) c(mean_exper=mean(fs[-c(1:N), ]), sd_exper=sd(fs[-c(1:N), ]))   ############################ ## Item length constraint example for each participant in the experimental ## items group. In this example, all participants were forced to have a test ## length of J=30, though the item pool had J=50 total items.  # new experimental data (relatively extreme, theta ~ N(.5,1.5)) dataset2 <- simdata(a, d, N = 1000, itemtype=itemtype,     mu=.5, sigma=matrix(1.5))  # Add missing values to each participant in new dataset where individuals # were randomly administered 10 experimental items, subject to the constraint # that each participant received a test with J=30 items. dataset2 <- t(apply(dataset2, 1, function(x){    NA_precalib <- sample(1:30, 10)    NA_experimental <- sample(31:50, 10)    x[c(NA_precalib, NA_experimental)] <- NA    x })) head(dataset2)  # check that all individuals had 30 items all(rowSums(!is.na(dataset2)) == 30)  # Multiple Prior Weights Updating and Multiple EM Cycles (MWU-MEM) MWU_MEM <- fixedCalib(dataset2, model = 1, old_mod = mod) coef(MWU_MEM, simplify=TRUE) data.frame(coef(MWU_MEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) plot(MWU_MEM, type = 'empiricalhist')  ## factor scores check fs <- fscores(MWU_MEM) hist(fs) c(mean_calib=mean(fs[1:N, ]), sd_calib=sd(fs[1:N, ]))  ## shrinkage, but generally different from calibrated sample c(mean_exper=mean(fs[-c(1:N), ]), sd_exper=sd(fs[-c(1:N), ]))   } # }"},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute latent regression fixed effect expected values — fixef","title":"Compute latent regression fixed effect expected values — fixef","text":"Create expected values fixed effects parameters latent regression models.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute latent regression fixed effect expected values — fixef","text":"","code":"fixef(x)"},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute latent regression fixed effect expected values — fixef","text":"x estimated model object mixedmirt mirt function","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute latent regression fixed effect expected values — fixef","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models MH-RM Algorithm. Journal Educational Measurement, 52, 200-222. doi:10.1111/jedm.12072","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute latent regression fixed effect expected values — fixef","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute latent regression fixed effect expected values — fixef","text":"","code":"if (FALSE) { # \\dontrun{  #simulate data set.seed(1234) N <- 1000  # covariates X1 <- rnorm(N); X2 <- rnorm(N) covdata <- data.frame(X1, X2) Theta <- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))  #items and response data a <- matrix(1, 20); d <- matrix(rnorm(20)) dat <- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)  #conditional model using X1 and X2 as predictors of Theta mod1 <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2)  #latent regression fixed effects (i.e., expected values) fe <- fixef(mod1) head(fe)  # with mixedmirt() mod1b <- mixedmirt(dat, covdata, 1, lr.fixed = ~ X1 + X2, fixed = ~ 0 + items) fe2 <- fixef(mod1b) head(fe2)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"Computes MAP, EAP, ML (Embretson & Reise, 2000), EAP sum-scores (Thissen et al., 1995), WLE (Warm, 1989) factor scores multivariate normal prior distribution using equally spaced quadrature. EAP scores models three factors generally recommended since integration grid becomes large, resulting slower estimation less precision quadpts low. Therefore, MAP scores used instead EAP scores higher dimensional models. Multiple imputation variants possible estimator parameter information matrix computed, useful sample size/number items small. well, model contained latent regression predictors information used computing MAP EAP estimates (models, full.scores=TRUE always used). Finally, plausible value imputation also available, also account latent regression predictor effects.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"","code":"fscores(   object,   method = \"EAP\",   full.scores = TRUE,   rotate = \"oblimin\",   Target = NULL,   response.pattern = NULL,   append_response.pattern = FALSE,   na.rm = FALSE,   plausible.draws = 0,   plausible.type = \"normal\",   quadpts = NULL,   item_weights = rep(1, extract.mirt(object, \"nitems\")),   returnER = FALSE,   T_as_X = FALSE,   EAPsum.scores = FALSE,   return.acov = FALSE,   mean = NULL,   cov = NULL,   covdata = NULL,   verbose = TRUE,   full.scores.SE = FALSE,   theta_lim = c(-6, 6),   MI = 0,   use_dentype_estimate = FALSE,   QMC = FALSE,   custom_den = NULL,   custom_theta = NULL,   min_expected = 1,   max_theta = 20,   start = NULL,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"object computed model object class SingleGroupClass, MultipleGroupClass, DiscreteClass method type factor score estimation method. Can : \"EAP\" expected -posteriori (default). models fit using       mdirt return posterior classification probabilities \"MAP\" maximum -posteriori (.e, Bayes modal) \"ML\" maximum likelihood \"WLE\" weighted likelihood estimation \"EAPsum\" expected -posteriori sum score \"plausible\" single plausible value imputation case.       equivalent setting plausible.draws = 1 \"classify\" posteriori classification probabilities (      applicable input model class MixtureClass) full.scores FALSE summary table factor scores unique pattern displayed formatted matrix object. Otherwise, matrix factor scores response pattern data returned (default) rotate prior rotation used estimating factor scores. See summary-method details. object exploratory model argument ignored Target target rotation; see summary-method details response.pattern optional argument used calculate factor scores standard errors given response vector matrix/data.frame append_response.pattern logical; inputs response.pattern also appended factor score output? na.rm logical; remove rows missing values? generally required due nature computing factors scores, however \"EAPsum\" method may necessary ensure sum-scores correspond composite score plausible.draws number plausible values draw future researchers perform secondary analyses latent trait scores. Typically used conjunction latent regression predictors (see mirt details), can also generated predictor variables modelled. plausible.draws greater 0 list plausible values returned plausible.type type plausible values obtain. Can either 'normal' (default) use normal approximation based ACOV matrix, 'MH' obtain Metropolis-Hastings samples posterior (silently passes object mirt, therefore arguments like technical can supplied increase number burn-draws discarded samples) quadpts number quadrature use per dimension. specified, suitable one created decreases number dimensions increases (therefore estimates EAP, less accurate). determined switch statement quadpts <- switch(.character(nfact), '1'=121, '2'=61, '3'=31, '4'=19, '5'=11, '6'=7, 5) item_weights user-defined weight vector used likelihood expressions add /less weight given observed response. Default vector 1's, indicating items receive weight returnER logical; return empirical reliability (also known marginal reliability) estimates numeric values? T_as_X logical; observed variance equal var(X) = var(T) + E(E^2) var(X) = var(T) computing empirical reliability estimates? Default (FALSE) uses former EAPsum.scores logical; include model-implied expected values variance item total scores using method = 'EAPsum' full.scores=FALSE? information included hidden 'fit' attribute can extracted via attr(., 'fit') later use return.acov logical; return list containing covariance matrices instead factors scores? impute = TRUE supported option mean vector custom latent variable means. NULL, default 'group' values computed mirt object used cov custom matrix latent variable covariance matrix. NULL, default 'group' values computed mirt object used covdata latent regression model fitted, response.pattern input used score individuals, argument used include latent regression covariate terms row vector supplied response.pattern verbose logical; print verbose output messages? full.scores.SE logical; full.scores == TRUE, also return standard errors associated respondent? Default FALSE theta_lim lower upper range evaluate latent trait integral dimension. omitted, range generated automatically based number dimensions MI number indicating many multiple imputation draws perform. Default 0, indicating MI draws performed use_dentype_estimate logical; density latent trait estimated model (e.g., via Davidian curves empirical histograms), information used compute latent trait estimates? applicable EAP-based estimates (EAP, EAPsum, plausible) QMC logical; use quasi-Monte Carlo integration? quadpts omitted default number nodes 5000 custom_den function used define integration density (required). NULL default   assumes multivariate normal distribution 'GroupPars' hyper-parameters   used. minimum must form: function(Theta, ...) Theta matrix latent trait values (grid values   method == 'EAPsum' method == 'EAP', otherwise Theta 1 row).   Additional arguments may included caught fscores(...) input.   function must return numeric vector density weights (one row Theta) custom_theta matrix custom integration nodes use instead default, column corresponds respective dimension model min_expected computing goodness fit tests method = 'EAPsum', value used collapse across conditioned total scores expected values greater value. Note affect goodness fit tests returned EAP sum scores table max_theta maximum/minimum value given factor score estimate achieve using modal estimator method (e.g., MAP, WLE, ML) start matrix starting values use iterative estimation methods. Default start vector 0's response pattern, start EAP estimates (unidimensional models ). Must form matches full.scores = FALSE (mostly used mirtCAT package) ... additional arguments passed nlm","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"function return either table computed scores standard errors, original data matrix scores appended rightmost column, scores . default latent means covariances determined estimated object, though can overwritten. Iterative estimation methods can estimated parallel decrease estimation times mirtCluster object available. input object discrete latent class object estimated mdirt returned results respect posterior classification individual. method inputs 'DiscreteClass' objects may 'EAP', posterior classification response pattern, 'EAPsum' posterior classification based raw sum-score. information algorithms refer mirtCAT package associated JSS paper (Chalmers, 2016).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. (2016). Generating Adaptive Non-Adaptive Test Interfaces Multidimensional Item Response Theory Applications. Journal Statistical Software, 71(5), 1-39. doi:10.18637/jss.v071.i05 Embretson, S. E. & Reise, S. P. (2000). Item Response Theory Psychologists. Erlbaum. Thissen, D., Pommerich, M., Billeaud, K., & Williams, V. S. L. (1995). Item Response Theory Scores Tests Including Polytomous Items Ordered Responses. Applied Psychological Measurement, 19, 39-49. Warm, T. . (1989). Weighted likelihood estimation ability item response theory. Psychometrika, 54, 427-450.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"","code":"mod <- mirt(Science) #>  Iteration: 1, Log-Lik: -1629.361, Max-Change: 0.50660 Iteration: 2, Log-Lik: -1617.374, Max-Change: 0.25442 Iteration: 3, Log-Lik: -1612.894, Max-Change: 0.16991 Iteration: 4, Log-Lik: -1610.306, Max-Change: 0.10461 Iteration: 5, Log-Lik: -1609.814, Max-Change: 0.09162 Iteration: 6, Log-Lik: -1609.534, Max-Change: 0.07363 Iteration: 7, Log-Lik: -1609.030, Max-Change: 0.03677 Iteration: 8, Log-Lik: -1608.988, Max-Change: 0.03200 Iteration: 9, Log-Lik: -1608.958, Max-Change: 0.02754 Iteration: 10, Log-Lik: -1608.878, Max-Change: 0.01443 Iteration: 11, Log-Lik: -1608.875, Max-Change: 0.00847 Iteration: 12, Log-Lik: -1608.873, Max-Change: 0.00515 Iteration: 13, Log-Lik: -1608.872, Max-Change: 0.00550 Iteration: 14, Log-Lik: -1608.872, Max-Change: 0.00318 Iteration: 15, Log-Lik: -1608.871, Max-Change: 0.00462 Iteration: 16, Log-Lik: -1608.871, Max-Change: 0.00277 Iteration: 17, Log-Lik: -1608.870, Max-Change: 0.00145 Iteration: 18, Log-Lik: -1608.870, Max-Change: 0.00175 Iteration: 19, Log-Lik: -1608.870, Max-Change: 0.00126 Iteration: 20, Log-Lik: -1608.870, Max-Change: 0.00025 Iteration: 21, Log-Lik: -1608.870, Max-Change: 0.00285 Iteration: 22, Log-Lik: -1608.870, Max-Change: 0.00108 Iteration: 23, Log-Lik: -1608.870, Max-Change: 0.00022 Iteration: 24, Log-Lik: -1608.870, Max-Change: 0.00059 Iteration: 25, Log-Lik: -1608.870, Max-Change: 0.00014 Iteration: 26, Log-Lik: -1608.870, Max-Change: 0.00068 Iteration: 27, Log-Lik: -1608.870, Max-Change: 0.00065 Iteration: 28, Log-Lik: -1608.870, Max-Change: 0.00019 Iteration: 29, Log-Lik: -1608.870, Max-Change: 0.00061 Iteration: 30, Log-Lik: -1608.870, Max-Change: 0.00012 Iteration: 31, Log-Lik: -1608.870, Max-Change: 0.00012 Iteration: 32, Log-Lik: -1608.870, Max-Change: 0.00058 Iteration: 33, Log-Lik: -1608.870, Max-Change: 0.00055 Iteration: 34, Log-Lik: -1608.870, Max-Change: 0.00015 Iteration: 35, Log-Lik: -1608.870, Max-Change: 0.00052 Iteration: 36, Log-Lik: -1608.870, Max-Change: 0.00010 tabscores <- fscores(mod, full.scores = FALSE) #>  #> Method:  EAP #>  #> Empirical Reliability: #>  #>     F1  #> 0.6666  head(tabscores) #>      Comfort Work Future Benefit         F1     SE_F1 #> [1,]       1    1      1       1 -2.7492669 0.6293525 #> [2,]       1    3      2       1 -1.4198318 0.5772364 #> [3,]       1    4      2       3 -0.7141976 0.6200139 #> [4,]       1    4      3       1 -0.4469265 0.6509531 #> [5,]       2    1      1       1 -2.5437807 0.5909114 #> [6,]       2    1      2       4 -1.2478570 0.5840105  # convert scores into expected total score information with 95% CIs E.total <- expected.test(mod, Theta=tabscores[,'F1']) E.total_2.5 <- expected.test(mod, Theta=tabscores[,'F1'] +                                        tabscores[,'SE_F1'] * qnorm(.05/2)) E.total_97.5 <- expected.test(mod, Theta=tabscores[,'F1'] +                                        tabscores[,'SE_F1'] * qnorm(1-.05/2))  data.frame(Total_score=rowSums(tabscores[,1:4]),            E.total, E.total_2.5, E.total_97.5) |> head() #>   Total_score   E.total E.total_2.5 E.total_97.5 #> 1           4  6.791606    5.321810     9.084082 #> 2           7  9.266018    7.128071    11.296189 #> 3          10 10.584682    8.296461    12.504975 #> 4           9 11.041648    8.691107    13.034195 #> 5           5  7.141179    5.576233     9.330947 #> 6           9  9.592533    7.415339    11.582060  if (FALSE) { # \\dontrun{ fullscores <- fscores(mod) fullscores_with_SE <- fscores(mod, full.scores.SE=TRUE) head(fullscores) head(fullscores_with_SE)  # convert scores into expected total score information with 95% CIs E.total <- expected.test(mod, Theta=fullscores[,'F1']) E.total_2.5 <- expected.test(mod, Theta=fullscores_with_SE[,'F1'] +                                  fullscores_with_SE[,'SE_F1'] * qnorm(.05/2)) E.total_97.5 <- expected.test(mod, Theta=fullscores_with_SE[,'F1'] +                                fullscores_with_SE[,'SE_F1'] * qnorm(1-.05/2))  data.frame(Total_score=rowSums(Science),            E.total, E.total_2.5, E.total_97.5) |> head()  # change method argument to use MAP estimates fullscores <- fscores(mod, method='MAP') head(fullscores)  # calculate MAP for a given response vector fscores(mod, method='MAP', response.pattern = c(1,2,3,4)) # or matrix fscores(mod, method='MAP', response.pattern = rbind(c(1,2,3,4), c(2,2,1,3)))  # return only the scores and their SEs fscores(mod, method='MAP', response.pattern = c(1,2,3,4))  # use custom latent variable properties (diffuse prior for MAP is very close to ML) fscores(mod, method='MAP', cov = matrix(1000), full.scores = FALSE) fscores(mod, method='ML', full.scores = FALSE)  # EAPsum table of values based on total scores (fs <- fscores(mod, method = 'EAPsum', full.scores = FALSE))  # convert expected counts back into marginal probability distribution within(fs,    `P(y)` <- expected / sum(observed))  # list of error VCOV matrices for EAPsum (works for other estimators as well) acovs <- fscores(mod, method = 'EAPsum', full.scores = FALSE, return.acov = TRUE) acovs  # WLE estimation, run in parallel using available cores if(interactive()) mirtCluster() head(fscores(mod, method='WLE', full.scores = FALSE))  # multiple imputation using 30 draws for EAP scores. Requires information matrix mod <- mirt(Science, 1, SE=TRUE) fs <- fscores(mod, MI = 30) head(fs)  # plausible values for future work pv <- fscores(mod, plausible.draws = 5) lapply(pv, function(x) c(mean=mean(x), var=var(x), min=min(x), max=max(x)))  ## define a custom_den function (*must* return a numeric vector). #  EAP with a uniform prior between -3 and 3 fun <- function(Theta, ...) as.numeric(dunif(Theta, min = -3, max = 3)) head(fscores(mod, custom_den = fun))  # compare EAP estimators with same modified prior fun <- function(Theta, ...) as.numeric(dnorm(Theta, mean=.5)) head(fscores(mod, custom_den = fun)) head(fscores(mod, method = 'EAP', mean=.5))  # custom MAP prior: standard truncated normal between 5 and -2 library(msm) # need the :: scope for parallel to see the function (not require if no mirtCluster() defined) fun <- function(Theta, ...) msm::dtnorm(Theta, mean = 0, sd = 1, lower = -2, upper = 5) head(fscores(mod, custom_den = fun, method = 'MAP', full.scores = FALSE))   #################### # scoring via response.pattern input (with latent regression structure) # simulate data set.seed(1234) N <- 1000  # covariates X1 <- rnorm(N); X2 <- rnorm(N) covdata <- data.frame(X1, X2) Theta <- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))  # items and response data a <- matrix(1, 20); d <- matrix(rnorm(20)) dat <- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)  # conditional model using X1 and X2 as predictors of Theta mod <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2) coef(mod, simplify=TRUE)  # all EAP estimates that include latent regression information fs <- fscores(mod, full.scores.SE=TRUE) head(fs)  # score only two response patterns rp <- dat[1:2, ] cd <- covdata[1:2, ]  fscores(mod, response.pattern=rp, covdata=cd) fscores(mod, response.pattern=rp[2,], covdata=cd[2,]) # just one pattern  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized item difficulty summaries — gen.difficulty","title":"Generalized item difficulty summaries — gen.difficulty","text":"Function provides four generalized item difficulty representations polytomous response models described Ali, Chang, Anderson (2015). estimates used gauge difficult polytomous item may .","code":""},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized item difficulty summaries — gen.difficulty","text":"","code":"gen.difficulty(mod, type = \"IRF\", interval = c(-30, 30), ...)"},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized item difficulty summaries — gen.difficulty","text":"mod single factor model estimated mirt type type generalized difficulty parameter report. Can 'IRF' use item response function (default), 'mean' find average difficulty estimates, 'median' median difficulty estimates, 'trimmed' find trimmed mean removing first last difficulty estimates interval interval range search 'IRF' type ... additional arguments pass uniroot","code":""},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized item difficulty summaries — gen.difficulty","text":"Ali, U. S., Chang, H.-H., & Anderson, C. J. (2015). Location indices ordinal polytomous items based item response theory (Research Report . RR-15-20). Princeton, NJ: Educational Testing Service. http://dx.doi.org/10.1002/ets2.12065 Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized item difficulty summaries — gen.difficulty","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized item difficulty summaries — gen.difficulty","text":"","code":"if (FALSE) { # \\dontrun{  mod <- mirt(Science, 1) coef(mod, simplify=TRUE, IRTpars = TRUE)$items  gen.difficulty(mod) gen.difficulty(mod, type = 'mean')  # also works for dichotomous items (though this is unnecessary) dat <- expand.table(LSAT7) mod <- mirt(dat, 1) coef(mod, simplify=TRUE, IRTpars = TRUE)$items  gen.difficulty(mod) gen.difficulty(mod, type = 'mean')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":null,"dir":"Reference","previous_headings":"","what":"Imputing plausible data for missing values — imputeMissing","title":"Imputing plausible data for missing values — imputeMissing","text":"Given estimated model mirt's model fitting functions estimate latent trait, impute plausible missing data values. Returns original data data.frame without NA values. list Theta values supplied list complete datasets returned instead.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Imputing plausible data for missing values — imputeMissing","text":"","code":"imputeMissing(x, Theta, warn = TRUE, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Imputing plausible data for missing values — imputeMissing","text":"x estimated model x mirt package Theta matrix containing estimates latent trait scores (e.g., via fscores) warn logical; print warning messages? ... additional arguments pass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Imputing plausible data for missing values — imputeMissing","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Imputing plausible data for missing values — imputeMissing","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imputing plausible data for missing values — imputeMissing","text":"","code":"if (FALSE) { # \\dontrun{ dat <- expand.table(LSAT7) (original <- mirt(dat, 1)) NAperson <- sample(1:nrow(dat), 20, replace = TRUE) NAitem <- sample(1:ncol(dat), 20, replace = TRUE) for(i in 1:20)     dat[NAperson[i], NAitem[i]] <- NA (mod <- mirt(dat, 1)) scores <- fscores(mod, method = 'MAP')  # re-estimate imputed dataset (good to do this multiple times and average over) fulldata <- imputeMissing(mod, scores) (fullmod <- mirt(fulldata, 1))  # with multipleGroup set.seed(1) group <- sample(c('group1', 'group2'), 1000, TRUE) mod2 <- multipleGroup(dat, 1, group, TOL=1e-2) fs <- fscores(mod2) fulldata2 <- imputeMissing(mod2, fs)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric smoothed regression lines for item response probability functions — itemGAM","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"function uses generalized additive model (GAM) estimate response curves items seem fit well given model. Using stable axillary model, traceline functions poorly fitting dichotomous polytomous items can inspected using point estimates (plausible values) latent trait. Plots tracelines associated standard errors available help interpret misfit. function may also useful adding new items existing, well established set items, especially parametric form items investigation unknown.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"","code":"itemGAM(   item,   Theta,   formula = resp ~ s(Theta, k = 10),   CI = 0.95,   theta_lim = c(-3, 3),   return.models = FALSE,   ... )  # S3 method for class 'itemGAM' plot(   x,   y = NULL,   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"item single poorly fitting item investigated. Can vector matrix Theta list matrix latent trait estimates typically returned fscores formula R formula passed gam function. Default fits spline model 10 nodes. multidimensional models, traits assigned names 'Theta1', 'Theta2', ..., 'ThetaN' CI number ranging 0 1 indicating confidence interval range. Default provides 95 percent interval theta_lim range latent trait scores evaluated return.models logical; return list GAM models category? Useful GAMs inspected directly, also fitting multidimensional models (set TRUE automatically multidimensional models) ... additional arguments passed gam lattice x object class 'itemGAM' y NULL value ignored plotting function par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(10) N <- 1000 J <- 30  a <- matrix(1, J) d <- matrix(rnorm(J)) Theta <- matrix(rnorm(N, 0, 1.5)) dat <- simdata(a, d, N, itemtype = '2PL', Theta=Theta)  # make a bad item ps <- exp(Theta^2 + Theta) / (1 + exp(Theta^2 + Theta)) item1 <- sapply(ps, function(x) sample(c(0,1), size = 1, prob = c(1-x, x)))  ps2 <- exp(2 * Theta^2 + Theta + .5 * Theta^3) / (1 + exp(2 * Theta^2 + Theta + .5 * Theta^3)) item2 <- sapply(ps2, function(x) sample(c(0,1), size = 1, prob = c(1-x, x)))  # how the actual item looks in the population plot(Theta, ps, ylim = c(0,1)) plot(Theta, ps2, ylim = c(0,1))  baditems <- cbind(item1, item2) newdat <- cbind(dat, baditems)  badmod <- mirt(newdat, 1) itemfit(badmod) #clearly a bad fit for the last two items mod <- mirt(dat, 1) #fit a model that does not contain the bad items itemfit(mod)  #### Pure non-parametric way of investigating the items library(KernSmoothIRT) ks <- ksIRT(newdat, rep(1, ncol(newdat)), 1) plot(ks, item=c(1,31,32)) par(ask=FALSE)  # Using point estimates from the model Theta <- fscores(mod) IG0 <- itemGAM(dat[,1], Theta) #good item IG1 <- itemGAM(baditems[,1], Theta) IG2 <- itemGAM(baditems[,2], Theta) plot(IG0) plot(IG1) plot(IG2)  # same as above, but with plausible values to obtain the standard errors set.seed(4321) ThetaPV <- fscores(mod, plausible.draws=10) IG0 <- itemGAM(dat[,1], ThetaPV) #good item IG1 <- itemGAM(baditems[,1], ThetaPV) IG2 <- itemGAM(baditems[,2], ThetaPV) plot(IG0) plot(IG1) plot(IG2)  ## for polytomous test items SAT12[SAT12 == 8] <- NA dat <- key2binary(SAT12,                   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) dat <- dat[,-32] mod <- mirt(dat, 1)  # Kernal smoothing is very sensitive to which category is selected as 'correct' # 5th category as correct ks <- ksIRT(cbind(dat, SAT12[,32]), c(rep(1, 31), 5), 1) plot(ks, items = c(1,2,32))  # 3rd category as correct ks <- ksIRT(cbind(dat, SAT12[,32]), c(rep(1, 31), 3), 1) plot(ks, items = c(1,2,32))  # splines approach Theta <- fscores(mod) IG <- itemGAM(SAT12[,32], Theta) plot(IG)  set.seed(1423) ThetaPV <- fscores(mod, plausible.draws=10) IG2 <- itemGAM(SAT12[,32], ThetaPV) plot(IG2)  # assuming a simple increasing parametric form (like in a standard IRT model) IG3 <- itemGAM(SAT12[,32], Theta, formula = resp ~ Theta) plot(IG3) IG3 <- itemGAM(SAT12[,32], ThetaPV, formula = resp ~ Theta) plot(IG3)  ### multidimensional example by returning the GAM objects mod2 <- mirt(dat, 2) Theta <- fscores(mod2) IG4 <- itemGAM(SAT12[,32], Theta, formula = resp ~ s(Theta1, k=10) + s(Theta2, k=10),    return.models=TRUE) names(IG4) plot(IG4[[1L]], main = 'Category 1') plot(IG4[[2L]], main = 'Category 2') plot(IG4[[3L]], main = 'Category 3')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Item fit statistics — itemfit","title":"Item fit statistics — itemfit","text":"Computes item-fit statistics variety unidimensional multidimensional models. Poorly fitting items inspected empirical plots/tables unidimensional models, otherwise itemGAM can used diagnose functional form IRT model misspecified, models can refit using flexible semi-parametric response models (e.g., itemtype = 'spline'). latent trait density approximated (e.g., Davidian curves, Empirical histograms, etc) passing use_dentype_estimate = TRUE use internally saved quadrature density components (applicable). Currently, S-X2 statistic supported mixture IRT models. Finally, applicable root mean-square error approximation (RMSEA) reported help gauge magnitude item misfit.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Item fit statistics — itemfit","text":"","code":"itemfit(   x,   fit_stats = \"S_X2\",   which.items = 1:extract.mirt(x, \"nitems\"),   na.rm = FALSE,   p.adjust = \"none\",   group.bins = 10,   group.size = NA,   group.fun = mean,   mincell = 1,   mincell.X2 = 2,   return.tables = FALSE,   pv_draws = 30,   boot = 1000,   boot_dfapprox = 200,   S_X2.plot = NULL,   S_X2.plot_raw.score = TRUE,   ETrange = c(-2, 2),   ETpoints = 11,   empirical.plot = NULL,   empirical.CI = 0.95,   empirical.poly.collapse = FALSE,   method = \"EAP\",   Theta = NULL,   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Item fit statistics — itemfit","text":"x computed model object class SingleGroupClass, MultipleGroupClass, DiscreteClass fit_stats character vector indicating fit statistics computed.   Supported inputs : 'S_X2' : Orlando Thissen (2000, 2003)     Kang Chen's (2007) signed chi-squared test (default) 'Zh' : Drasgow, Levine, & Williams (1985) Zh 'X2' : Bock's (1972) chi-squared method.     default inputs compute Yen's (1981) Q1 variant X2 statistic     (.e., uses fixed group.bins = 10). However, Bock's group-size variable     median-based method can computed passing group.fun = median     modifying group.size input desired number bins 'G2' : McKinley & Mills (1985) G2 statistic (similar method Q1,     likelihood-ratio test). 'PV_Q1' : Chalmers Ng's (2017) plausible-value variant     Q1 statistic. 'PV_Q1*' : Chalmers Ng's (2017) plausible-value variant     Q1 statistic uses parametric bootstrapping obtain suitable empirical     distribution. 'X2*' : Stone's (2000) fit statistics require parametric     bootstrapping 'X2*_df' : Stone's (2000) fit statistics require parametric     bootstrapping obtain scaled versions X2* degrees freedom 'infit' : Compute infit outfit statistics Note 'S_X2' 'Zh' computed missing response data (.e., require multiple-imputation/row-removal techniques). .items integer vector indicating items test fit. Default tests possible items na.rm logical; remove rows missing values? required methods S-X2 require \"EAPsum\" method fscores p.adjust method use adjusting p-values respective item fit statistic (see p.adjust available options). Default 'none' group.bins number bins use X2 G2. example, setting group.bins = 10 compute Yen's (1981) Q1 statistic 'X2' requested group.size approximate size group used calculating \\(\\chi^2\\) statistic. default NA disables command instead uses group.bins input try construct equally sized bins group.fun function used 'X2' 'G2' computed. Determines central tendency measure within partitioned group. E.g., setting group.fun = median obtain median respective ability estimate subgroup (used Bock, 1972) mincell minimum expected cell size used S-X2 computations. Tables collapsed across items first polytomous, across scores necessary mincell.X2 minimum expected cell size used X2 computations. Tables collapsed polytomous, however condition can met group block omitted computations return.tables logical; return tables investigating 'X2', 'S_X2', 'X2*'? pv_draws number plausible-value draws obtain PV_Q1 PV_Q1* boot number parametric bootstrap samples create PV_Q1* X2* boot_dfapprox number parametric bootstrap samples create X2*_df statistic approximate scaling factor X2* well scaled degrees freedom estimates S_X2.plot argument input empirical.plot, however resulting image constructed according S-X2 statistic's conditional sum-score information S_X2.plot_raw.score logical; use raw-score information plot stead latent trait scale score? Default FALSE ETrange range integration nodes Stone's X2* statistic ETpoints number integration nodes use Stone's X2* statistic empirical.plot single numeric value character item name indicating item plot (via itemplot) overlay empirical \\(\\theta\\) groupings (see empirical.CI). Useful plotting expected bins based 'X2' 'G2' method empirical.CI numeric value indicating width empirical confidence interval ranging 0 1 (default 0 plots interval). example, 95 interval plotted empirical.CI = .95. applicable dichotomous items empirical.poly.collapse logical; collapse polytomous item categories expected scoring functions empirical plots? Default FALSE method type factor score estimation method. See fscores detail Theta matrix factor scores person used statistics require empirical estimates. supplied, arguments typically passed fscores() ignored values used instead. Also required estimating statistics missing data via imputation par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice ... additional arguments passed fscores() lattice","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Item fit statistics — itemfit","text":"Bock, R. D. (1972). Estimating item parameters latent ability responses scored two nominal categories. Psychometrika, 37, 29-51. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. & Ng, V. (2017). Plausible-Value Imputation Statistics Detecting Item Misfit. Applied Psychological Measurement, 41, 372-387. doi:10.1177/0146621617692079 Drasgow, F., Levine, M. V., & Williams, E. . (1985). Appropriateness measurement polychotomous item response models standardized indices. British Journal Mathematical Statistical Psychology, 38, 67-86. Kang, T. & Chen, Troy, T. (2007). investigation performance generalized S-X2 item-fit index polytomous IRT models. ACT McKinley, R., & Mills, C. (1985). comparison several goodness--fit statistics. Applied Psychological Measurement, 9, 49-57. Orlando, M. & Thissen, D. (2000). Likelihood-based item fit indices dichotomous item response theory models. Applied Psychological Measurement, 24, 50-64. Reise, S. P. (1990). comparison item- person-fit methods assessing model-data fit IRT. Applied Psychological Measurement, 14, 127-137. Stone, C. . (2000). Monte Carlo Based Null Distribution Alternative Goodness--Fit Test Statistics IRT Models. Journal Educational Measurement, 37, 58-75. Wright B. D. & Masters, G. N. (1982). Rating scale analysis. MESA Press. Yen, W. M. (1981). Using simulation results choose latent trait model. Applied Psychological Measurement, 5, 245-262.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Item fit statistics — itemfit","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Item fit statistics — itemfit","text":"","code":"if (FALSE) { # \\dontrun{  P <- function(Theta){exp(Theta^2 * 1.2 - 1) / (1 + exp(Theta^2 * 1.2 - 1))}  #make some data set.seed(1234) a <- matrix(rlnorm(20, meanlog=0, sdlog = .1),ncol=1) d <- matrix(rnorm(20),ncol=1) Theta <- matrix(rnorm(2000)) items <- rep('2PL', 20) ps <- P(Theta) baditem <- numeric(2000) for(i in 1:2000)    baditem[i] <- sample(c(0,1), 1, prob = c(1-ps[i], ps[i])) data <- cbind(simdata(a,d, 2000, items, Theta=Theta), baditem=baditem)  x <- mirt(data, 1) raschfit <- mirt(data, 1, itemtype='Rasch') fit <- itemfit(x) fit  # p-value adjustment itemfit(x, p.adjust='fdr')  # two different fit stats (with/without p-value adjustment) itemfit(x, c('S_X2' ,'X2'), p.adjust='fdr') itemfit(x, c('S_X2' ,'X2'))  # Conditional sum-score plot from S-X2 information itemfit(x, S_X2.plot = 1) # good fit itemfit(x, S_X2.plot = 2) # good fit itemfit(x, S_X2.plot = 21) # bad fit  itemfit(x, 'X2') # just X2 itemfit(x, 'X2', method = 'ML') # X2 with maximum-likelihood estimates for traits itemfit(x, group.bins=15, empirical.plot = 1, method = 'ML') #empirical item plot with 15 points itemfit(x, group.bins=15, empirical.plot = 21, method = 'ML')  # PV and X2* statistics (parametric bootstrap stats not run to save time) itemfit(x, 'PV_Q1')  if(interactive()) mirtCluster() # improve speed of bootstrap samples by running in parallel # itemfit(x, 'PV_Q1*') # itemfit(x, 'X2*') # Stone's 1993 statistic # itemfit(x, 'X2*_df') # Stone's 2000 scaled statistic with df estimate  # empirical tables for X2 statistic tabs <- itemfit(x, 'X2', return.tables=TRUE, which.items = 1) tabs  #infit/outfit statistics. method='ML' agrees better with eRm package itemfit(raschfit, 'infit', method = 'ML') #infit and outfit stats  #same as above, but inputting ML estimates instead (saves time for re-use) Theta <- fscores(raschfit, method = 'ML') itemfit(raschfit, 'infit', Theta=Theta) itemfit(raschfit, empirical.plot=1, Theta=Theta) itemfit(raschfit, 'X2', return.tables=TRUE, Theta=Theta, which.items=1)  # fit a new more flexible model for the mis-fitting item itemtype <- c(rep('2PL', 20), 'spline') x2 <- mirt(data, 1, itemtype=itemtype) itemfit(x2) itemplot(x2, 21) anova(x, x2)  #------------------------------------------------------------  #similar example to Kang and Chen 2007 a <- matrix(c(.8,.4,.7, .8, .4, .7, 1, 1, 1, 1)) d <- matrix(rep(c(2.0,0.0,-1,-1.5),10), ncol=4, byrow=TRUE) dat <- simdata(a,d,2000, itemtype = rep('graded', 10)) head(dat)  mod <- mirt(dat, 1) itemfit(mod) itemfit(mod, 'X2') # less useful given inflated Type I error rates itemfit(mod, empirical.plot = 1) itemfit(mod, empirical.plot = 1, empirical.poly.collapse=TRUE)  # collapsed tables (see mincell.X2) for X2 and G2 itemfit(mod, 'X2', return.tables = TRUE, which.items = 1)  mod2 <- mirt(dat, 1, 'Rasch') itemfit(mod2, 'infit', method = 'ML')  # massive list of tables for S-X2 tables <- itemfit(mod, return.tables = TRUE)  #observed and expected total score patterns for item 1 (post collapsing) tables$O[[1]] tables$E[[1]]  # can also select specific items # itemfit(mod, return.tables = TRUE, which.items=1)  # fit stats with missing data (run in parallel using all cores) dat[sample(1:prod(dim(dat)), 100)] <- NA raschfit <- mirt(dat, 1, itemtype='Rasch')  # use only valid data by removing rows with missing terms itemfit(raschfit, c('S_X2', 'infit'), na.rm = TRUE)  # note that X2, G2, PV-Q1, and X2* do not require complete datasets thetas <- fscores(raschfit, method = 'ML') # save for faster computations itemfit(raschfit, c('X2', 'G2'), Theta=thetas) itemfit(raschfit, empirical.plot=1, Theta=thetas) itemfit(raschfit, 'X2', return.tables=TRUE, which.items=1, Theta=thetas)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate item information — iteminfo","title":"Function to calculate item information — iteminfo","text":"Given internal mirt item object extracted using extract.item, compute item information.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate item information — iteminfo","text":"","code":"iteminfo(x, Theta, degrees = NULL, total.info = TRUE, multidim_matrix = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate item information — iteminfo","text":"x extracted internal mirt object containing item information (see extract.item) Theta vector (unidimensional) matrix (multidimensional) latent trait values degrees vector angles degrees 0 90. applicable input object multidimensional total.info logical; return total information curve item? FALSE, information curves category returned matrix multidim_matrix logical; compute information matrix row Theta? Theta contains 1 row list matrices returned, otherwise Theta exactly one row matrix returned","code":""},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate item information — iteminfo","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate item information — iteminfo","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate item information — iteminfo","text":"","code":"mod <- mirt(Science, 1) #>  Iteration: 1, Log-Lik: -1629.361, Max-Change: 0.50660 Iteration: 2, Log-Lik: -1617.374, Max-Change: 0.25442 Iteration: 3, Log-Lik: -1612.894, Max-Change: 0.16991 Iteration: 4, Log-Lik: -1610.306, Max-Change: 0.10461 Iteration: 5, Log-Lik: -1609.814, Max-Change: 0.09162 Iteration: 6, Log-Lik: -1609.534, Max-Change: 0.07363 Iteration: 7, Log-Lik: -1609.030, Max-Change: 0.03677 Iteration: 8, Log-Lik: -1608.988, Max-Change: 0.03200 Iteration: 9, Log-Lik: -1608.958, Max-Change: 0.02754 Iteration: 10, Log-Lik: -1608.878, Max-Change: 0.01443 Iteration: 11, Log-Lik: -1608.875, Max-Change: 0.00847 Iteration: 12, Log-Lik: -1608.873, Max-Change: 0.00515 Iteration: 13, Log-Lik: -1608.872, Max-Change: 0.00550 Iteration: 14, Log-Lik: -1608.872, Max-Change: 0.00318 Iteration: 15, Log-Lik: -1608.871, Max-Change: 0.00462 Iteration: 16, Log-Lik: -1608.871, Max-Change: 0.00277 Iteration: 17, Log-Lik: -1608.870, Max-Change: 0.00145 Iteration: 18, Log-Lik: -1608.870, Max-Change: 0.00175 Iteration: 19, Log-Lik: -1608.870, Max-Change: 0.00126 Iteration: 20, Log-Lik: -1608.870, Max-Change: 0.00025 Iteration: 21, Log-Lik: -1608.870, Max-Change: 0.00285 Iteration: 22, Log-Lik: -1608.870, Max-Change: 0.00108 Iteration: 23, Log-Lik: -1608.870, Max-Change: 0.00022 Iteration: 24, Log-Lik: -1608.870, Max-Change: 0.00059 Iteration: 25, Log-Lik: -1608.870, Max-Change: 0.00014 Iteration: 26, Log-Lik: -1608.870, Max-Change: 0.00068 Iteration: 27, Log-Lik: -1608.870, Max-Change: 0.00065 Iteration: 28, Log-Lik: -1608.870, Max-Change: 0.00019 Iteration: 29, Log-Lik: -1608.870, Max-Change: 0.00061 Iteration: 30, Log-Lik: -1608.870, Max-Change: 0.00012 Iteration: 31, Log-Lik: -1608.870, Max-Change: 0.00012 Iteration: 32, Log-Lik: -1608.870, Max-Change: 0.00058 Iteration: 33, Log-Lik: -1608.870, Max-Change: 0.00055 Iteration: 34, Log-Lik: -1608.870, Max-Change: 0.00015 Iteration: 35, Log-Lik: -1608.870, Max-Change: 0.00052 Iteration: 36, Log-Lik: -1608.870, Max-Change: 0.00010 extr.2 <- extract.item(mod, 2) Theta <- matrix(seq(-4,4, by = .1)) info.2 <- iteminfo(extr.2, Theta)  #do something with the info? plot(Theta, info.2, type = 'l', main = 'Item information')   if (FALSE) { # \\dontrun{  #category information curves cat.info <- iteminfo(extr.2, Theta, total.info = FALSE) plot(Theta, cat.info[,1], type = 'l', ylim = c(0, max(cat.info)),      ylab = 'info', main = 'Category information') for(i in 2:ncol(cat.info))    lines(Theta, cat.info[,i], col = i)  ## Customized test information plot T1 <- T2 <- 0 dat <- expand.table(LSAT7) mod1 <- mirt(dat, 1) mod2 <- mirt(dat, 1, 'Rasch') for(i in 1:5){   T1 <- T1 + iteminfo(extract.item(mod1, i), Theta)   T2 <- T2 + iteminfo(extract.item(mod2, i), Theta) } plot(Theta, T2/T1, type = 'l', ylab = 'Relative Test Information', las = 1) lines(Theta, T1/T1, col = 'red')  # multidimensional mod <- mirt(dat, 2, TOL=1e-2) ii <- extract.item(mod, 1) Theta <- as.matrix(expand.grid(-4:4, -4:4))  iteminfo(ii, Theta, degrees=c(45,45)) # equal angle iteminfo(ii, Theta, degrees=c(90,0)) # first dimension only  # information matrices iteminfo(ii, Theta, multidim_matrix = TRUE) iteminfo(ii, Theta[1, , drop=FALSE], multidim_matrix = TRUE)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Displays item surface and information plots — itemplot","title":"Displays item surface and information plots — itemplot","text":"itemplot displays various item based IRT plots, special options plotting items contain several 0 slope parameters. Supports three dimensional models.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Displays item surface and information plots — itemplot","text":"","code":"itemplot(   object,   item,   type = \"trace\",   degrees = 45,   CE = FALSE,   CEalpha = 0.05,   CEdraws = 1000,   drop.zeros = FALSE,   theta_lim = c(-6, 6),   shiny = FALSE,   rot = list(xaxis = -70, yaxis = 30, zaxis = 10),   par.strip.text = list(cex = 0.7),   npts = 200,   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Displays item surface and information plots — itemplot","text":"object computed model object class SingleGroupClass MultipleGroupClass. Input may also list comparing similar item types (e.g., 1PL vs 2PL) item single numeric value, item name, indicating item plot type plot type use, information ('info'), standard errors ('SE'), item trace lines ('trace'), cumulative probability plots indicate thresholds ('threshold'), information standard errors ('infoSE') information trace lines ('infotrace'), category total information ('infocat'), relative efficiency lines ('RE'), expected score 'score', information trace line contours ('infocontour' 'tracecontour'; supported MultipleGroupClass objects) degrees degrees argument used two three factors. See iteminfo detail. new vector required three dimensional models override default CE logical; plot confidence envelope? CEalpha area remaining tail confidence envelope. Default gives 95% confidence region CEdraws draws number draws use confidence envelope drop.zeros logical; drop slope values numerically close zero reduce dimensionality? Useful objects returned bfactor confirmatory models contain several zero slopes theta_lim lower upper limits latent trait (theta) evaluated, used conjunction npts. Default uses c(-6,6) shiny logical; run interactive display item plots using shiny interface. primarily instructive tool demonstrating item response curves behave adjusting parameters rot list rotation coordinates used 3 dimensional plots par.strip.text plotting argument passed lattice npts number quadrature points used plotting features. Larger values make plots look smoother par.settings plotting argument passed lattice auto.key plotting argument passed lattice ... additional arguments passed lattice coef()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Displays item surface and information plots — itemplot","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Displays item surface and information plots — itemplot","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Displays item surface and information plots — itemplot","text":"","code":"if (FALSE) { # \\dontrun{  data(LSAT7) fulldata <- expand.table(LSAT7) mod1 <- mirt(fulldata,1,SE=TRUE) mod2 <- mirt(fulldata,1, itemtype = 'Rasch') mod3 <- mirt(fulldata,2)  itemplot(mod1, 2) itemplot(mod1, 2, CE = TRUE) itemplot(mod1, 2, type = 'info') itemplot(mod1, 2, type = 'info', CE = TRUE)  mods <- list(twoPL = mod1, onePL = mod2) itemplot(mods, 1, type = 'RE')  # multidimensional itemplot(mod3, 4, type = 'info') itemplot(mod3, 4, type = 'info',   col.regions = colorRampPalette(c(\"white\", \"red\"))(100)) itemplot(mod3, 4, type = 'infocontour') itemplot(mod3, 4, type = 'tracecontour')  # polytomous items pmod <- mirt(Science, 1, SE=TRUE) itemplot(pmod, 3) itemplot(pmod, 3, type = 'threshold') itemplot(pmod, 3, CE = TRUE) itemplot(pmod, 3, type = 'score') itemplot(pmod, 3, type = 'score', CE = TRUE) itemplot(pmod, 3, type = 'infotrace') itemplot(pmod, 3, type = 'infocat')   # use the directlabels package to put labels on tracelines library(directlabels) plt <- itemplot(pmod, 3) direct.label(plt, 'top.points')  # change colour theme of plots bwtheme <- standard.theme(\"pdf\", color=FALSE) plot(pmod, type='trace', par.settings=bwtheme) itemplot(pmod, 1, type = 'trace', par.settings=bwtheme)  # additional modifications can be made via update(). # See ?update.trellis for further documentation (plt <- itemplot(pmod, 1)) update(plt, ylab = expression(Prob(theta))) # ylab changed  # infoSE plot itemplot(pmod, 1, type = 'infoSE')  # uncomment to run interactive shiny applet # itemplot(shiny = TRUE)     } # }"},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic item summary statistics — itemstats","title":"Generic item summary statistics — itemstats","text":"Function compute generic item summary statistics require prior fitting IRT models. Contains information coefficient alpha (alpha item deleted), mean/SD frequency total scores, reduced item-total correlations, average/sd correlation items, response frequencies, conditional mean/sd information given unweighted sum scores.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic item summary statistics — itemstats","text":"","code":"itemstats(   data,   group = NULL,   use_ts = TRUE,   proportions = TRUE,   ts.tables = FALSE )"},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic item summary statistics — itemstats","text":"data object class data.frame matrix response patterns group optional grouping variable condition computing summary information use_ts logical; include information conditional meaningful total score? proportions logical; include response proportion information item? ts.tables logical; include mean/sd summary information pertaining unweighted total score?","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic item summary statistics — itemstats","text":"Returns list containing summary statistics","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generic item summary statistics — itemstats","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generic item summary statistics — itemstats","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic item summary statistics — itemstats","text":"","code":"# dichotomous data example LSAT7full <- expand.table(LSAT7) head(LSAT7full) #>   Item.1 Item.2 Item.3 Item.4 Item.5 #> 1      0      0      0      0      0 #> 2      0      0      0      0      0 #> 3      0      0      0      0      0 #> 4      0      0      0      0      0 #> 5      0      0      0      0      0 #> 6      0      0      0      0      0 itemstats(LSAT7full) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            3.707          1.199 0.143 0.052 0.453     0.886 #>  #> $itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 1000 0.828 0.378   0.530         0.246       0.396 #> Item.2 1000 0.658 0.475   0.600         0.247       0.394 #> Item.3 1000 0.772 0.420   0.611         0.313       0.345 #> Item.4 1000 0.606 0.489   0.592         0.223       0.415 #> Item.5 1000 0.843 0.364   0.461         0.175       0.438 #>  #> $proportions #>            0     1 #> Item.1 0.172 0.828 #> Item.2 0.342 0.658 #> Item.3 0.228 0.772 #> Item.4 0.394 0.606 #> Item.5 0.157 0.843 #>   # behaviour with missing data LSAT7full[1:5,1] <- NA itemstats(LSAT7full) #> $overall #>  N.complete    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>         995 1000            3.726          1.172 0.137 0.052 0.426     0.888 #>  #> $itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  995 0.832 0.374   0.515         0.222       0.396 #> Item.2 1000 0.658 0.475   0.595         0.232       0.364 #> Item.3 1000 0.772 0.420   0.602         0.295       0.316 #> Item.4 1000 0.606 0.489   0.589         0.209       0.384 #> Item.5 1000 0.843 0.364   0.442         0.149       0.418 #>  #> $proportions #>            0     1    NA #> Item.1 0.167 0.828 0.005 #> Item.2 0.342 0.658    NA #> Item.3 0.228 0.772    NA #> Item.4 0.394 0.606    NA #> Item.5 0.157 0.843    NA #>   # data with no meaningful total score head(SAT12) #>   Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> 1      1      4      5      2      3      1      2      1      3       1 #> 2      3      4      2      8      3      3      2      8      3       1 #> 3      1      4      5      4      3      2      2      3      3       2 #> 4      2      4      4      2      3      3      2      4      3       2 #> 5      2      4      5      2      3      2      2      1      1       2 #> 6      1      4      3      1      3      2      2      3      3       1 #>   Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> 1       2       4       2       1       5       3       4       4       1 #> 2       2       8       2       1       5       2       4       1       1 #> 3       2       1       3       1       5       5       4       1       3 #> 4       2       4       2       1       5       2       4       1       3 #> 5       2       4       2       1       5       4       4       5       1 #> 6       2       3       2       1       5       5       4       4       1 #>   Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> 1       4       3       3       4       1       3       5       1       3 #> 2       4       3       3       8       1       8       4       1       4 #> 3       4       3       3       1       1       3       4       1       3 #> 4       4       3       1       5       2       5       4       1       3 #> 5       4       3       3       3       1       1       5       1       3 #> 6       4       3       3       4       1       1       4       1       4 #>   Item.29 Item.30 Item.31 Item.32 #> 1       1       5       4       5 #> 2       5       8       4       8 #> 3       4       4       4       1 #> 4       4       2       4       2 #> 5       1       2       4       1 #> 6       2       3       4       3 itemstats(SAT12, use_ts=FALSE) #> $overall #>     N #> 1 600 #>  #> $itemstats #>           N  mean    sd #> Item.1  600 2.497 1.188 #> Item.2  600 3.385 1.356 #> Item.3  600 3.212 1.534 #> Item.4  600 2.762 1.370 #> Item.5  600 2.868 0.911 #> Item.6  600 2.358 1.135 #> Item.7  600 2.422 0.908 #> Item.8  600 2.925 1.370 #> Item.9  600 2.907 0.567 #> Item.10 600 2.320 1.490 #> Item.11 600 2.017 0.199 #> Item.12 600 3.642 1.184 #> Item.13 600 2.317 0.956 #> Item.14 600 1.798 1.432 #> Item.15 600 4.535 1.087 #> Item.16 600 3.368 1.135 #> Item.17 600 3.968 0.343 #> Item.18 600 3.020 1.514 #> Item.19 600 1.900 1.053 #> Item.20 600 3.870 0.483 #> Item.21 600 2.937 0.554 #> Item.22 600 2.985 0.442 #> Item.23 600 2.755 1.437 #> Item.24 600 1.502 1.037 #> Item.25 600 2.740 1.380 #> Item.26 600 3.923 1.265 #> Item.27 600 1.240 0.766 #> Item.28 600 3.262 0.937 #> Item.29 600 2.285 1.306 #> Item.30 600 3.703 1.553 #> Item.31 600 3.788 0.899 #> Item.32 600 3.023 1.303 #>  #> $proportions #>             1     2     3     4     5     8 #> Item.1  0.283 0.203 0.267 0.232 0.013 0.002 #> Item.2  0.212 0.022 0.070 0.568 0.127 0.002 #> Item.3  0.165 0.183 0.260 0.098 0.280 0.013 #> Item.4  0.165 0.378 0.148 0.172 0.128 0.008 #> Item.5  0.093 0.143 0.620 0.093 0.048 0.002 #> Item.6  0.160 0.582 0.107 0.043 0.108    NA #> Item.7  0.025 0.760 0.007 0.190 0.017 0.002 #> Item.8  0.202 0.205 0.207 0.250 0.133 0.003 #> Item.9  0.065 0.010 0.885 0.033 0.007    NA #> Item.10 0.422 0.215 0.165 0.028 0.167 0.003 #> Item.11 0.003 0.983 0.008 0.003 0.002    NA #> Item.12 0.072 0.082 0.218 0.415 0.205 0.008 #> Item.13 0.110 0.662 0.070 0.118 0.040    NA #> Item.14 0.723 0.027 0.108 0.022 0.117 0.003 #> Item.15 0.035 0.062 0.060 0.025 0.817 0.002 #> Item.16 0.070 0.105 0.413 0.215 0.195 0.002 #> Item.17 0.008 0.005 0.010 0.963 0.013    NA #> Item.18 0.303 0.033 0.165 0.352 0.142 0.005 #> Item.19 0.548 0.053 0.358 0.030 0.010    NA #> Item.20 0.012 0.002 0.105 0.873 0.007 0.002 #> Item.21 0.050 0.008 0.915 0.013 0.012 0.002 #> Item.22 0.028 0.005 0.935 0.017 0.015    NA #> Item.23 0.290 0.177 0.128 0.313 0.087 0.005 #> Item.24 0.728 0.162 0.042 0.022 0.045 0.002 #> Item.25 0.240 0.170 0.375 0.065 0.142 0.008 #> Item.26 0.020 0.227 0.030 0.262 0.460 0.002 #> Item.27 0.862 0.093 0.012 0.020 0.010 0.003 #> Item.28 0.082 0.010 0.530 0.337 0.037 0.005 #> Item.29 0.340 0.295 0.205 0.085 0.067 0.008 #> Item.30 0.150 0.110 0.107 0.183 0.440 0.010 #> Item.31 0.075 0.020 0.012 0.833 0.058 0.002 #> Item.32 0.125 0.183 0.443 0.075 0.162 0.012 #>   # extra total scores tables dat <- key2binary(SAT12,                    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,                            5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) itemstats(dat, ts.tables=TRUE) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  600           18.202          5.054 0.108 0.075 0.798     2.272 #>  #> $itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  600 0.283 0.451   0.380         0.300       0.793 #> Item.2  600 0.568 0.496   0.539         0.464       0.785 #> Item.3  600 0.280 0.449   0.446         0.371       0.789 #> Item.4  600 0.378 0.485   0.325         0.235       0.796 #> Item.5  600 0.620 0.486   0.424         0.340       0.791 #> Item.6  600 0.160 0.367   0.414         0.351       0.791 #> Item.7  600 0.760 0.427   0.366         0.289       0.793 #> Item.8  600 0.202 0.402   0.307         0.233       0.795 #> Item.9  600 0.885 0.319   0.189         0.127       0.798 #> Item.10 600 0.422 0.494   0.465         0.383       0.789 #> Item.11 600 0.983 0.128   0.181         0.156       0.797 #> Item.12 600 0.415 0.493   0.173         0.076       0.803 #> Item.13 600 0.662 0.474   0.438         0.358       0.790 #> Item.14 600 0.723 0.448   0.411         0.333       0.791 #> Item.15 600 0.817 0.387   0.393         0.325       0.792 #> Item.16 600 0.413 0.493   0.367         0.278       0.794 #> Item.17 600 0.963 0.188   0.238         0.202       0.796 #> Item.18 600 0.352 0.478   0.576         0.508       0.783 #> Item.19 600 0.548 0.498   0.401         0.314       0.792 #> Item.20 600 0.873 0.333   0.376         0.318       0.792 #> Item.21 600 0.915 0.279   0.190         0.136       0.798 #> Item.22 600 0.935 0.247   0.284         0.238       0.795 #> Item.23 600 0.313 0.464   0.338         0.253       0.795 #> Item.24 600 0.728 0.445   0.422         0.346       0.791 #> Item.25 600 0.375 0.485   0.383         0.297       0.793 #> Item.26 600 0.460 0.499   0.562         0.489       0.783 #> Item.27 600 0.862 0.346   0.425         0.367       0.791 #> Item.28 600 0.530 0.500   0.465         0.383       0.789 #> Item.29 600 0.340 0.474   0.407         0.324       0.791 #> Item.30 600 0.440 0.497   0.255         0.159       0.799 #> Item.31 600 0.833 0.373   0.479         0.419       0.788 #> Item.32 600 0.162 0.368   0.110         0.037       0.802 #>  #> $proportions #>             0     1 #> Item.1  0.717 0.283 #> Item.2  0.432 0.568 #> Item.3  0.720 0.280 #> Item.4  0.622 0.378 #> Item.5  0.380 0.620 #> Item.6  0.840 0.160 #> Item.7  0.240 0.760 #> Item.8  0.798 0.202 #> Item.9  0.115 0.885 #> Item.10 0.578 0.422 #> Item.11 0.017 0.983 #> Item.12 0.585 0.415 #> Item.13 0.338 0.662 #> Item.14 0.277 0.723 #> Item.15 0.183 0.817 #> Item.16 0.587 0.413 #> Item.17 0.037 0.963 #> Item.18 0.648 0.352 #> Item.19 0.452 0.548 #> Item.20 0.127 0.873 #> Item.21 0.085 0.915 #> Item.22 0.065 0.935 #> Item.23 0.687 0.313 #> Item.24 0.272 0.728 #> Item.25 0.625 0.375 #> Item.26 0.540 0.460 #> Item.27 0.138 0.862 #> Item.28 0.470 0.530 #> Item.29 0.660 0.340 #> Item.30 0.560 0.440 #> Item.31 0.167 0.833 #> Item.32 0.838 0.162 #>  #> $total.score_frequency #>      4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #> Freq 1 2 2 2 5 7 14 14 17 35 51 45 41 46 50 44 44 20 35 31 18 18 18 19  7  7  3 #>      31 32 #> Freq  1  3 #>  #> $total.score_means #>                0        1 #> Item.1  16.99535 21.25294 #> Item.2  15.07722 20.57478 #> Item.3  16.79630 21.81548 #> Item.4  16.92225 20.30396 #> Item.5  15.46930 19.87634 #> Item.6  17.28968 22.98958 #> Item.7  14.91667 19.23904 #> Item.8  17.42171 21.28926 #> Item.9  15.55072 18.54614 #> Item.10 16.19597 20.95257 #> Item.11 11.20000 18.32034 #> Item.12 17.46724 19.23695 #> Item.13 15.10837 19.78338 #> Item.14 14.84940 19.48387 #> Item.15 14.01818 19.14082 #> Item.16 16.64773 20.40726 #> Item.17 12.04545 18.43599 #> Item.18 16.05913 22.15166 #> Item.19 15.97048 20.03951 #> Item.20 13.21053 18.92557 #> Item.21 15.05882 18.49362 #> Item.22 12.76923 18.57932 #> Item.23 17.04854 20.72872 #> Item.24 14.71166 19.50343 #> Item.25 16.70400 20.69778 #> Item.26 15.58025 21.27899 #> Item.27 12.84337 19.06190 #> Item.28 15.70567 20.41509 #> Item.29 16.72727 21.06373 #> Item.30 17.06250 19.65152 #> Item.31 12.79000 19.28400 #> Item.32 17.95825 19.46392 #>  #> $total.score_sds #>                0        1 #> Item.1  4.495009 5.115311 #> Item.2  3.791287 4.583007 #> Item.3  4.322840 5.013323 #> Item.4  4.333771 5.444014 #> Item.5  4.280262 4.756698 #> Item.6  4.448894 5.353788 #> Item.7  4.313744 4.825059 #> Item.8  4.575452 5.661917 #> Item.9  5.007454 4.961288 #> Item.10 4.278821 4.736481 #> Item.11 4.184628 4.985966 #> Item.12 4.861326 5.147431 #> Item.13 4.274965 4.679466 #> Item.14 4.008502 4.822098 #> Item.15 4.212219 4.744448 #> Item.16 4.361290 5.155818 #> Item.17 4.613410 4.923352 #> Item.18 3.955174 4.446051 #> Item.19 4.349442 4.854746 #> Item.20 3.714174 4.809188 #> Item.21 5.092786 4.954396 #> Item.22 3.923355 4.906759 #> Item.23 4.505479 5.276912 #> Item.24 3.896380 4.816172 #> Item.25 4.379749 5.124107 #> Item.26 3.761839 4.627003 #> Item.27 3.775666 4.692898 #> Item.28 4.340725 4.593648 #> Item.29 4.241013 5.281332 #> Item.30 4.817161 4.984363 #> Item.31 3.364386 4.622779 #> Item.32 4.901850 5.638524 #>   # grouping information group <- gl(2, 300, labels=c('G1', 'G2')) itemstats(dat, group=group) #> $G1 #> $G1$overall #>    N mean_total.score sd_total.score ave.r sd.r alpha SEM.alpha #>  300           17.987          5.051 0.107 0.09 0.796     2.282 #>  #> $G1$itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  300 0.290 0.455   0.410         0.331       0.789 #> Item.2  300 0.573 0.495   0.534         0.458       0.783 #> Item.3  300 0.290 0.455   0.458         0.382       0.787 #> Item.4  300 0.353 0.479   0.342         0.255       0.793 #> Item.5  300 0.630 0.484   0.480         0.401       0.786 #> Item.6  300 0.130 0.337   0.398         0.340       0.789 #> Item.7  300 0.727 0.446   0.383         0.303       0.790 #> Item.8  300 0.213 0.410   0.352         0.277       0.791 #> Item.9  300 0.897 0.305   0.203         0.144       0.796 #> Item.10 300 0.403 0.491   0.433         0.349       0.788 #> Item.11 300 0.993 0.082   0.154         0.138       0.796 #> Item.12 300 0.413 0.493   0.123         0.026       0.803 #> Item.13 300 0.647 0.479   0.441         0.359       0.788 #> Item.14 300 0.727 0.446   0.394         0.316       0.790 #> Item.15 300 0.793 0.406   0.407         0.337       0.789 #> Item.16 300 0.377 0.485   0.338         0.249       0.793 #> Item.17 300 0.957 0.204   0.220         0.181       0.795 #> Item.18 300 0.360 0.481   0.567         0.497       0.781 #> Item.19 300 0.537 0.499   0.432         0.347       0.788 #> Item.20 300 0.863 0.344   0.355         0.293       0.791 #> Item.21 300 0.910 0.287   0.202         0.147       0.795 #> Item.22 300 0.927 0.261   0.260         0.211       0.794 #> Item.23 300 0.260 0.439   0.323         0.242       0.793 #> Item.24 300 0.707 0.456   0.421         0.342       0.789 #> Item.25 300 0.370 0.484   0.406         0.321       0.790 #> Item.26 300 0.473 0.500   0.539         0.463       0.783 #> Item.27 300 0.857 0.351   0.474         0.418       0.787 #> Item.28 300 0.537 0.499   0.435         0.350       0.788 #> Item.29 300 0.343 0.476   0.378         0.293       0.791 #> Item.30 300 0.440 0.497   0.245         0.149       0.798 #> Item.31 300 0.810 0.393   0.518         0.457       0.784 #> Item.32 300 0.180 0.385   0.036        -0.041       0.803 #>  #> $G1$proportions #>             0     1 #> Item.1  0.710 0.290 #> Item.2  0.427 0.573 #> Item.3  0.710 0.290 #> Item.4  0.647 0.353 #> Item.5  0.370 0.630 #> Item.6  0.870 0.130 #> Item.7  0.273 0.727 #> Item.8  0.787 0.213 #> Item.9  0.103 0.897 #> Item.10 0.597 0.403 #> Item.11 0.007 0.993 #> Item.12 0.587 0.413 #> Item.13 0.353 0.647 #> Item.14 0.273 0.727 #> Item.15 0.207 0.793 #> Item.16 0.623 0.377 #> Item.17 0.043 0.957 #> Item.18 0.640 0.360 #> Item.19 0.463 0.537 #> Item.20 0.137 0.863 #> Item.21 0.090 0.910 #> Item.22 0.073 0.927 #> Item.23 0.740 0.260 #> Item.24 0.293 0.707 #> Item.25 0.630 0.370 #> Item.26 0.527 0.473 #> Item.27 0.143 0.857 #> Item.28 0.463 0.537 #> Item.29 0.657 0.343 #> Item.30 0.560 0.440 #> Item.31 0.190 0.810 #> Item.32 0.820 0.180 #>  #>  #> $G2 #> $G2$overall #>    N mean_total.score sd_total.score ave.r sd.r alpha SEM.alpha #>  300           18.417          5.056  0.11 0.08   0.8     2.262 #>  #> $G2$itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  300 0.277 0.448   0.352         0.271       0.796 #> Item.2  300 0.563 0.497   0.547         0.472       0.787 #> Item.3  300 0.270 0.445   0.438         0.363       0.792 #> Item.4  300 0.403 0.491   0.305         0.213       0.799 #> Item.5  300 0.610 0.489   0.371         0.283       0.796 #> Item.6  300 0.190 0.393   0.426         0.360       0.792 #> Item.7  300 0.793 0.406   0.344         0.270       0.796 #> Item.8  300 0.190 0.393   0.265         0.190       0.799 #> Item.9  300 0.873 0.333   0.180         0.116       0.801 #> Item.10 300 0.440 0.497   0.495         0.415       0.789 #> Item.11 300 0.973 0.161   0.215         0.184       0.799 #> Item.12 300 0.417 0.494   0.222         0.127       0.803 #> Item.13 300 0.677 0.469   0.434         0.354       0.792 #> Item.14 300 0.720 0.450   0.428         0.351       0.792 #> Item.15 300 0.840 0.367   0.375         0.310       0.794 #> Item.16 300 0.450 0.498   0.391         0.303       0.795 #> Item.17 300 0.970 0.171   0.258         0.226       0.798 #> Item.18 300 0.343 0.476   0.588         0.522       0.784 #> Item.19 300 0.560 0.497   0.369         0.279       0.796 #> Item.20 300 0.883 0.322   0.398         0.343       0.794 #> Item.21 300 0.920 0.272   0.175         0.123       0.800 #> Item.22 300 0.943 0.232   0.309         0.266       0.797 #> Item.23 300 0.367 0.483   0.348         0.260       0.797 #> Item.24 300 0.750 0.434   0.421         0.347       0.793 #> Item.25 300 0.380 0.486   0.360         0.272       0.796 #> Item.26 300 0.447 0.498   0.590         0.520       0.784 #> Item.27 300 0.867 0.341   0.374         0.314       0.794 #> Item.28 300 0.523 0.500   0.498         0.418       0.789 #> Item.29 300 0.337 0.473   0.437         0.357       0.792 #> Item.30 300 0.440 0.497   0.265         0.170       0.801 #> Item.31 300 0.857 0.351   0.435         0.376       0.792 #> Item.32 300 0.143 0.351   0.196         0.128       0.800 #>  #> $G2$proportions #>             0     1 #> Item.1  0.723 0.277 #> Item.2  0.437 0.563 #> Item.3  0.730 0.270 #> Item.4  0.597 0.403 #> Item.5  0.390 0.610 #> Item.6  0.810 0.190 #> Item.7  0.207 0.793 #> Item.8  0.810 0.190 #> Item.9  0.127 0.873 #> Item.10 0.560 0.440 #> Item.11 0.027 0.973 #> Item.12 0.583 0.417 #> Item.13 0.323 0.677 #> Item.14 0.280 0.720 #> Item.15 0.160 0.840 #> Item.16 0.550 0.450 #> Item.17 0.030 0.970 #> Item.18 0.657 0.343 #> Item.19 0.440 0.560 #> Item.20 0.117 0.883 #> Item.21 0.080 0.920 #> Item.22 0.057 0.943 #> Item.23 0.633 0.367 #> Item.24 0.250 0.750 #> Item.25 0.620 0.380 #> Item.26 0.553 0.447 #> Item.27 0.133 0.867 #> Item.28 0.477 0.523 #> Item.29 0.663 0.337 #> Item.30 0.560 0.440 #> Item.31 0.143 0.857 #> Item.32 0.857 0.143 #>  #>    ##### # polytomous data example itemstats(Science) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  392           11.668          2.003 0.275 0.098 0.598      1.27 #>  #> $itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Comfort 392 3.120 0.588   0.596         0.352       0.552 #> Work    392 2.722 0.807   0.666         0.332       0.567 #> Future  392 2.990 0.757   0.748         0.488       0.437 #> Benefit 392 2.837 0.802   0.684         0.363       0.541 #>  #> $proportions #>             1     2     3     4 #> Comfort 0.013 0.082 0.679 0.227 #> Work    0.084 0.250 0.526 0.140 #> Future  0.036 0.184 0.536 0.245 #> Benefit 0.054 0.255 0.492 0.199 #>   # polytomous data with missing newScience <- Science newScience[1:5,1] <- NA itemstats(newScience) #> $overall #>  N.complete   N mean_total.score sd_total.score ave.r sd.r alpha SEM.alpha #>         387 392           11.672          2.011 0.276  0.1 0.605     1.264 #>  #> $itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Comfort 387 3.119 0.590   0.596         0.352       0.552 #> Work    392 2.722 0.807   0.666         0.335       0.576 #> Future  392 2.990 0.757   0.749         0.491       0.449 #> Benefit 392 2.837 0.802   0.695         0.382       0.538 #>  #> $proportions #>             1     2     3     4    NA #> Comfort 0.013 0.082 0.668 0.224 0.013 #> Work    0.084 0.250 0.526 0.140    NA #> Future  0.036 0.184 0.536 0.245    NA #> Benefit 0.054 0.255 0.492 0.199    NA #>   # unequal categories newScience[,1] <- ifelse(Science[,1] == 1, NA, Science[,1]) itemstats(newScience) #> $overall #>  N.complete   N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>         387 392           11.731          1.917  0.26 0.092 0.572     1.254 #>  #> $itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Comfort 387 3.147 0.540   0.556         0.314       0.552 #> Work    392 2.722 0.807   0.680         0.339       0.517 #> Future  392 2.990 0.757   0.738         0.460       0.409 #> Benefit 392 2.837 0.802   0.668         0.328       0.525 #>  #> $proportions #>             1     2     3     4    NA #> Comfort    NA 0.082 0.679 0.227 0.013 #> Work    0.084 0.250 0.526 0.140    NA #> Future  0.036 0.184 0.536 0.245    NA #> Benefit 0.054 0.255 0.492 0.199    NA #>   merged <- data.frame(LSAT7full[1:392,], Science) itemstats(merged) #> $overall #>  N.complete   N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>         387 392           14.331          2.231 0.037 0.167 0.379     1.759 #>  #> $itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  387 0.568 0.496   0.193        -0.030       0.417 #> Item.2  392 0.232 0.423   0.033        -0.156       0.443 #> Item.3  392 0.605 0.490   0.216        -0.003       0.405 #> Item.4  392 0.467 0.500   0.261         0.038       0.392 #> Item.5  392 0.760 0.428   0.178        -0.011       0.402 #> Comfort 392 3.120 0.588   0.527         0.295       0.286 #> Work    392 2.722 0.807   0.620         0.314       0.251 #> Future  392 2.990 0.757   0.680         0.421       0.185 #> Benefit 392 2.837 0.802   0.608         0.299       0.261 #>  #> $proportions #>             0     1     2     3     4    NA #> Item.1  0.426 0.561    NA    NA    NA 0.013 #> Item.2  0.768 0.232    NA    NA    NA    NA #> Item.3  0.395 0.605    NA    NA    NA    NA #> Item.4  0.533 0.467    NA    NA    NA    NA #> Item.5  0.240 0.760    NA    NA    NA    NA #> Comfort    NA 0.013 0.082 0.679 0.227    NA #> Work       NA 0.084 0.250 0.526 0.140    NA #> Future     NA 0.036 0.184 0.536 0.245    NA #> Benefit    NA 0.054 0.255 0.492 0.199    NA #>"},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Score a test by converting response patterns to binary data — key2binary","title":"Score a test by converting response patterns to binary data — key2binary","text":"key2binary function convert response pattern data dichotomous format, given response key.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Score a test by converting response patterns to binary data — key2binary","text":"","code":"key2binary(fulldata, key, score_missing = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Score a test by converting response patterns to binary data — key2binary","text":"fulldata object class data.frame, matrix, table response patterns key vector matrix consisting 'correct' response items. value/row corresponds column fulldata. input matrix, multiple scoring keys can supplied item. NA values used indicate scoring key (case matrix input, additional scoring keys) score_missing logical; missing data elements returned incorrect (.e., 0)? FALSE, missing data terms kept missing","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Score a test by converting response patterns to binary data — key2binary","text":"Returns numeric matrix response patterns   dichotomous format","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Score a test by converting response patterns to binary data — key2binary","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Score a test by converting response patterns to binary data — key2binary","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Score a test by converting response patterns to binary data — key2binary","text":"","code":"data(SAT12) head(SAT12) #>   Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> 1      1      4      5      2      3      1      2      1      3       1 #> 2      3      4      2      8      3      3      2      8      3       1 #> 3      1      4      5      4      3      2      2      3      3       2 #> 4      2      4      4      2      3      3      2      4      3       2 #> 5      2      4      5      2      3      2      2      1      1       2 #> 6      1      4      3      1      3      2      2      3      3       1 #>   Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> 1       2       4       2       1       5       3       4       4       1 #> 2       2       8       2       1       5       2       4       1       1 #> 3       2       1       3       1       5       5       4       1       3 #> 4       2       4       2       1       5       2       4       1       3 #> 5       2       4       2       1       5       4       4       5       1 #> 6       2       3       2       1       5       5       4       4       1 #>   Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> 1       4       3       3       4       1       3       5       1       3 #> 2       4       3       3       8       1       8       4       1       4 #> 3       4       3       3       1       1       3       4       1       3 #> 4       4       3       1       5       2       5       4       1       3 #> 5       4       3       3       3       1       1       5       1       3 #> 6       4       3       3       4       1       1       4       1       4 #>   Item.29 Item.30 Item.31 Item.32 #> 1       1       5       4       5 #> 2       5       8       4       8 #> 3       4       4       4       1 #> 4       4       2       4       2 #> 5       1       2       4       1 #> 6       2       3       4       3 key <- c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)  dicho.SAT12 <- key2binary(SAT12, key) head(dicho.SAT12) #>      Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> [1,]      1      1      1      1      1      1      1      1      1       1 #> [2,]      0      1      0      0      1      0      1      0      1       1 #> [3,]      1      1      1      0      1      0      1      0      1       0 #> [4,]      0      1      0      1      1      0      1      0      1       0 #> [5,]      0      1      1      1      1      0      1      1      0       0 #> [6,]      1      1      0      0      1      0      1      0      1       1 #>      Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> [1,]       1       1       1       1       1       1       1       1       1 #> [2,]       1       0       1       1       1       0       1       0       1 #> [3,]       1       0       0       1       1       0       1       0       0 #> [4,]       1       1       1       1       1       0       1       0       0 #> [5,]       1       1       1       1       1       0       1       0       1 #> [6,]       1       0       1       1       1       0       1       1       1 #>      Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> [1,]       1       1       1       1       1       1       1       1       1 #> [2,]       1       1       1       0       1       0       0       1       0 #> [3,]       1       1       1       0       1       1       0       1       1 #> [4,]       1       1       0       0       0       0       0       1       1 #> [5,]       1       1       1       0       1       0       1       1       1 #> [6,]       1       1       1       1       1       0       0       1       0 #>      Item.29 Item.30 Item.31 Item.32 #> [1,]       1       1       1       1 #> [2,]       0       0       1       0 #> [3,]       0       0       1       0 #> [4,]       0       0       1       0 #> [5,]       1       0       1       0 #> [6,]       0       0       1       0  # multiple scoring keys key2 <- cbind(c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5),               c(2,3,NA,1,rep(NA, 28))) dicho.SAT12 <- key2binary(SAT12, key2)  # keys from raw character responses resp <- as.data.frame(matrix(c(   \"B\",\"B\",\"D\",\"D\",\"E\",   \"B\",\"A\",\"D\",\"D\",\"E\",   \"B\",\"A\",\"D\",\"C\",\"E\",   \"D\",\"D\",\"D\",\"C\",\"E\",   \"B\",\"C\",\"A\",\"D\",\"A\"), ncol=5, byrow=TRUE))  key <- c(\"B\", \"D\", \"D\", \"C\", \"E\")  d01 <- key2binary(resp, key) head(d01) #>      V1 V2 V3 V4 V5 #> [1,]  1  0  1  0  1 #> [2,]  1  0  1  0  1 #> [3,]  1  0  1  1  1 #> [4,]  0  1  1  1  1 #> [5,]  1  0  0  0  0  # score/don't score missing values resp[1,1] <- NA d01NA <- key2binary(resp, key) # without scoring d01NA #>      V1 V2 V3 V4 V5 #> [1,] NA  0  1  0  1 #> [2,]  1  0  1  0  1 #> [3,]  1  0  1  1  1 #> [4,]  0  1  1  1  1 #> [5,]  1  0  0  0  0  d01 <- key2binary(resp, key, score_missing = TRUE) # with scoring d01 #>      V1 V2 V3 V4 V5 #> [1,]  0  0  1  0  1 #> [2,]  1  0  1  0  1 #> [3,]  1  0  1  1  1 #> [4,]  0  1  1  1  1 #> [5,]  1  0  0  0  0"},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":null,"dir":"Reference","previous_headings":"","what":"Lagrange test for freeing parameters — lagrange","title":"Lagrange test for freeing parameters — lagrange","text":"Lagrange (.e., score) test test whether parameters freed constrained baseline model.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lagrange test for freeing parameters — lagrange","text":"","code":"lagrange(mod, parnum, SE.type = \"Oakes\", type = \"Richardson\", ...)"},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lagrange test for freeing parameters — lagrange","text":"mod estimated model parnum vector, list vectors, containing one parameter locations/sets locations tested. See objects returned mod2values locations SE.type type information matrix estimator use. See mirt details type type numerical algorithm passed numerical_deriv obtain gradient terms ... additional arguments pass mirt","code":""},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Lagrange test for freeing parameters — lagrange","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Lagrange test for freeing parameters — lagrange","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lagrange test for freeing parameters — lagrange","text":"","code":"if (FALSE) { # \\dontrun{ dat <- expand.table(LSAT7) mod <- mirt(dat, 1, 'Rasch') (values <- mod2values(mod))  # test all fixed slopes individually parnum <- values$parnum[values$name == 'a1'] lagrange(mod, parnum)  # compare to LR test for first two slopes mod2 <- mirt(dat, 'F = 1-5                    FREE = (1, a1)', 'Rasch') coef(mod2, simplify=TRUE)$items anova(mod, mod2)  mod2 <- mirt(dat, 'F = 1-5                    FREE = (2, a1)', 'Rasch') coef(mod2, simplify=TRUE)$items anova(mod, mod2)  mod2 <- mirt(dat, 'F = 1-5                    FREE = (3, a1)', 'Rasch') coef(mod2, simplify=TRUE)$items anova(mod, mod2)  # test slopes first two slopes and last three slopes jointly lagrange(mod, list(parnum[1:2], parnum[3:5]))  # test all 5 slopes and first + last jointly lagrange(mod, list(parnum[1:5], parnum[c(1, 5)]))  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"Given matrix data.frame object consisting Likert responses return object dimensions integer values.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"","code":"likert2int(x, levels = NULL)"},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"x matrix character values data.frame character/factor vectors levels named character vector indicating integer values assigned elements. omitted, order elements determined converting column x factor variable","code":""},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"","code":"if (FALSE) { # \\dontrun{  # simulate data  dat1 <- matrix(sample(c('Disagree', 'Strongly Disagree', 'Agree',                         'Neutral', 'Strongly Agree'), 1000*5, replace=TRUE),                nrow=1000, ncol=5) dat1[2,2] <- dat1[3,3] <- dat1[1,3] <- NA # NAs added for flavour dat2 <- matrix(sample(c('D', 'SD', 'A', 'N', 'SA'), 1000*5, replace=TRUE),                nrow=1000, ncol=5) dat <- cbind(dat1, dat2)  # separately intdat1 <- likert2int(dat1) head(dat1) head(intdat1)  # more useful with explicit levels lvl1 <- c('Strongly Disagree'=1, 'Disagree'=2, 'Neutral'=3, 'Agree'=4,           'Strongly Agree'=5) intdat1 <- likert2int(dat1, levels = lvl1) head(dat1) head(intdat1)  # second data lvl2 <- c('SD'=1, 'D'=2, 'N'=3, 'A'=4, 'SA'=5) intdat2 <- likert2int(dat2, levels = lvl2) head(dat2) head(intdat2)  # full dataset (using both mapping schemes) intdat <- likert2int(dat, levels = c(lvl1, lvl2)) head(dat) head(intdat)   ##### # data.frame as input with ordered factors  dat1 <- data.frame(dat1) dat2 <- data.frame(dat2) dat.old <- cbind(dat1, dat2) colnames(dat.old) <- paste0('Item_', 1:10) str(dat.old) # factors are leveled alphabetically by default  # create explicit ordering in factor variables for(i in 1:ncol(dat1))    levels(dat1[[i]]) <- c('Strongly Disagree', 'Disagree', 'Neutral', 'Agree',                           'Strongly Agree')  for(i in 1:ncol(dat2))    levels(dat2[[i]]) <- c('SD', 'D', 'N', 'A', 'SA')  dat <- cbind(dat1, dat2) colnames(dat) <- colnames(dat.old) str(dat) # note ordering  intdat <- likert2int(dat) head(dat) head(intdat)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract log-likelihood — logLik-method","title":"Extract log-likelihood — logLik-method","text":"Extract observed-data log-likelihood.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract log-likelihood — logLik-method","text":"","code":"# S4 method for class 'SingleGroupClass' logLik(object)"},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract log-likelihood — logLik-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract log-likelihood — logLik-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract log-likelihood — logLik-method","text":"","code":"if (FALSE) { # \\dontrun{ x <- mirt(Science, 1) logLik(x)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate the marginal reliability — marginal_rxx","title":"Function to calculate the marginal reliability — marginal_rxx","text":"Given estimated model prior density function, compute marginal reliability (Thissen Wainer, 2001). available unidimensional tests.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate the marginal reliability — marginal_rxx","text":"","code":"marginal_rxx(mod, density = dnorm, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate the marginal reliability — marginal_rxx","text":"mod object class 'SingleGroupClass' density density function use integration. Default assumes latent traits normal (Gaussian) distribution ... additional arguments passed density function","code":""},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate the marginal reliability — marginal_rxx","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Thissen, D. Wainer, H. (2001). Test Scoring. Lawrence Erlbaum Associates.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate the marginal reliability — marginal_rxx","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate the marginal reliability — marginal_rxx","text":"","code":"dat <- expand.table(deAyala) mod <- mirt(dat) #>  Iteration: 1, Log-Lik: -56256.669, Max-Change: 0.33820 Iteration: 2, Log-Lik: -55598.944, Max-Change: 0.25622 Iteration: 3, Log-Lik: -55344.183, Max-Change: 0.17901 Iteration: 4, Log-Lik: -55252.392, Max-Change: 0.12170 Iteration: 5, Log-Lik: -55219.175, Max-Change: 0.08221 Iteration: 6, Log-Lik: -55206.845, Max-Change: 0.05582 Iteration: 7, Log-Lik: -55202.096, Max-Change: 0.03866 Iteration: 8, Log-Lik: -55200.153, Max-Change: 0.02623 Iteration: 9, Log-Lik: -55199.330, Max-Change: 0.01879 Iteration: 10, Log-Lik: -55198.648, Max-Change: 0.00688 Iteration: 11, Log-Lik: -55198.588, Max-Change: 0.00523 Iteration: 12, Log-Lik: -55198.554, Max-Change: 0.00418 Iteration: 13, Log-Lik: -55198.501, Max-Change: 0.00094 Iteration: 14, Log-Lik: -55198.498, Max-Change: 0.00025 Iteration: 15, Log-Lik: -55198.497, Max-Change: 0.00024 Iteration: 16, Log-Lik: -55198.497, Max-Change: 0.00021 Iteration: 17, Log-Lik: -55198.497, Max-Change: 0.00096 Iteration: 18, Log-Lik: -55198.496, Max-Change: 0.00057 Iteration: 19, Log-Lik: -55198.496, Max-Change: 0.00015 Iteration: 20, Log-Lik: -55198.496, Max-Change: 0.00007  # marginal estimate treating item parameters as known marginal_rxx(mod) #> [1] 0.6092894  # compare to alpha itemstats(dat)$overall$alpha #> [1] 0.6077281  if (FALSE) { # \\dontrun{  # empirical estimate (assuming the same prior) fscores(mod, returnER = TRUE)  # empirical rxx the alternative way, given theta scores and SEs fs <- fscores(mod, full.scores.SE=TRUE) head(fs) empirical_rxx(fs)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Multidimensional discrete item response theory — mdirt","title":"Multidimensional discrete item response theory — mdirt","text":"mdirt fits variety item response models discrete latent variables. include, limited , latent class analysis, multidimensional latent class models, multidimensional discrete latent class models, DINA/DINO models, grade measurement models, C-RUM, . response models defined explicitly customized models can defined using createItem function.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multidimensional discrete item response theory — mdirt","text":"","code":"mdirt(   data,   model,   customTheta = NULL,   structure = NULL,   item.Q = NULL,   nruns = 1,   method = \"EM\",   covdata = NULL,   formula = NULL,   itemtype = \"lca\",   optimizer = \"nlminb\",   return_max = TRUE,   group = NULL,   GenRandomPars = FALSE,   verbose = TRUE,   pars = NULL,   technical = list(),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multidimensional discrete item response theory — mdirt","text":"data matrix data.frame consists numerically ordered data, organized form integers,  missing data coded NA model number mutually exclusive classes fit, alternatively specific mirt.model definition (reflects -called Q-matrix). Note using mirt.model, order syntax factors/attributes defined associated columns customTheta input customTheta input passed technical = list(customTheta = ...), included directly function convenience. input interesting discrete latent models allows customized patterns latent classes (.e., defines possible combinations latent attribute profile). default builds pattern customTheta = diag(model), typical pattern traditional latent class analysis whereby class membership mutually distinct exhaustive. See thetaComb quick method generate matrix possible combinations structure R formula allowing profile probability patterns (.e., structural component model) fitted according log-linear model. NULL, profile probabilities (except one) estimated. Use input requires customTheta input supplied, column names matrix match names found within formula item.Q list item-level Q-matrices indicating respective categories modeled underlying attributes. matrix must represent \\(K_i \\times \\) matrix, \\(K_i\\) represents number categories ith item, \\(\\) number attributes included Theta matrix; otherwise, value ofNULL default matrix consisting 1's \\(K_i \\times \\) element except first row, contains 0's proper identification. Incidentally, first row matrix must contain 0's first category represents reference category identification nruns numeric value indicating many times model fit data using random starting values. greater 1, GenRandomPars set true default method estimation method. Can 'EM' 'BL' (see mirt details) covdata data.frame data used latent regression models formula R formula (list formulas) indicating latent traits can regressed using external covariates covdata. named list formulas supplied (names correspond latent trait/attribute names model) specific regression effects can estimated factor. Supplying single formula estimate regression parameters latent variables default itemtype vector indicating itemtype associated item. discrete models limited 'lca' items defined using createItem definition optimizer optimizer used M-step, set 'nlminb' default. See mirt details return_max logical; nruns > 1, return model optimal maximum likelihood criteria? FALSE, returns list estimated objects group factor variable indicating group membership used multiple group analyses GenRandomPars logical; use random starting values verbose logical; turn messages R console pars used modifying starting values; see mirt details technical list lower-level inputs. See mirt details ... additional arguments passed estimation engine. See mirt details examples","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multidimensional discrete item response theory — mdirt","text":"Posterior classification accuracy response pattern may obtained via fscores function. summary() function display category probability values given class membership, can also displayed graphically plot(), coef() displays raw coefficient values (standard errors, estimated). Finally, anova() used compare nested models, M2 itemfit may used model fitting purposes.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"-lca-model-definition","dir":"Reference","previous_headings":"","what":"'lca' model definition","title":"Multidimensional discrete item response theory — mdirt","text":"latent class IRT model two latent classes form $$P(x = k|\\theta_1, \\theta_2, a1, a2) = \\frac{exp(a1 \\theta_1 + a2 \\theta_2)}{   \\sum_j^K exp(a1 \\theta_1 + a2 \\theta_2)}$$ \\(\\theta\\) values generally take discrete points (0 1). proper identification, first category slope parameters (\\(a1\\) \\(a2\\)) never freely estimated. Alternatively, supplying different grid \\(\\theta\\) values allow estimation similar models (multidimensional discrete models, grade membership, etc.). See examples . item.Q utilized, equation can understood $$P(x = k|\\theta_1, \\theta_2, a1, a2) = \\frac{exp(a1 \\theta_1 Q_{j1} + a2 \\theta_2 Q_{j2})}{   \\sum_j^K exp(a1 \\theta_1 Q_{j1} + a2 \\theta_2 Q_{j2})}$$ construction Q \\(K_i \\times \\) matrix indicating whether category modeled according latent class structure. standard latent class model, Q-matrix many rows categories, many columns number classes/attributes modeled, consist 0's first row 1's elsewhere. course can -written passing alternative item.Q definition respective item.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multidimensional discrete item response theory — mdirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. Proctor, C. H. (1970). probabilistic formulation statistical analysis Guttman scaling.   Psychometrika, 35, 73-78. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multidimensional discrete item response theory — mdirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multidimensional discrete item response theory — mdirt","text":"","code":"# LSAT6 dataset dat <- expand.table(LSAT6)  # fit with 2-3 latent classes (mod2 <- mdirt(dat, 2)) #>  Iteration: 1, Log-Lik: -3209.317, Max-Change: 2.67790 Iteration: 2, Log-Lik: -2475.451, Max-Change: 0.21401 Iteration: 3, Log-Lik: -2470.563, Max-Change: 0.09205 Iteration: 4, Log-Lik: -2469.778, Max-Change: 0.05245 Iteration: 5, Log-Lik: -2469.535, Max-Change: 0.03452 Iteration: 6, Log-Lik: -2469.405, Max-Change: 0.02589 Iteration: 7, Log-Lik: -2469.246, Max-Change: 0.02880 Iteration: 8, Log-Lik: -2469.158, Max-Change: 0.01855 Iteration: 9, Log-Lik: -2469.093, Max-Change: 0.01736 Iteration: 10, Log-Lik: -2469.039, Max-Change: 0.03472 Iteration: 11, Log-Lik: -2468.920, Max-Change: 0.01539 Iteration: 12, Log-Lik: -2468.878, Max-Change: 0.01420 Iteration: 13, Log-Lik: -2468.831, Max-Change: 0.02339 Iteration: 14, Log-Lik: -2468.770, Max-Change: 0.01408 Iteration: 15, Log-Lik: -2468.735, Max-Change: 0.01310 Iteration: 16, Log-Lik: -2468.695, Max-Change: 0.02106 Iteration: 17, Log-Lik: -2468.645, Max-Change: 0.01246 Iteration: 18, Log-Lik: -2468.615, Max-Change: 0.01221 Iteration: 19, Log-Lik: -2468.581, Max-Change: 0.02004 Iteration: 20, Log-Lik: -2468.534, Max-Change: 0.01204 Iteration: 21, Log-Lik: -2468.507, Max-Change: 0.01004 Iteration: 22, Log-Lik: -2468.496, Max-Change: 0.02473 Iteration: 23, Log-Lik: -2468.422, Max-Change: 0.01147 Iteration: 24, Log-Lik: -2468.398, Max-Change: 0.01041 Iteration: 25, Log-Lik: -2468.376, Max-Change: 0.02018 Iteration: 26, Log-Lik: -2468.328, Max-Change: 0.01024 Iteration: 27, Log-Lik: -2468.308, Max-Change: 0.00924 Iteration: 28, Log-Lik: -2468.300, Max-Change: 0.02179 Iteration: 29, Log-Lik: -2468.241, Max-Change: 0.00899 Iteration: 30, Log-Lik: -2468.223, Max-Change: 0.00917 Iteration: 31, Log-Lik: -2468.205, Max-Change: 0.01688 Iteration: 32, Log-Lik: -2468.170, Max-Change: 0.00823 Iteration: 33, Log-Lik: -2468.154, Max-Change: 0.00852 Iteration: 34, Log-Lik: -2468.138, Max-Change: 0.01546 Iteration: 35, Log-Lik: -2468.107, Max-Change: 0.00808 Iteration: 36, Log-Lik: -2468.093, Max-Change: 0.00770 Iteration: 37, Log-Lik: -2468.085, Max-Change: 0.01709 Iteration: 38, Log-Lik: -2468.047, Max-Change: 0.00756 Iteration: 39, Log-Lik: -2468.033, Max-Change: 0.00694 Iteration: 40, Log-Lik: -2468.033, Max-Change: 0.01749 Iteration: 41, Log-Lik: -2467.990, Max-Change: 0.00707 Iteration: 42, Log-Lik: -2467.978, Max-Change: 0.00670 Iteration: 43, Log-Lik: -2467.975, Max-Change: 0.01603 Iteration: 44, Log-Lik: -2467.939, Max-Change: 0.00663 Iteration: 45, Log-Lik: -2467.929, Max-Change: 0.00628 Iteration: 46, Log-Lik: -2467.927, Max-Change: 0.01508 Iteration: 47, Log-Lik: -2467.895, Max-Change: 0.00612 Iteration: 48, Log-Lik: -2467.885, Max-Change: 0.00614 Iteration: 49, Log-Lik: -2467.886, Max-Change: 0.01511 Iteration: 50, Log-Lik: -2467.853, Max-Change: 0.00604 Iteration: 51, Log-Lik: -2467.844, Max-Change: 0.00554 Iteration: 52, Log-Lik: -2467.835, Max-Change: 0.01010 Iteration: 53, Log-Lik: -2467.821, Max-Change: 0.00526 Iteration: 54, Log-Lik: -2467.814, Max-Change: 0.00533 Iteration: 55, Log-Lik: -2467.814, Max-Change: 0.01387 Iteration: 56, Log-Lik: -2467.787, Max-Change: 0.00518 Iteration: 57, Log-Lik: -2467.780, Max-Change: 0.00445 Iteration: 58, Log-Lik: -2467.778, Max-Change: 0.01108 Iteration: 59, Log-Lik: -2467.758, Max-Change: 0.00559 Iteration: 60, Log-Lik: -2467.752, Max-Change: 0.00397 Iteration: 61, Log-Lik: -2467.745, Max-Change: 0.00700 Iteration: 62, Log-Lik: -2467.738, Max-Change: 0.00388 Iteration: 63, Log-Lik: -2467.732, Max-Change: 0.00563 Iteration: 64, Log-Lik: -2467.724, Max-Change: 0.00766 Iteration: 65, Log-Lik: -2467.716, Max-Change: 0.00398 Iteration: 66, Log-Lik: -2467.711, Max-Change: 0.00555 Iteration: 67, Log-Lik: -2467.704, Max-Change: 0.00726 Iteration: 68, Log-Lik: -2467.696, Max-Change: 0.00448 Iteration: 69, Log-Lik: -2467.691, Max-Change: 0.00340 Iteration: 70, Log-Lik: -2467.691, Max-Change: 0.00960 Iteration: 71, Log-Lik: -2467.675, Max-Change: 0.00460 Iteration: 72, Log-Lik: -2467.671, Max-Change: 0.00320 Iteration: 73, Log-Lik: -2467.666, Max-Change: 0.00647 Iteration: 74, Log-Lik: -2467.660, Max-Change: 0.00455 Iteration: 75, Log-Lik: -2467.655, Max-Change: 0.00346 Iteration: 76, Log-Lik: -2467.651, Max-Change: 0.00712 Iteration: 77, Log-Lik: -2467.643, Max-Change: 0.00459 Iteration: 78, Log-Lik: -2467.639, Max-Change: 0.00319 Iteration: 79, Log-Lik: -2467.635, Max-Change: 0.00690 Iteration: 80, Log-Lik: -2467.628, Max-Change: 0.00439 Iteration: 81, Log-Lik: -2467.624, Max-Change: 0.00308 Iteration: 82, Log-Lik: -2467.620, Max-Change: 0.00652 Iteration: 83, Log-Lik: -2467.615, Max-Change: 0.00407 Iteration: 84, Log-Lik: -2467.611, Max-Change: 0.00291 Iteration: 85, Log-Lik: -2467.607, Max-Change: 0.00631 Iteration: 86, Log-Lik: -2467.602, Max-Change: 0.00328 Iteration: 87, Log-Lik: -2467.598, Max-Change: 0.00354 Iteration: 88, Log-Lik: -2467.595, Max-Change: 0.00435 Iteration: 89, Log-Lik: -2467.591, Max-Change: 0.00248 Iteration: 90, Log-Lik: -2467.589, Max-Change: 0.00331 Iteration: 91, Log-Lik: -2467.585, Max-Change: 0.00380 Iteration: 92, Log-Lik: -2467.582, Max-Change: 0.00267 Iteration: 93, Log-Lik: -2467.580, Max-Change: 0.00317 Iteration: 94, Log-Lik: -2467.577, Max-Change: 0.00345 Iteration: 95, Log-Lik: -2467.574, Max-Change: 0.00281 Iteration: 96, Log-Lik: -2467.572, Max-Change: 0.00304 Iteration: 97, Log-Lik: -2467.569, Max-Change: 0.00319 Iteration: 98, Log-Lik: -2467.566, Max-Change: 0.00287 Iteration: 99, Log-Lik: -2467.564, Max-Change: 0.00293 Iteration: 100, Log-Lik: -2467.561, Max-Change: 0.00299 Iteration: 101, Log-Lik: -2467.559, Max-Change: 0.00287 Iteration: 102, Log-Lik: -2467.557, Max-Change: 0.00283 Iteration: 103, Log-Lik: -2467.554, Max-Change: 0.00284 Iteration: 104, Log-Lik: -2467.552, Max-Change: 0.00284 Iteration: 105, Log-Lik: -2467.550, Max-Change: 0.00276 Iteration: 106, Log-Lik: -2467.548, Max-Change: 0.00271 Iteration: 107, Log-Lik: -2467.546, Max-Change: 0.00278 Iteration: 108, Log-Lik: -2467.544, Max-Change: 0.00269 Iteration: 109, Log-Lik: -2467.542, Max-Change: 0.00265 Iteration: 110, Log-Lik: -2467.540, Max-Change: 0.00272 Iteration: 111, Log-Lik: -2467.538, Max-Change: 0.00264 Iteration: 112, Log-Lik: -2467.536, Max-Change: 0.00258 Iteration: 113, Log-Lik: -2467.534, Max-Change: 0.00264 Iteration: 114, Log-Lik: -2467.532, Max-Change: 0.00258 Iteration: 115, Log-Lik: -2467.530, Max-Change: 0.00252 Iteration: 116, Log-Lik: -2467.528, Max-Change: 0.00257 Iteration: 117, Log-Lik: -2467.527, Max-Change: 0.00253 Iteration: 118, Log-Lik: -2467.525, Max-Change: 0.00247 Iteration: 119, Log-Lik: -2467.523, Max-Change: 0.00249 Iteration: 120, Log-Lik: -2467.522, Max-Change: 0.00248 Iteration: 121, Log-Lik: -2467.520, Max-Change: 0.00241 Iteration: 122, Log-Lik: -2467.518, Max-Change: 0.00241 Iteration: 123, Log-Lik: -2467.517, Max-Change: 0.00243 Iteration: 124, Log-Lik: -2467.515, Max-Change: 0.00236 Iteration: 125, Log-Lik: -2467.513, Max-Change: 0.00234 Iteration: 126, Log-Lik: -2467.512, Max-Change: 0.00238 Iteration: 127, Log-Lik: -2467.510, Max-Change: 0.00230 Iteration: 128, Log-Lik: -2467.509, Max-Change: 0.00226 Iteration: 129, Log-Lik: -2467.507, Max-Change: 0.00233 Iteration: 130, Log-Lik: -2467.506, Max-Change: 0.00225 Iteration: 131, Log-Lik: -2467.504, Max-Change: 0.00219 Iteration: 132, Log-Lik: -2467.503, Max-Change: 0.00229 Iteration: 133, Log-Lik: -2467.502, Max-Change: 0.00220 Iteration: 134, Log-Lik: -2467.500, Max-Change: 0.00212 Iteration: 135, Log-Lik: -2467.499, Max-Change: 0.00224 Iteration: 136, Log-Lik: -2467.497, Max-Change: 0.00215 Iteration: 137, Log-Lik: -2467.496, Max-Change: 0.00206 Iteration: 138, Log-Lik: -2467.495, Max-Change: 0.00220 Iteration: 139, Log-Lik: -2467.494, Max-Change: 0.00210 Iteration: 140, Log-Lik: -2467.492, Max-Change: 0.00187 Iteration: 141, Log-Lik: -2467.491, Max-Change: 0.00201 Iteration: 142, Log-Lik: -2467.490, Max-Change: 0.00317 Iteration: 143, Log-Lik: -2467.488, Max-Change: 0.00198 Iteration: 144, Log-Lik: -2467.487, Max-Change: 0.00189 Iteration: 145, Log-Lik: -2467.486, Max-Change: 0.00406 Iteration: 146, Log-Lik: -2467.483, Max-Change: 0.00201 Iteration: 147, Log-Lik: -2467.482, Max-Change: 0.00181 Iteration: 148, Log-Lik: -2467.481, Max-Change: 0.00400 Iteration: 149, Log-Lik: -2467.478, Max-Change: 0.00197 Iteration: 150, Log-Lik: -2467.477, Max-Change: 0.00176 Iteration: 151, Log-Lik: -2467.477, Max-Change: 0.00376 Iteration: 152, Log-Lik: -2467.474, Max-Change: 0.00187 Iteration: 153, Log-Lik: -2467.473, Max-Change: 0.00170 Iteration: 154, Log-Lik: -2467.473, Max-Change: 0.00390 Iteration: 155, Log-Lik: -2467.470, Max-Change: 0.00187 Iteration: 156, Log-Lik: -2467.469, Max-Change: 0.00166 Iteration: 157, Log-Lik: -2467.468, Max-Change: 0.00336 Iteration: 158, Log-Lik: -2467.466, Max-Change: 0.00170 Iteration: 159, Log-Lik: -2467.465, Max-Change: 0.00159 Iteration: 160, Log-Lik: -2467.465, Max-Change: 0.00373 Iteration: 161, Log-Lik: -2467.463, Max-Change: 0.00177 Iteration: 162, Log-Lik: -2467.462, Max-Change: 0.00156 Iteration: 163, Log-Lik: -2467.461, Max-Change: 0.00308 Iteration: 164, Log-Lik: -2467.459, Max-Change: 0.00157 Iteration: 165, Log-Lik: -2467.459, Max-Change: 0.00149 Iteration: 166, Log-Lik: -2467.458, Max-Change: 0.00352 Iteration: 167, Log-Lik: -2467.456, Max-Change: 0.00166 Iteration: 168, Log-Lik: -2467.455, Max-Change: 0.00147 Iteration: 169, Log-Lik: -2467.455, Max-Change: 0.00282 Iteration: 170, Log-Lik: -2467.453, Max-Change: 0.00154 Iteration: 171, Log-Lik: -2467.453, Max-Change: 0.00139 Iteration: 172, Log-Lik: -2467.452, Max-Change: 0.00333 Iteration: 173, Log-Lik: -2467.450, Max-Change: 0.00155 Iteration: 174, Log-Lik: -2467.450, Max-Change: 0.00138 Iteration: 175, Log-Lik: -2467.449, Max-Change: 0.00283 Iteration: 176, Log-Lik: -2467.448, Max-Change: 0.00161 Iteration: 177, Log-Lik: -2467.447, Max-Change: 0.00127 Iteration: 178, Log-Lik: -2467.446, Max-Change: 0.00220 Iteration: 179, Log-Lik: -2467.446, Max-Change: 0.00138 Iteration: 180, Log-Lik: -2467.445, Max-Change: 0.00124 Iteration: 181, Log-Lik: -2467.445, Max-Change: 0.00307 Iteration: 182, Log-Lik: -2467.443, Max-Change: 0.00142 Iteration: 183, Log-Lik: -2467.443, Max-Change: 0.00127 Iteration: 184, Log-Lik: -2467.442, Max-Change: 0.00248 Iteration: 185, Log-Lik: -2467.441, Max-Change: 0.00144 Iteration: 186, Log-Lik: -2467.440, Max-Change: 0.00116 Iteration: 187, Log-Lik: -2467.440, Max-Change: 0.00212 Iteration: 188, Log-Lik: -2467.439, Max-Change: 0.00132 Iteration: 189, Log-Lik: -2467.439, Max-Change: 0.00114 Iteration: 190, Log-Lik: -2467.438, Max-Change: 0.00267 Iteration: 191, Log-Lik: -2467.437, Max-Change: 0.00125 Iteration: 192, Log-Lik: -2467.437, Max-Change: 0.00115 Iteration: 193, Log-Lik: -2467.436, Max-Change: 0.00233 Iteration: 194, Log-Lik: -2467.435, Max-Change: 0.00126 Iteration: 195, Log-Lik: -2467.435, Max-Change: 0.00110 Iteration: 196, Log-Lik: -2467.435, Max-Change: 0.00227 Iteration: 197, Log-Lik: -2467.434, Max-Change: 0.00123 Iteration: 198, Log-Lik: -2467.433, Max-Change: 0.00107 Iteration: 199, Log-Lik: -2467.433, Max-Change: 0.00237 Iteration: 200, Log-Lik: -2467.432, Max-Change: 0.00133 Iteration: 201, Log-Lik: -2467.432, Max-Change: 0.00161 Iteration: 202, Log-Lik: -2467.431, Max-Change: 0.00163 Iteration: 203, Log-Lik: -2467.431, Max-Change: 0.00107 Iteration: 204, Log-Lik: -2467.430, Max-Change: 0.00099 Iteration: 205, Log-Lik: -2467.430, Max-Change: 0.00244 Iteration: 206, Log-Lik: -2467.429, Max-Change: 0.00111 Iteration: 207, Log-Lik: -2467.429, Max-Change: 0.00100 Iteration: 208, Log-Lik: -2467.429, Max-Change: 0.00199 Iteration: 209, Log-Lik: -2467.428, Max-Change: 0.00090 Iteration: 210, Log-Lik: -2467.428, Max-Change: 0.00123 Iteration: 211, Log-Lik: -2467.427, Max-Change: 0.00080 Iteration: 212, Log-Lik: -2467.427, Max-Change: 0.00094 Iteration: 213, Log-Lik: -2467.427, Max-Change: 0.00090 Iteration: 214, Log-Lik: -2467.427, Max-Change: 0.00227 Iteration: 215, Log-Lik: -2467.426, Max-Change: 0.00102 Iteration: 216, Log-Lik: -2467.425, Max-Change: 0.00093 Iteration: 217, Log-Lik: -2467.425, Max-Change: 0.00176 Iteration: 218, Log-Lik: -2467.425, Max-Change: 0.00081 Iteration: 219, Log-Lik: -2467.424, Max-Change: 0.00113 Iteration: 220, Log-Lik: -2467.424, Max-Change: 0.00074 Iteration: 221, Log-Lik: -2467.424, Max-Change: 0.00086 Iteration: 222, Log-Lik: -2467.424, Max-Change: 0.00083 Iteration: 223, Log-Lik: -2467.424, Max-Change: 0.00196 Iteration: 224, Log-Lik: -2467.423, Max-Change: 0.00105 Iteration: 225, Log-Lik: -2467.423, Max-Change: 0.00069 Iteration: 226, Log-Lik: -2467.422, Max-Change: 0.00081 Iteration: 227, Log-Lik: -2467.422, Max-Change: 0.00106 Iteration: 228, Log-Lik: -2467.422, Max-Change: 0.00070 Iteration: 229, Log-Lik: -2467.422, Max-Change: 0.00071 Iteration: 230, Log-Lik: -2467.421, Max-Change: 0.00103 Iteration: 231, Log-Lik: -2467.421, Max-Change: 0.00068 Iteration: 232, Log-Lik: -2467.421, Max-Change: 0.00069 Iteration: 233, Log-Lik: -2467.421, Max-Change: 0.00100 Iteration: 234, Log-Lik: -2467.421, Max-Change: 0.00066 Iteration: 235, Log-Lik: -2467.420, Max-Change: 0.00068 Iteration: 236, Log-Lik: -2467.420, Max-Change: 0.00098 Iteration: 237, Log-Lik: -2467.420, Max-Change: 0.00065 Iteration: 238, Log-Lik: -2467.420, Max-Change: 0.00067 Iteration: 239, Log-Lik: -2467.420, Max-Change: 0.00096 Iteration: 240, Log-Lik: -2467.419, Max-Change: 0.00063 Iteration: 241, Log-Lik: -2467.419, Max-Change: 0.00066 Iteration: 242, Log-Lik: -2467.419, Max-Change: 0.00094 Iteration: 243, Log-Lik: -2467.419, Max-Change: 0.00062 Iteration: 244, Log-Lik: -2467.419, Max-Change: 0.00064 Iteration: 245, Log-Lik: -2467.418, Max-Change: 0.00092 Iteration: 246, Log-Lik: -2467.418, Max-Change: 0.00061 Iteration: 247, Log-Lik: -2467.418, Max-Change: 0.00063 Iteration: 248, Log-Lik: -2467.418, Max-Change: 0.00090 Iteration: 249, Log-Lik: -2467.418, Max-Change: 0.00060 Iteration: 250, Log-Lik: -2467.418, Max-Change: 0.00062 Iteration: 251, Log-Lik: -2467.417, Max-Change: 0.00088 Iteration: 252, Log-Lik: -2467.417, Max-Change: 0.00058 Iteration: 253, Log-Lik: -2467.417, Max-Change: 0.00061 Iteration: 254, Log-Lik: -2467.417, Max-Change: 0.00086 Iteration: 255, Log-Lik: -2467.417, Max-Change: 0.00057 Iteration: 256, Log-Lik: -2467.417, Max-Change: 0.00059 Iteration: 257, Log-Lik: -2467.417, Max-Change: 0.00085 Iteration: 258, Log-Lik: -2467.416, Max-Change: 0.00056 Iteration: 259, Log-Lik: -2467.416, Max-Change: 0.00058 Iteration: 260, Log-Lik: -2467.416, Max-Change: 0.00083 Iteration: 261, Log-Lik: -2467.416, Max-Change: 0.00055 Iteration: 262, Log-Lik: -2467.416, Max-Change: 0.00057 Iteration: 263, Log-Lik: -2467.416, Max-Change: 0.00081 Iteration: 264, Log-Lik: -2467.416, Max-Change: 0.00054 Iteration: 265, Log-Lik: -2467.415, Max-Change: 0.00055 Iteration: 266, Log-Lik: -2467.415, Max-Change: 0.00079 Iteration: 267, Log-Lik: -2467.415, Max-Change: 0.00053 Iteration: 268, Log-Lik: -2467.415, Max-Change: 0.00054 Iteration: 269, Log-Lik: -2467.415, Max-Change: 0.00078 Iteration: 270, Log-Lik: -2467.415, Max-Change: 0.00052 Iteration: 271, Log-Lik: -2467.415, Max-Change: 0.00053 Iteration: 272, Log-Lik: -2467.414, Max-Change: 0.00076 Iteration: 273, Log-Lik: -2467.414, Max-Change: 0.00051 Iteration: 274, Log-Lik: -2467.414, Max-Change: 0.00052 Iteration: 275, Log-Lik: -2467.414, Max-Change: 0.00075 Iteration: 276, Log-Lik: -2467.414, Max-Change: 0.00050 Iteration: 277, Log-Lik: -2467.414, Max-Change: 0.00051 Iteration: 278, Log-Lik: -2467.414, Max-Change: 0.00073 Iteration: 279, Log-Lik: -2467.414, Max-Change: 0.00049 Iteration: 280, Log-Lik: -2467.414, Max-Change: 0.00049 Iteration: 281, Log-Lik: -2467.413, Max-Change: 0.00072 Iteration: 282, Log-Lik: -2467.413, Max-Change: 0.00048 Iteration: 283, Log-Lik: -2467.413, Max-Change: 0.00048 Iteration: 284, Log-Lik: -2467.413, Max-Change: 0.00070 Iteration: 285, Log-Lik: -2467.413, Max-Change: 0.00047 Iteration: 286, Log-Lik: -2467.413, Max-Change: 0.00047 Iteration: 287, Log-Lik: -2467.413, Max-Change: 0.00069 Iteration: 288, Log-Lik: -2467.413, Max-Change: 0.00046 Iteration: 289, Log-Lik: -2467.413, Max-Change: 0.00046 Iteration: 290, Log-Lik: -2467.413, Max-Change: 0.00067 Iteration: 291, Log-Lik: -2467.412, Max-Change: 0.00045 Iteration: 292, Log-Lik: -2467.412, Max-Change: 0.00045 Iteration: 293, Log-Lik: -2467.412, Max-Change: 0.00066 Iteration: 294, Log-Lik: -2467.412, Max-Change: 0.00044 Iteration: 295, Log-Lik: -2467.412, Max-Change: 0.00044 Iteration: 296, Log-Lik: -2467.412, Max-Change: 0.00064 Iteration: 297, Log-Lik: -2467.412, Max-Change: 0.00043 Iteration: 298, Log-Lik: -2467.412, Max-Change: 0.00043 Iteration: 299, Log-Lik: -2467.412, Max-Change: 0.00063 Iteration: 300, Log-Lik: -2467.412, Max-Change: 0.00042 Iteration: 301, Log-Lik: -2467.412, Max-Change: 0.00042 Iteration: 302, Log-Lik: -2467.412, Max-Change: 0.00062 Iteration: 303, Log-Lik: -2467.411, Max-Change: 0.00041 Iteration: 304, Log-Lik: -2467.411, Max-Change: 0.00041 Iteration: 305, Log-Lik: -2467.411, Max-Change: 0.00061 Iteration: 306, Log-Lik: -2467.411, Max-Change: 0.00040 Iteration: 307, Log-Lik: -2467.411, Max-Change: 0.00040 Iteration: 308, Log-Lik: -2467.411, Max-Change: 0.00059 Iteration: 309, Log-Lik: -2467.411, Max-Change: 0.00040 Iteration: 310, Log-Lik: -2467.411, Max-Change: 0.00040 Iteration: 311, Log-Lik: -2467.411, Max-Change: 0.00058 Iteration: 312, Log-Lik: -2467.411, Max-Change: 0.00039 Iteration: 313, Log-Lik: -2467.411, Max-Change: 0.00039 Iteration: 314, Log-Lik: -2467.411, Max-Change: 0.00057 Iteration: 315, Log-Lik: -2467.411, Max-Change: 0.00038 Iteration: 316, Log-Lik: -2467.410, Max-Change: 0.00038 Iteration: 317, Log-Lik: -2467.410, Max-Change: 0.00056 Iteration: 318, Log-Lik: -2467.410, Max-Change: 0.00037 Iteration: 319, Log-Lik: -2467.410, Max-Change: 0.00037 Iteration: 320, Log-Lik: -2467.410, Max-Change: 0.00055 Iteration: 321, Log-Lik: -2467.410, Max-Change: 0.00037 Iteration: 322, Log-Lik: -2467.410, Max-Change: 0.00036 Iteration: 323, Log-Lik: -2467.410, Max-Change: 0.00054 Iteration: 324, Log-Lik: -2467.410, Max-Change: 0.00036 Iteration: 325, Log-Lik: -2467.410, Max-Change: 0.00036 Iteration: 326, Log-Lik: -2467.410, Max-Change: 0.00052 Iteration: 327, Log-Lik: -2467.410, Max-Change: 0.00035 Iteration: 328, Log-Lik: -2467.410, Max-Change: 0.00035 Iteration: 329, Log-Lik: -2467.410, Max-Change: 0.00051 Iteration: 330, Log-Lik: -2467.410, Max-Change: 0.00034 Iteration: 331, Log-Lik: -2467.410, Max-Change: 0.00034 Iteration: 332, Log-Lik: -2467.410, Max-Change: 0.00050 Iteration: 333, Log-Lik: -2467.409, Max-Change: 0.00034 Iteration: 334, Log-Lik: -2467.409, Max-Change: 0.00034 Iteration: 335, Log-Lik: -2467.409, Max-Change: 0.00049 Iteration: 336, Log-Lik: -2467.409, Max-Change: 0.00033 Iteration: 337, Log-Lik: -2467.409, Max-Change: 0.00033 Iteration: 338, Log-Lik: -2467.409, Max-Change: 0.00048 Iteration: 339, Log-Lik: -2467.409, Max-Change: 0.00032 Iteration: 340, Log-Lik: -2467.409, Max-Change: 0.00032 Iteration: 341, Log-Lik: -2467.409, Max-Change: 0.00047 Iteration: 342, Log-Lik: -2467.409, Max-Change: 0.00032 Iteration: 343, Log-Lik: -2467.409, Max-Change: 0.00032 Iteration: 344, Log-Lik: -2467.409, Max-Change: 0.00046 Iteration: 345, Log-Lik: -2467.409, Max-Change: 0.00031 Iteration: 346, Log-Lik: -2467.409, Max-Change: 0.00031 Iteration: 347, Log-Lik: -2467.409, Max-Change: 0.00045 Iteration: 348, Log-Lik: -2467.409, Max-Change: 0.00031 Iteration: 349, Log-Lik: -2467.409, Max-Change: 0.00030 Iteration: 350, Log-Lik: -2467.409, Max-Change: 0.00045 Iteration: 351, Log-Lik: -2467.409, Max-Change: 0.00030 Iteration: 352, Log-Lik: -2467.409, Max-Change: 0.00030 Iteration: 353, Log-Lik: -2467.409, Max-Change: 0.00044 Iteration: 354, Log-Lik: -2467.409, Max-Change: 0.00029 Iteration: 355, Log-Lik: -2467.408, Max-Change: 0.00029 Iteration: 356, Log-Lik: -2467.408, Max-Change: 0.00043 Iteration: 357, Log-Lik: -2467.408, Max-Change: 0.00029 Iteration: 358, Log-Lik: -2467.408, Max-Change: 0.00029 Iteration: 359, Log-Lik: -2467.408, Max-Change: 0.00042 Iteration: 360, Log-Lik: -2467.408, Max-Change: 0.00028 Iteration: 361, Log-Lik: -2467.408, Max-Change: 0.00028 Iteration: 362, Log-Lik: -2467.408, Max-Change: 0.00041 Iteration: 363, Log-Lik: -2467.408, Max-Change: 0.00000 #>  #> Call: #> mdirt(data = dat, model = 2) #>  #> Latent class model with 2 classes and 2 profiles. #> Converged within 1e-04 tolerance after 363 EM iterations. #> mirt version: 1.43  #> M-step optimizer: nlminb  #> EM acceleration: Ramsay #> Latent density type: discrete #>  #> Log-likelihood = -2467.408 #> Estimated parameters: 11  #> AIC = 4956.816 #> BIC = 5010.802; SABIC = 4975.865 #> G2 (20) = 22.74, p = 0.3018, RMSEA = 0.012 if (FALSE) { # \\dontrun{ (mod3 <- mdirt(dat, 3)) summary(mod2) residuals(mod2) residuals(mod2, type = 'exp') anova(mod2, mod3) M2(mod2) itemfit(mod2)  # generate classification plots plot(mod2) plot(mod2, facet_items = FALSE) plot(mod2, profile = TRUE)  # available for polytomous data mod <- mdirt(Science, 2) summary(mod) plot(mod) plot(mod, profile=TRUE)  # classification based on response patterns fscores(mod2, full.scores = FALSE)  # classify individuals either with the largest posterior probability..... fs <- fscores(mod2) head(fs) classes <- 1:2 class_max <- classes[apply(apply(fs, 1, max) == fs, 1, which)] table(class_max)  # ... or by probability sampling (i.e., plausible value draws) class_prob <- apply(fs, 1, function(x) sample(1:2, 1, prob=x)) table(class_prob)  # plausible value imputations for stochastic classification in both classes pvs <- fscores(mod2, plausible.draws=10) tabs <- lapply(pvs, function(x) apply(x, 2, table)) tabs[[1]]   # fit with random starting points (run in parallel to save time) if(interactive()) mirtCluster() mod <- mdirt(dat, 2, nruns=10)  #-------------------------- # Grade of measurement model  # define a custom Theta grid for including a 'fuzzy' class membership (Theta <- matrix(c(1, 0, .5, .5, 0, 1), nrow=3 , ncol=2, byrow=TRUE)) (mod_gom <- mdirt(dat, 2, customTheta = Theta)) summary(mod_gom)  #----------------- # Multidimensional discrete latent class model  dat <- key2binary(SAT12,      key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  # define Theta grid for three latent classes (Theta <- thetaComb(0:1, 3)) (mod_discrete <- mdirt(dat, 3, customTheta = Theta)) summary(mod_discrete)  # Located latent class model model <- mirt.model('C1 = 1-32                      C2 = 1-32                      C3 = 1-32                      CONSTRAIN = (1-32, a1), (1-32, a2), (1-32, a3)') (mod_located <- mdirt(dat, model, customTheta = diag(3))) summary(mod_located)  #----------------- ### DINA model example # generate some suitable data for a two dimensional DINA application #     (first columns are intercepts) set.seed(1) Theta <- expand.table(matrix(c(1,0,0,0,                                1,1,0,0,                                1,0,1,0,                                1,1,1,1), 4, 4, byrow=TRUE),                       freq = c(200,200,100,500)) a <- matrix(c(rnorm(15, -1.5, .5), rlnorm(5, .2, .3), numeric(15), rlnorm(5, .2, .3),               numeric(15), rlnorm(5, .2, .3)), 15, 4)  guess <- plogis(a[11:15,1]) # population guess slip <- 1 - plogis(rowSums(a[11:15,])) # population slip  dat <- simdata(a, Theta=Theta, itemtype = 'lca')  # first column is the intercept, 2nd and 3rd are attributes theta <- cbind(1, thetaComb(0:1, 2)) theta <- cbind(theta, theta[,2] * theta[,3]) #DINA interaction of main attributes model <- mirt.model('Intercept = 1-15                      A1 = 1-5                      A2 = 6-10                      A1A2 = 11-15')  # last 5 items are DINA (first 10 are unidimensional C-RUMs) DINA <- mdirt(dat, model, customTheta = theta) coef(DINA, simplify=TRUE) summary(DINA) M2(DINA) # fits well (as it should)  cfs <- coef(DINA, simplify=TRUE)$items[11:15,] cbind(guess, estguess = plogis(cfs[,1])) cbind(slip, estslip = 1 - plogis(rowSums(cfs)))   ### DINO model example theta <- cbind(1, thetaComb(0:1, 2)) # define theta matrix with negative interaction term (theta <- cbind(theta, -theta[,2] * theta[,3]))  model <- mirt.model('Intercept = 1-15                      A1 = 1-5, 11-15                      A2 = 6-15                      Yoshi = 11-15                      CONSTRAIN = (11,a2,a3,a4), (12,a2,a3,a4), (13,a2,a3,a4),                                  (14,a2,a3,a4), (15,a2,a3,a4)')  # last five items are DINOs (first 10 are unidimensional C-RUMs) DINO <- mdirt(dat, model, customTheta = theta) coef(DINO, simplify=TRUE) summary(DINO) M2(DINO) #doesn't fit as well, because not the generating model  ## C-RUM (analogous to MIRT model) theta <- cbind(1, thetaComb(0:1, 2)) model <- mirt.model('Intercept = 1-15                      A1 = 1-5, 11-15                      A2 = 6-15')  CRUM <- mdirt(dat, model, customTheta = theta) coef(CRUM, simplify=TRUE) summary(CRUM)  # good fit, but over-saturated (main effects for items 11-15 can be set to 0) M2(CRUM)  #------------------ # multidimensional latent class model  dat <- key2binary(SAT12,      key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  # 5 latent classes within 2 different sets of items model <- mirt.model('C1 = 1-16                      C2 = 1-16                      C3 = 1-16                      C4 = 1-16                      C5 = 1-16                      C6 = 17-32                      C7 = 17-32                      C8 = 17-32                      C9 = 17-32                      C10 = 17-32                      CONSTRAIN = (1-16, a1), (1-16, a2), (1-16, a3), (1-16, a4), (1-16, a5),                        (17-32, a6), (17-32, a7), (17-32, a8), (17-32, a9), (17-32, a10)')  theta <- diag(10) # defined explicitly. Otherwise, this profile is assumed mod <- mdirt(dat, model, customTheta = theta) coef(mod, simplify=TRUE) summary(mod)  #------------------ # multiple group with constrained group probabilities  dat <- key2binary(SAT12,    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) group <- rep(c('G1', 'G2'), each = nrow(SAT12)/2) Theta <- diag(2)  # the latent class parameters are technically located in the (nitems + 1) location model <- mirt.model('A1 = 1-32                      A2 = 1-32                      CONSTRAINB = (33, c1)') mod <- mdirt(dat, model, group = group, customTheta = Theta) coef(mod, simplify=TRUE) summary(mod)   #------------------ # Probabilistic Guttman Model (Proctor, 1970)  # example analysis can also be found in the sirt package (see ?prob.guttman) data(data.read, package = 'sirt') head(data.read)  Theta <- matrix(c(1,0,0,0,                   1,1,0,0,                   1,1,1,0,                   1,1,1,1), 4, byrow=TRUE)  model <- mirt.model(\"INTERCEPT = 1-12                      C1 = 1,7,9,11                      C2 = 2,5,8,10,12                      C3 = 3,4,6\")  mod <- mdirt(data.read, model, customTheta=Theta) summary(mod)  M2(mod) itemfit(mod)   } # }"},{"path":"https://philchalmers.github.io/mirt/reference/mirt-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Full information maximum likelihood estimation of IRT models. — mirt-package","title":"Full information maximum likelihood estimation of IRT models. — mirt-package","text":"Full information maximum likelihood estimation multidimensional IRT models","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Full information maximum likelihood estimation of IRT models. — mirt-package","text":"Analysis dichotomous polytomous response data using unidimensional multidimensional latent trait models Item Response Theory (IRT) paradigm. Exploratory confirmatory models can estimated quadrature (EM) stochastic (MHRM) methods. Confirmatory bi-factor two-tier analyses available modeling item testlets. Multiple group analysis mixed effects designs also available detecting differential item test functioning well modeling item person covariates. Finally, latent class models DINA, DINO, multidimensional latent class, mixture zero-inflated IRT models, several discrete variable models supported. Users interested recent version package can visit https://github.com/philchalmers/mirt follow instructions installing package source. Questions regarding package can sent mirt-package Google Group, located https://groups.google.com/forum/#!forum/mirt-package. User contributed files, workshop files, evaluated help files also available package wiki (https://github.com/philchalmers/mirt/wiki).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Full information maximum likelihood estimation of IRT models. — mirt-package","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Full information maximum likelihood estimation of IRT models. — mirt-package","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"mirt fits maximum likelihood (maximum posteriori) factor analysis model mixture dichotomous polytomous data item response theory paradigm using either Cai's (2010) Metropolis-Hastings Robbins-Monro (MHRM) algorithm, EM algorithm approach outlined Bock Aitkin (1981) using rectangular quasi-Monte Carlo integration grids, stochastic EM (.e., first two stages MH-RM algorithm). Models containing 'explanatory' person item level predictors can included using mixedmirt function, though latent regression models can fit using formula input function. Tests form two-tier bi-factor structure estimated bfactor function, uses dimension reduction EM algorithm modeling item parcels.  Multiple group analyses (useful DIF DTF testing) also available using multipleGroup function.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"","code":"mirt(   data,   model = 1,   itemtype = NULL,   guess = 0,   upper = 1,   SE = FALSE,   covdata = NULL,   formula = NULL,   itemdesign = NULL,   item.formula = NULL,   SE.type = \"Oakes\",   method = \"EM\",   optimizer = NULL,   dentype = \"Gaussian\",   pars = NULL,   constrain = NULL,   calcNull = FALSE,   draws = 5000,   survey.weights = NULL,   quadpts = NULL,   TOL = NULL,   gpcm_mats = list(),   grsm.block = NULL,   rsm.block = NULL,   monopoly.k = 1L,   key = NULL,   large = FALSE,   GenRandomPars = FALSE,   accelerate = \"Ramsay\",   verbose = TRUE,   solnp_args = list(),   nloptr_args = list(),   spline_args = list(),   control = list(),   technical = list(),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"data matrix data.frame consists numerically ordered data, organized form integers,  missing data coded NA (convert ordered factor data.frame see data.matrix) model string passed (object returned ) mirt.model, declaring IRT model estimated (loadings, constraints, priors, etc). exploratory IRT models, single numeric value indicating number factors extract also supported. Default 1, indicating unidimensional model fit unless otherwise specified itemtype type items modeled, declared either ) single value   recycled item, b) vector respective item, c) applicable,   matrix columns equal number items rows equal number   latent classes. NULL default assumes items follow graded   2PL structure, however may changed following: 'Rasch' - Rasch/partial credit model constraining slopes 1 freely estimating       variance parameters (alternatively, can specified applying equality constraints       slope parameters 'gpcm' '2PL'; Rasch, 1960) '1PL', '2PL', '3PL', '3PLu', '4PL' - 1-4 parameter logistic model,       3PL estimates lower asymptote 3PLu estimates upper asymptote       (Lord Novick, 1968; Lord, 1980). Note specifying '1PL' automatically estimate       variance latent trait compared 'Rasch' type '5PL' - 5 parameter logistic model estimate asymmetric logistic      response curves. Currently restricted unidimensional models 'CLL' - complementary log-log link model.       Currently restricted unidimensional models 'ULL' - unipolar log-logistic model (Lucke, 2015). Note use itemtype       automatically use log-normal distribution latent traits 'graded' - graded response model (Samejima, 1969) 'grsm' - graded ratings scale model       classical IRT parameterization (restricted unidimensional models; Muraki, 1992) 'gpcm' 'gpcmIRT' - generalized partial credit model slope-intercept       classical parameterization. 'gpcmIRT' restricted unidimensional models. Note       optional scoring matrices 'gpcm' available gpcm_mats input (Muraki, 1992) 'rsm' - Rasch rating scale model using 'gpcmIRT' structure       (unidimensional ; Andrich, 1978) 'nominal' - nominal response model (Bock, 1972) 'ideal' - dichotomous ideal point model (Maydeu-Olivares, 2006) 'ggum' - generalized graded unfolding model (Roberts, Donoghue, & Laughlin, 2000)       multidimensional extension 'sequential' - multidimensional sequential response model (Tutz, 1990) slope-intercept form 'Tutz' - 'sequential' itemtype, except slopes fixed 1       latent variance terms freely estimated (similar 'Rasch' itemtype input) 'PC1PL', 'PC2PL', 'PC3PL' - 1-3 parameter partially compensatory model.       Note constraining slopes equal across items also reduce model       Embretson's (.k.. Whitely's) multicomponent model (1980), 'PC1PL'       slopes fixed 1 latent trait variance terms estimated '2PLNRM', '3PLNRM', '3PLuNRM', '4PLNRM' - 2-4 parameter nested       logistic model, 3PLNRM estimates lower asymptote 3PLuNRM estimates       upper asymptote (Suh Bolt, 2010) 'spline' - spline response model bs (default)       ns function (Winsberg, Thissen, Wainer, 1984) 'monopoly' - monotonic polynomial model unidimensional tests       dichotomous polytomous response data (Falk Cai, 2016) Additionally, user defined item classes can also defined using createItem function guess fixed pseudo-guessing parameters. Can entered single value assign global guessing parameter may entered numeric vector corresponding item upper fixed upper bound parameters 4-PL model. Can entered single value assign global guessing parameter may entered numeric vector corresponding item SE logical; estimate standard errors computing parameter information matrix? See SE.type type estimates available covdata data.frame data used latent regression models formula R formula (list formulas) indicating latent traits can regressed using external covariates covdata. named list formulas supplied (names correspond latent trait names model) specific regression effects can estimated factor. Supplying single formula estimate regression parameters latent traits default itemdesign data.frame rows equal number items columns containing item-design effects. items included design structure (.e., left canonical structure) fewer rows can used, however rownames must defined matched colnames data input. item design matrix constructed use item.formula. Providing input fix associated 'd' intercepts 0, applicable item.formula R formula used specify intercept decomposition (e.g.,   LLTM; Fischer, 1983). Note right-hand side formula required   compensatory models. non-compensatory itemtypes (e.g., 'PC1PL') formula must include   name latent trait left hand side expression indicate   trait specification intercepts decomposed (see MLTM; Embretson, 1984) SE.type type estimation method use calculating parameter information matrix   computing standard errors wald tests. Can :  'Richardson', 'forward', 'central' numerical Richardson,       forward difference, central difference evaluation observed Hessian matrix 'crossprod' 'Louis' standard error computations based variance       Fisher scores well Louis' (1982) exact computation observed information matrix.       Note Louis' estimates can take long time obtain large sample sizes long tests 'sandwich' sandwich covariance estimate based       'crossprod' 'Oakes' estimates (see Chalmers, 2018, details) 'sandwich.Louis' sandwich covariance estimate based       'crossprod' 'Louis' estimates 'Oakes' Oakes' (1999) method using central difference approximation       (see Chalmers, 2018, details) 'SEM' supplemented EM (disables accelerate option automatically; EM ) 'Fisher' expected information, 'complete' information based       complete-data Hessian used EM algorithm 'MHRM' 'FMHRM' stochastic approximations observed information matrix       based Robbins-Monro filter fixed number MHRM draws without RM filter.       options supported method = 'MHRM' 'numerical' obtain numerical estimate call optim       method = 'BL' Note 'SEM' method becomes sensitive ML solution   reached sufficient precision, may sensitive   history EM cycles stable/sufficient convergence respective estimates.   Increasing number iterations (increasing NCYCLES decreasing   TOL, see ) help improve accuracy, can   run parallel mirtCluster object defined (  used Oakes' method well). Additionally,   inspecting symmetry ACOV matrix convergence issues passing   technical = list(symmetric = FALSE) can helpful determine sufficient   solution reached method character object specifying estimation algorithm used. default   'EM', standard EM algorithm fixed quadrature, 'QMCEM'   quasi-Monte Carlo EM estimation, 'MCEM' Monte Carlo EM estimation.   option 'MHRM' may also passed use MH-RM algorithm,   'SEM' Stochastic EM algorithm (first   two stages MH-RM stage using optimizer single Newton-Raphson iteration),   'BL' Bock Lieberman   approach (generally recommended longer tests). 'EM' generally effective 1-3 factors, methods 'QMCEM',   'MCEM', 'SEM', 'MHRM' used dimensions 3 . Note   optimizer stochastic associated SE.type automatically changed   SE.type = 'MHRM' default avoid use quadrature optimizer character indicating numerical optimizer use. default, EM   algorithm use 'BFGS' upper lower bounds box-constraints   'nlminb' . options include Newton-Raphson ('NR'),   can efficient 'BFGS' stable complex   IRT models (nominal nested logit models)   related 'NR1' also Newton-Raphson   consists 1 update coupled RM Hessian (  applicable MH-RM algorithm used). MH-RM algorithm uses 'NR1' default,   though currently 'BFGS', 'L-BFGS-B', 'NR'   also supported method (  fewer iterations default) emulate stochastic EM updates.   well, 'Nelder-Mead' 'SANN'   estimators available, routine use generally required recommended. Additionally, estimation subroutines Rsolnp nloptr   packages available passing arguments 'solnp' 'nloptr',   respectively. used conjunction solnp_args   nloptr_args specified . equality constraints specified   model definition parameter lowest parnum   pars = 'values' data.frame used estimation vector passed   objective function, group hyper-parameters omitted.   Equality inequality functions form function(p, optim_args),   optim_args list internally parameters largely can ignored   defining constraints (though use browser() may helpful) dentype type density form use latent trait parameters. Current options include  'Gaussian' (default) assumes multivariate Gaussian distribution associated       mean vector variance-covariance matrix 'empiricalhist' 'EH' estimates latent distribution using empirical histogram described       Bock Aitkin (1981). applicable unidimensional models estimated EM algorithm.       option, number cycles, TOL, quadpts adjusted accommodate       less precision estimation (namely: TOL = 3e-5, NCYCLES = 2000, quadpts = 121) 'empiricalhist_Woods' 'EHW' estimates latent distribution using empirical histogram described       Bock Aitkin (1981), specifications dentype = 'empiricalhist',       extrapolation-interpolation method described Woods (2007). NOTE: improve stability       presence extreme response styles (.e., highest lowest item) technical option       zeroExtreme = TRUE may required -weight contribution problematic patterns 'Davidian-#' estimates semi-parametric Davidian curves described Woods Lin (2009),       # placeholder represents number Davidian parameters estimate       (e.g., 'Davidian-6' estimate 6 smoothing parameters). default, number       quadpts increased 121, method applicable       unidimensional models estimated EM algorithm Note itemtype = 'ULL' log-normal(0,1) density used support unipolar scaling pars data.frame structure starting values, parameter numbers, estimation logical values, etc, defined. user may observe model defines values using pars = 'values', object can turn modified input back estimation pars = mymodifiedpars constrain list user declared equality constraints. see define parameters correctly use pars = 'values' initially see parameters labeled. constrain parameters equal create list separate concatenated vectors signifying parameters constrain. example, set parameters 1 5 equal, also set parameters 2, 6, 10 equal use constrain = list(c(1,5), c(2,6,10)). Constraints can also specified using mirt.model syntax (recommended) calcNull logical; calculate Null model additional fit statistics (e.g., TLI)? applicable data contains NA's data overly sparse draws number Monte Carlo draws estimate log-likelihood MH-RM algorithm. Default 5000 survey.weights optional numeric vector survey weights apply case data (EM estimation ). specified, cases weighted equally (standard IRT approach). sum survey.weights must equal total sample size proper weighting applied quadpts number quadrature points per dimension (must larger 2). default number quadrature uses following scheme: switch(.character(nfact), '1'=61, '2'=31, '3'=15, '4'=9, '5'=7, 3). However, method input set 'QMCEM' argument left blank default number quasi-Monte Carlo integration nodes set 5000 total TOL convergence threshold EM MH-RM; defaults .0001 .001. SE.type = 'SEM' value specified, default set 1e-5. evaluate model using starting values pass TOL = NaN, evaluate starting values without log-likelihood pass TOL = NA gpcm_mats list matrices specifying scoring coefficients (generalized) partial credit model constructed. omitted, standard gpcm format used (.e., seq(0, k, = 1) trait). input used traits scored different category (e.g., matrix(c(0:3, 1,0,0,0), 4, 2) two-dimensional model first trait scored like gpcm, second trait positively indicated first category selected). Can used itemtypes 'gpcm' 'Rasch', respective element gpcm_mats NULL grsm.block optional numeric vector indicating blocking occur using grsm, NA represents items belong grsm block (items may estimated test data). example, specify two blocks 3 2PL item last item: grsm.block = c(rep(1,3), rep(2,3), NA). NULL items assumed within group therefore number item categories rsm.block grsm.block, 'rsm' blocks monopoly.k vector values (single value repeated item) indicate degree monotone polynomial fitted, monotone polynomial corresponds monopoly.k * 2 + 1 (e.g., monopoly.k = 2 fits 5th degree polynomial). Default monopoly.k = 1, fits 3rd degree polynomial key numeric vector response scoring key. Required using nested logit item types, must length number items used. Items nested logit ignore vector, use NA item locations applicable large logical indicating whether unique response patterns obtained prior   performing estimation avoid repeating computations identical patterns.   default TRUE provides correct degrees freedom model since unique patterns   tallied (typically affects goodness fit statistics G2, also influence   nested model comparison methods anova(mod1, mod2)), FALSE use   number rows data placeholder total degrees freedom. , model   objects compared flags set TRUE set FALSE Alternatively, collapse table frequencies desired purpose saving computations   (.e., computing collapsed frequencies data onte-time) character vector can   passed arguement large = 'return' return list desired   table information used mirt. list object can reused passing back   large argument avoid re-tallying data   (, useful dataset large computing tabulated data   computationally burdensome). strategy shown : Compute organized data e.g., internaldat <- mirt(Science, 1, large = 'return') Pass organized data estimation functions e.g.,   mod <- mirt(Science, 1, large = internaldat) GenRandomPars logical; generate random starting values prior optimization instead using fixed internal starting values? accelerate character vector indicating type acceleration use. Default 'Ramsay', may also 'squarem' SQUAREM procedure (specifically, gSqS3 approach) described Varadhan Roldand (2008). disable acceleration, pass 'none' verbose logical; print observed- (EM) complete-data (MHRM) log-likelihood iteration cycle? Default TRUE solnp_args list arguments passed solnp::solnp() function equality constraints, inequality constraints, etc nloptr_args list arguments passed nloptr::nloptr() function equality constraints, inequality constraints, etc spline_args named list lists containing information passed bs (default)   ns spline itemtype. element must refer name itemtype   spline, internal list names refer arguments passed. example, item 2 called   'read2', item 5 called 'read5', itemtype 'spline' item 5 use   ns form, modified list input might form: spline_args = list(read2 = list(degree = 4),                            read5 = list(fun = 'ns', knots = c(-2, 2))) code input changes bs() splines function degree = 4 input,   second element changes ns() function knots set c(-2, 2) control list passed respective optimizers (.e., optim(), nlminb(), etc). Additional arguments included 'NR' optimizer: 'tol' convergence tolerance M-step (default TOL/1000), default number iterations Newton-Raphson optimizer 50 (modified 'maxit' control input) technical list containing lower level technical parameters estimation. May : NCYCLES maximum number EM MH-RM cycles; defaults 500 2000 MAXQUAD maximum number quadratures, can increase     4GB RAM PC; default 20000 theta_lim range integration grid dimension; default c(-6, 6). Note     itemtype = 'ULL' log-normal distribution used range change     c(.01, 6^2), second term square theta_lim input instead set.seed seed number used estimation. Default 12345 SEtol standard error tolerance criteria S-EM MHRM computation     information matrix. Default 1e-3 symmetric logical; force S-EM/Oakes information matrix estimates symmetric? Default TRUE     computation standard errors stable. Setting FALSE can help     detect solutions reached ML estimate SEM_window ratio values used define S-EM window based     observed likelihood differences across EM iterations. default     c(0, 1 - SEtol), provides nearly full S-EM window (.e.,     nearly EM cycles used). use smaller SEM window change window     something like c(.9, .999) start point farther EM history warn logical; include warning messages estimation? Default TRUE message logical; include general messages estimation? Default TRUE customK numeric vector used explicitly declare number response     categories item. used constructing mirt model     reasons parameter estimation (obtain factor scores), requires     input data 0 lowest category. format     extract.mirt(mod, 'K') slot converged models customPriorFun custom function used determine normalized density     integration EM algorithm. Must form function(Theta, Etable){...},     return numeric vector length number rows Theta.     Etable input contains aggregated table generated current E-step     computations. proper integration, returned vector sum     1 (.e., normalized). Note using Etable NULL     first call, therefore prior deal issue accordingly zeroExtreme logical; assign extreme response patterns survey.weight 0     (formally equivalent removing data vectors estimation)?     dentype = 'EHW', Woods' extrapolation utilized,     option may required extrapolation causes expected densities tend towards     positive negative infinity. default FALSE customTheta custom Theta grid, matrix form, used integration.     defined, grid determined internally based number quadpts nconstrain specification constrain list argument,     however imposes negative equality constraint instead (e.g., \\(a12 = -a21\\),     specified nconstrain = list(c(12, 21))). Note specification     list must length 2, second element taken -1 times     first element delta deviation term used numerical estimates computing ACOV matrix     'forward' 'central' numerical approaches, well Oakes' method     Richardson extrapolation. Default 1e-5 parallel logical; use parallel cluster defined mirtCluster?     Default TRUE storeEMhistory logical; store iteration history using EM algorithm?    Default FALSE. TRUE, use extract.mirt extract internal_constraints logical; include internal constraints using certain     IRT models (e.g., 'grsm' itemtype). Disable want use special optimizers     solnp. Default TRUE gain vector two values specifying numerator exponent        values RM gain function \\((val1 / cycle)^val2\\).        Default c(0.10, 0.75) BURNIN number burn cycles (stage 1) MH-RM; default 150 SEMCYCLES number SEM cycles (stage 2) MH-RM; default 100 MHDRAWS number Metropolis-Hasting draws use MH-RM iteration; default 5 MHcand vector values used tune MH sampler. Larger values     cause acceptance ratio decrease. One value required group     unconditional item factor analysis (mixedmirt() requires additional values     random effect). null, values determined internally, attempting     tune acceptance draws .1 .4 MHRM_SE_draws number fixed draws use SE=TRUE SE.type = 'FMHRM'     maximum number draws SE.type = 'MHRM'. Default 2000 MCEM_draws function used determine number quadrature points draw     'MCEM' method. Must include one argument indicates iteration number     EM cycle. Default function(cycles) 500 + (cycles - 1)*2, starts number     draws 500 increases 2 full EM iteration info_if_converged logical; compute information matrix using MH-RM algorithm     model converged within suitable number iterations? Default TRUE logLik_if_converged logical; compute observed log-likelihood using MH-RM algorithm     model converged within suitable number iterations? Default TRUE keep_vcov_PD logical; attempt keep variance-covariance matrix latent traits     positive definite estimation EM algorithm? generally improves convergence     properties traits highly correlated. Default TRUE ... additional arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"function returns object class SingleGroupClass   (SingleGroupClass-class)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"confirmatory-and-exploratory-irt","dir":"Reference","previous_headings":"","what":"Confirmatory and Exploratory IRT","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Specification confirmatory item factor analysis model follows many rules structural equation modeling framework confirmatory factor analysis. variances latent factors automatically fixed 1 help facilitate model identification. parameters may fixed constant values set equal parameters using appropriate declarations. Confirmatory models may also contain 'explanatory' person item level predictors, though including predictors currently limited mixedmirt function. specifying single number greater 1 model input mirt exploratory IRT model estimated. Rotation target matrix options available passed generic functions summary-method fscores. Factor means variances fixed ensure proper identification. model exploratory item factor analysis estimation begin computing matrix quasi-polychoric correlations. factor analysis nfact extracted item parameters estimated \\(a_{ij} = f_{ij}/u_j\\), \\(f_{ij}\\) factor loading jth item ith factor, \\(u_j\\) square root factor uniqueness, \\(\\sqrt{1 - h_j^2}\\). initial intercept parameters determined calculating inverse normal item facility (.e., item easiness), \\(q_j\\), obtain \\(d_j = q_j / u_j\\). similar implementation also used obtaining initial values polytomous items.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"a-note-on-upper-and-lower-bound-parameters","dir":"Reference","previous_headings":"","what":"A note on upper and lower bound parameters","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Internally \\(g\\) \\(u\\) parameters transformed using logit transformation (\\(log(x/(1-x))\\)), can reversed using \\(1 / (1 + exp(-x))\\) following convergence. also applies computing confidence intervals parameters, done automatically coef(mod, rawug = FALSE). , applying prior distributions parameters recommended use prior ranges negative infinity positive infinity, normally distributed prior via 'norm' input (see mirt.model).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"convergence-for-quadrature-methods","dir":"Reference","previous_headings":"","what":"Convergence for quadrature methods","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Unrestricted full-information factor analysis known problems convergence, items may need constrained removed entirely allow acceptable solution. general rule dichotomous items means greater .95, items .05 greater guessing parameter, considered removal analysis treated prior parameter distributions. type reasoning applicable including upper bound parameters well. polytomous items, categories rarely endorsed cause similar issues. Also, increasing number quadrature points per dimension, using quasi-Monte Carlo integration method, may help stabilize estimation process higher dimensions. Finally, solutions well defined also difficulty converging, can indicate model misspecified (e.g., extracting many dimensions).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"convergence-for-mh-rm-method","dir":"Reference","previous_headings":"","what":"Convergence for MH-RM method","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"MH-RM algorithm, number iterations grows high (e.g., greater 1500) Max Change = .2500 values repeatedly printed console often (indicating parameters constrained since naturally moving steps greater 0.25) model may either ill defined flat likelihood surface, genuine maximum-likelihood parameter estimates may difficult find. Standard errors computed following model convergence passing SE = TRUE, perform addition MH-RM stage treating maximum-likelihood estimates fixed points.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"additional-helper-functions","dir":"Reference","previous_headings":"","what":"Additional helper functions","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Additional functions available package can useful pre- post-estimation. : mirt.model Define IRT model specification use special syntax. Useful defining within     group parameter constraints, prior parameter distributions, specifying slope     coefficients factor coef-method Extract raw coefficients model, along standard errors confidence     intervals summary-method Extract standardized loadings model. Accepts rotate argument exploratory     item response model anova-method Compare nested models using likelihood ratio statistics well information criteria     AIC BIC residuals-method Compute pairwise residuals item using methods LD statistic     (Chen & Thissen, 1997), well response pattern residuals plot-method Plot various types test level plots including test score information functions     itemplot Plot various types item level plots, including score, standard error, information     functions, createItem Create customized itemtype currently exist package imputeMissing Impute missing data given computed Theta matrix fscores Find predicted scores latent traits using estimation methods EAP, MAP, ML,     WLE, EAPsum wald Compute Wald statistics follow convergence model suitable information matrix M2 Limited information goodness fit test statistic based determine well model fits     data itemfit personfit Goodness fit statistics item person levels, S-X2, infit, outfit,     boot.mirt Compute estimated parameter confidence intervals via bootstrap methods mirtCluster Define cluster package functions use capitalizing multi-core architecture     utilize available CPUs possible. help decrease estimation times tasks     can run parallel","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"irt-models","dir":"Reference","previous_headings":"","what":"IRT Models","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"parameter labels use follow convention, using two factors \\(K\\) total number categories (using \\(k\\) specific category instances). Rasch one intercept estimated, latent variance \\(\\theta\\) freely estimated.     data two categories partial credit model used instead (see     'gpcm' ).      $$P(x = 1|\\theta, d) = \\frac{1}{1 + exp(-(\\theta + d))}$$ 1-4PL Depending model \\(u\\) may equal 1 (e.g., 3PL), \\(g\\) may equal 0 (e.g., 2PL),     may fixed 1 (e.g., 1PL).     $$P(x = 1|\\theta, \\psi) = g + \\frac{(u - g)}{       1 + exp(-(a_1 * \\theta_1 + a_2 * \\theta_2 + d))}$$ 5PL Currently restricted unidimensional models     $$P(x = 1|\\theta, \\psi) = g + \\frac{(u - g)}{       1 + exp(-(a_1 * \\theta_1 + d))^S}$$     \\(S\\) allows asymmetry response function     transformation constrained greater 0 (.e., log(S) estimated rather S) CLL Complementary log-log model (see Shim, Bonifay, Wiedermann, 2022)     $$P(x = 1|\\theta, b) = 1 - exp(-exp(\\theta - b))$$     Currently restricted unidimensional dichotomous data. graded graded model consists sequential 2PL models,     $$P(x = k | \\theta, \\psi) = P(x \\ge k | \\theta, \\phi) - P(x \\ge k + 1 | \\theta, \\phi)$$     Note \\(P(x \\ge 1 | \\theta, \\phi) = 1\\) \\(P(x \\ge K + 1 | \\theta, \\phi) = 0\\) ULL unipolar log-logistic model (ULL; Lucke, 2015) defined     graded response model, however     $$P(x \\le k | \\theta, \\psi) = \\frac{\\lambda_k\\theta^\\eta}{1 + \\lambda_k\\theta^\\eta}$$.     Internally \\(\\lambda\\) parameters exponentiated keep positive,     therefore reported estimates interpreted log units grsm constrained version graded model graded spacing equal across item     blocks adjusted single 'difficulty' parameter (c) latent variance     \\(\\theta\\) freely estimated (see Muraki, 1990 exact form).     restricted unidimensional models . gpcm/nominal gpcm \\(d\\) values treated fixed ordered values     \\(0:(K-1)\\) (nominal model \\(d_0\\) also set 0). Additionally,     identification nominal model \\(ak_0 = 0\\), \\(ak_{(K-1)} = (K - 1)\\).     $$P(x = k | \\theta, \\psi) =     \\frac{exp(ak_{k-1} * (a_1 * \\theta_1 + a_2 * \\theta_2) + d_{k-1})}     {\\sum_{k=1}^K exp(ak_{k-1} * (a_1 * \\theta_1 + a_2 * \\theta_2) + d_{k-1})}$$ partial credit model (itemtype = 'Rasch'; unidimensional )     model constrained \\(ak = (0,1,\\ldots, K-1)\\), \\(a_1 = 1\\),     latent variance \\(\\theta_1\\) freely estimated. Alternatively, partial credit model     can obtained containing slope parameters gpcms equal.     specific scoring function may included passing suitable list matrices     gpcm_mats input argument. nominal model parametrization helps identify empirical ordering     categories inspecting \\(ak\\) values. Larger values indicate item category     positively related latent trait(s) measured. instance, item     truly ordinal (Likert scale), 4 response categories, expect     see \\(ak_0 < ak_1 < ak_2 < ak_3\\) following estimation. hand     \\(ak_0 > ak_1\\) appear second category less related     trait first, therefore second category understood     'lowest score'. NOTE: nominal model can become numerical unstable poor choices high low     values chosen, resulting ak values greater abs(10) .     recommended choose high low anchors cause estimated parameters fall     0 \\(K - 1\\) either theoretical means re-estimating     model better values following convergence. gpcmIRT rsm gpcmIRT model classical generalized partial credit model unidimensional response      data. obtain fit gpcm presented , however parameterization      allows Rasch/generalized rating scale model special case. E.g., K = 4 category response model, $$P(x = 0 | \\theta, \\psi) = exp(0) / G$$      $$P(x = 1 | \\theta, \\psi) = exp((\\theta - b1) + c) / G$$      $$P(x = 2 | \\theta, \\psi) = exp((2\\theta - b1 - b2) + 2c) / G$$      $$P(x = 3 | \\theta, \\psi) = exp((3\\theta - b1 - b2 - b3) + 3c) / G$$           $$G = exp(0) + exp((\\theta - b1) + c) + exp((2\\theta - b1 - b2) + 2c) +        exp((3\\theta - b1 - b2 - b3) + 3c)$$      \\(\\) slope parameter, \\(b\\) parameters threshold      values adjacent category, \\(c\\) -called difficulty parameter      rating scale model fitted (otherwise, \\(c = 0\\) drops computations). gpcmIRT can constrained partial credit IRT model either constraining      slopes equal, setting slopes 1 freeing latent variance parameter. Finally, rsm constrained version (generalized) partial      credit model spacing equal      across item blocks adjusted single 'difficulty' parameter (c). Note      analogous relationship graded model grsm (additional      constraint regarding fixed discrimination parameters). sequential/Tutz multidimensional sequential response model form     $$P(x = k | \\theta, \\psi) = \\prod (1 - F(a_1 \\theta_1 + a_2 \\theta_2 + d_{sk}))       F(a_1 \\theta_1 + a_2 \\theta_2 + d_{jk})$$     \\(F(\\cdot)\\) cumulative logistic function.     Tutz variant model (Tutz, 1990) (via itemtype = 'Tutz')     assumes slope terms equal 1 latent     variance terms estimated (.e., Rasch variant).  ideal ideal point model form, upper bound constraint \\(d\\) set 0:     $$P(x = 1 | \\theta, \\psi) = exp(-0.5 * (a_1 * \\theta_1 + a_2 * \\theta_2 + d)^2)$$ partcomp Partially compensatory models consist product 2PL probability curves.     $$P(x = 1 | \\theta, \\psi) = g + (1 - g) (\\frac{1}{1 + exp(-(a_1 * \\theta_1 + d_1))}^c_1 *     \\frac{1}{1 + exp(-(a_2 * \\theta_2 + d_2))}^c_2)$$ $c_1$ $c_2$ binary indicator variables reflecting whether item include     select compensatory component (1) (0). Note constraining slopes     equal across items reduce model Embretson's (Whitely's) multicomponent model (1980). 2-4PLNRM Nested logistic curves modeling distractor items. Requires scoring key.     model broken two components probability endorsement. successful     endorsement probability trace 1-4PL model, unsuccessful endorsement:     $$P(x = 0 | \\theta, \\psi) =     (1 - P_{1-4PL}(x = 1 | \\theta, \\psi)) * P_{nominal}(x = k | \\theta, \\psi)$$     product complement dichotomous trace line nominal     response model. nominal model, slope parameters defined constrained     1's, last value \\(ak\\) freely estimated. ggum (multidimensional) generalized graded unfolding model     class ideal point models useful ordinal response data. form     $$P(z=k|\\theta,\\psi)=\\frac{exp\\left[\\left(z\\sqrt{\\sum_{d=1}^{D}     a_{id}^{2}(\\theta_{jd}-b_{id})^{2}}\\right)+\\sum_{k=0}^{z}\\psi_{ik}\\right]+     exp\\left[\\left((M-z)\\sqrt{\\sum_{d=1}^{D}a_{id}^{2}(\\theta_{jd}-b_{id})^{2}}\\right)+     \\sum_{k=0}^{z}\\psi_{ik}\\right]}{\\sum_{w=0}^{C}\\left(exp\\left[\\left(w     \\sqrt{\\sum_{d=1}^{D}a_{id}^{2}(\\theta_{jd}-b_{id})^{2}}\\right)+     \\sum_{k=0}^{z}\\psi_{ik}\\right]+exp\\left[\\left((M-w)     \\sqrt{\\sum_{d=1}^{D}a_{id}^{2}(\\theta_{jd}-b_{id})^{2}}\\right)+     \\sum_{k=0}^{z}\\psi_{ik}\\right]\\right)}$$     \\(\\theta_{jd}\\) location \\(j\\)th individual \\(d\\)th dimension,     \\(b_{id}\\) difficulty location \\(\\)th item \\(d\\)th dimension,     \\(a_{id}\\) discrimination \\(j\\)th individual \\(d\\)th dimension     (discrimination values constrained positive),     \\(\\psi_{ik}\\) \\(k\\)th subjective response category threshold \\(\\)th item,     assumed symmetric item constant across dimensions,     \\(\\psi_{ik} = \\sum_{d=1}^D a_{id} t_{ik}\\)     \\(z = 1,2,\\ldots, C\\) (\\(C\\) number categories minus 1),     \\(M = 2C + 1\\). spline Spline response models attempt model response curves uses non-linear potentially     non-monotonic patterns. form     $$P(x = 1|\\theta, \\eta) = \\frac{1}{1 + exp(-(\\eta_1 * X_1 + \\eta_2 * X_2 + \\cdots + \\eta_n * X_n))}$$     \\(X_n\\) spline design matrix \\(X\\) organized grid \\(\\theta\\)     values. B-splines natural polynomial basis supported, intercept input     set TRUE default. monopoly Monotone polynomial model polytomous response data form     $$P(x = k | \\theta, \\psi) =     \\frac{exp(\\sum_1^k (m^*(\\psi) + \\xi_{c-1})}     {\\sum_1^C exp(\\sum_1^K (m^*(\\psi) + \\xi_{c-1}))}$$     \\(m^*(\\psi)\\) monotone polynomial function without intercept.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"html-help-files-exercises-and-examples","dir":"Reference","previous_headings":"","what":"HTML help files, exercises, and examples","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"access examples, vignettes, exercise files generated knitr please visit https://github.com/philchalmers/mirt/wiki.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Andrich, D. (1978). rating scale formulation ordered response categories. Psychometrika, 43, 561-573. Bock, R. D., & Aitkin, M. (1981). Marginal maximum likelihood estimation item parameters: Application EM algorithm. Psychometrika, 46(4), 443-459. Bock, R. D., Gibbons, R., & Muraki, E. (1988). Full-Information Item Factor Analysis. Applied Psychological Measurement, 12(3), 261-280. Bock, R. D. & Lieberman, M. (1970). Fitting response model n dichotomously scored items. Psychometrika, 35, 179-197. Cai, L. (2010a). High-Dimensional exploratory item factor analysis Metropolis-Hastings Robbins-Monro algorithm. Psychometrika, 75, 33-57. Cai, L. (2010b). Metropolis-Hastings Robbins-Monro algorithm confirmatory item factor analysis. Journal Educational Behavioral Statistics, 35, 307-335. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models MH-RM Algorithm. Journal Educational Measurement, 52, 200-222. doi:10.1111/jedm.12072 Chalmers, R. P. (2018). Numerical Approximation Observed Information Matrix Oakes' Identity. British Journal Mathematical Statistical Psychology DOI: 10.1111/bmsp.12127 Chalmers, R., P. & Flora, D. (2014). Maximum-likelihood Estimation Noncompensatory IRT Models MH-RM Algorithm. Applied Psychological Measurement, 38, 339-358. doi:10.1177/0146621614520958 Chen, W. H. & Thissen, D. (1997). Local dependence indices item pairs using item response theory. Journal Educational Behavioral Statistics, 22, 265-289. Embretson, S. E. (1984). general latent trait model response processes. Psychometrika, 49, 175-186. Falk, C. F. & Cai, L. (2016). Maximum Marginal Likelihood Estimation Monotonic Polynomial Generalized Partial Credit Model Applications Multiple Group Analysis. Psychometrika, 81, 434-460. Fischer, G. H. (1983). Logistic latent trait models linear constraints. Psychometrika, 48, 3-26. Lord, F. M. & Novick, M. R. (1968). Statistical theory mental test scores. Addison-Wesley. Lucke, J. F. (2015). Unipolar item response models. S. P. Reise & D. . Revicki (Eds.), Handbook item response theory modeling: Applications typical performance assessment (pp. 272-284). New York, NY:  Routledge/Taylor & Francis Group. Ramsay, J. O. (1975). Solving implicit equations psychometric data analysis. Psychometrika, 40, 337-360. Rasch, G. (1960). Probabilistic models intelligence attainment tests. Danish Institute Educational Research. Roberts, J. S., Donoghue, J. R., & Laughlin, J. E. (2000). General Item Response Theory Model Unfolding Unidimensional Polytomous Responses. Applied Psychological Measurement, 24, 3-32. Shim, H., Bonifay, W., & Wiedermann, W. (2022). Parsimonious asymmetric item response theory modeling complementary log-log link. Behavior Research Methods, 55, 200-219. Maydeu-Olivares, ., Hernandez, . & McDonald, R. P. (2006). Multidimensional Ideal Point Item Response Theory Model Binary Data. Multivariate Behavioral Research, 41, 445-471. Muraki, E. (1990). Fitting polytomous item response model Likert-type data. Applied Psychological Measurement, 14, 59-71. Muraki, E. (1992). generalized partial credit model: Application EM algorithm. Applied Psychological Measurement, 16, 159-176. Muraki, E. & Carlson, E. B. (1995). Full-information factor analysis polytomous item responses. Applied Psychological Measurement, 19, 73-90. Samejima, F. (1969). Estimation latent ability using response pattern graded scores. Psychometrika Monographs, 34. Suh, Y. & Bolt, D. (2010). Nested logit models multiple-choice item response data. Psychometrika, 75, 454-473. Sympson, J. B. (1977). model testing multidimensional items. Proceedings 1977 Computerized Adaptive Testing Conference. Thissen, D. (1982). Marginal maximum likelihood estimation one-parameter logistic model. Psychometrika, 47, 175-186. Tutz, G. (1990). Sequential item response models ordered response. British Journal Mathematical Statistical Psychology, 43, 39-55. Varadhan, R. & Roland, C. (2008). Simple Globally Convergent Methods Accelerating Convergence EM Algorithm. Scandinavian Journal Statistics, 35, 335-353. Whitely, S. E. (1980). Multicomponent latent trait models ability tests. Psychometrika, 45(4), 470-494. Wood, R., Wilson, D. T., Gibbons, R. D., Schilling, S. G., Muraki, E., & Bock, R. D. (2003). TESTFACT 4 Windows: Test Scoring, Item Statistics, Full-information Item Factor Analysis [Computer software]. Lincolnwood, IL: Scientific Software International. Woods, C. M., Lin, N. (2009). Item Response Theory Estimation Latent Density Using Davidian Curves. Applied Psychological Measurement,33(2), 102-117.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"","code":"# load LSAT section 7 data and compute 1 and 2 factor models data <- expand.table(LSAT7) itemstats(data) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            3.707          1.199 0.143 0.052 0.453     0.886 #>  #> $itemstats #>           N  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 1000 0.828 0.378   0.530         0.246       0.396 #> Item.2 1000 0.658 0.475   0.600         0.247       0.394 #> Item.3 1000 0.772 0.420   0.611         0.313       0.345 #> Item.4 1000 0.606 0.489   0.592         0.223       0.415 #> Item.5 1000 0.843 0.364   0.461         0.175       0.438 #>  #> $proportions #>            0     1 #> Item.1 0.172 0.828 #> Item.2 0.342 0.658 #> Item.3 0.228 0.772 #> Item.4 0.394 0.606 #> Item.5 0.157 0.843 #>   (mod1 <- mirt(data, 1)) #>  Iteration: 1, Log-Lik: -2668.786, Max-Change: 0.18243 Iteration: 2, Log-Lik: -2663.691, Max-Change: 0.13637 Iteration: 3, Log-Lik: -2661.454, Max-Change: 0.10231 Iteration: 4, Log-Lik: -2659.430, Max-Change: 0.04181 Iteration: 5, Log-Lik: -2659.241, Max-Change: 0.03417 Iteration: 6, Log-Lik: -2659.113, Max-Change: 0.02911 Iteration: 7, Log-Lik: -2658.812, Max-Change: 0.00456 Iteration: 8, Log-Lik: -2658.809, Max-Change: 0.00363 Iteration: 9, Log-Lik: -2658.808, Max-Change: 0.00273 Iteration: 10, Log-Lik: -2658.806, Max-Change: 0.00144 Iteration: 11, Log-Lik: -2658.806, Max-Change: 0.00118 Iteration: 12, Log-Lik: -2658.806, Max-Change: 0.00101 Iteration: 13, Log-Lik: -2658.805, Max-Change: 0.00042 Iteration: 14, Log-Lik: -2658.805, Max-Change: 0.00025 Iteration: 15, Log-Lik: -2658.805, Max-Change: 0.00026 Iteration: 16, Log-Lik: -2658.805, Max-Change: 0.00023 Iteration: 17, Log-Lik: -2658.805, Max-Change: 0.00023 Iteration: 18, Log-Lik: -2658.805, Max-Change: 0.00021 Iteration: 19, Log-Lik: -2658.805, Max-Change: 0.00019 Iteration: 20, Log-Lik: -2658.805, Max-Change: 0.00017 Iteration: 21, Log-Lik: -2658.805, Max-Change: 0.00017 Iteration: 22, Log-Lik: -2658.805, Max-Change: 0.00015 Iteration: 23, Log-Lik: -2658.805, Max-Change: 0.00015 Iteration: 24, Log-Lik: -2658.805, Max-Change: 0.00013 Iteration: 25, Log-Lik: -2658.805, Max-Change: 0.00013 Iteration: 26, Log-Lik: -2658.805, Max-Change: 0.00011 Iteration: 27, Log-Lik: -2658.805, Max-Change: 0.00011 Iteration: 28, Log-Lik: -2658.805, Max-Change: 0.00010 #>  #> Call: #> mirt(data = data, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.43  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN coef(mod1) #> $Item.1 #>        a1     d g u #> par 0.988 1.856 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.081 0.808 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.706 1.804 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.765 0.486 0 1 #>  #> $Item.5 #>        a1     d g u #> par 0.736 1.855 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  summary(mod1) #>           F1    h2 #> Item.1 0.502 0.252 #> Item.2 0.536 0.287 #> Item.3 0.708 0.501 #> Item.4 0.410 0.168 #> Item.5 0.397 0.157 #>  #> SS loadings:  1.366  #> Proportion Var:  0.273  #>  #> Factor correlations:  #>  #>    F1 #> F1  1 plot(mod1)  plot(mod1, type = 'trace')   if (FALSE) { # \\dontrun{ (mod2 <- mirt(data, 1, SE = TRUE)) #standard errors via the Oakes method (mod2 <- mirt(data, 1, SE = TRUE, SE.type = 'SEM')) #standard errors with SEM method coef(mod2) (mod3 <- mirt(data, 1, SE = TRUE, SE.type = 'Richardson')) #with numerical Richardson method residuals(mod1) plot(mod1) #test score function plot(mod1, type = 'trace') #trace lines plot(mod2, type = 'info') #test information plot(mod2, MI=200) #expected total score with 95% confidence intervals  # estimated 3PL model for item 5 only (mod1.3PL <- mirt(data, 1, itemtype = c('2PL', '2PL', '2PL', '2PL', '3PL'))) coef(mod1.3PL)  # internally g and u pars are stored as logits, so usually a good idea to include normal prior #  to help stabilize the parameters. For a value around .182 use a mean #  of -1.5 (since 1 / (1 + exp(-(-1.5))) == .182) model <- 'F = 1-5          PRIOR = (5, g, norm, -1.5, 3)' mod1.3PL.norm <- mirt(data, model, itemtype = c('2PL', '2PL', '2PL', '2PL', '3PL')) coef(mod1.3PL.norm) #limited information fit statistics M2(mod1.3PL.norm)  # unidimensional ideal point model idealpt <- mirt(data, 1, itemtype = 'ideal') plot(idealpt, type = 'trace', facet_items = TRUE) plot(idealpt, type = 'trace', facet_items = FALSE)  # two factors (exploratory) mod2 <- mirt(data, 2) coef(mod2) summary(mod2, rotate = 'oblimin') #oblimin rotation residuals(mod2) plot(mod2) plot(mod2, rotate = 'oblimin')  anova(mod1, mod2) #compare the two models scoresfull <- fscores(mod2) #factor scores for each response pattern head(scoresfull) scorestable <- fscores(mod2, full.scores = FALSE) #save factor score table head(scorestable)  # confirmatory (as an example, model is not identified since you need 3 items per factor) # Two ways to define a confirmatory model: with mirt.model, or with a string  # these model definitions are equivalent cmodel <- mirt.model('    F1 = 1,4,5    F2 = 2,3') cmodel2 <- 'F1 = 1,4,5             F2 = 2,3'  cmod <- mirt(data, cmodel) # cmod <- mirt(data, cmodel2) # same as above coef(cmod) anova(cmod, mod2) # check if identified by computing information matrix (cmod <- mirt(data, cmodel, SE = TRUE))  ########### # data from the 'ltm' package in numeric format itemstats(Science)  pmod1 <- mirt(Science, 1) plot(pmod1) plot(pmod1, type = 'trace') plot(pmod1, type = 'itemscore') summary(pmod1)  # Constrain all slopes to be equal with the constrain = list() input or mirt.model() syntax # first obtain parameter index values <- mirt(Science,1, pars = 'values') values #note that slopes are numbered 1,5,9,13, or index with values$parnum[values$name == 'a1'] (pmod1_equalslopes <- mirt(Science, 1, constrain = list(c(1,5,9,13)))) coef(pmod1_equalslopes)  # using mirt.model syntax, constrain all item slopes to be equal model <- 'F = 1-4           CONSTRAIN = (1-4, a1)' (pmod1_equalslopes <- mirt(Science, model)) coef(pmod1_equalslopes)  coef(pmod1_equalslopes) anova(pmod1_equalslopes, pmod1) #significantly worse fit with almost all criteria  pmod2 <- mirt(Science, 2) summary(pmod2) plot(pmod2, rotate = 'oblimin') itemplot(pmod2, 1, rotate = 'oblimin') anova(pmod1, pmod2)  # unidimensional fit with a generalized partial credit and nominal model (gpcmod <- mirt(Science, 1, 'gpcm')) coef(gpcmod)  # for the nominal model the lowest and highest categories are assumed to be the #  theoretically lowest and highest categories that related to the latent trait(s) (nomod <- mirt(Science, 1, 'nominal')) coef(nomod) #ordering of ak values suggest that the items are indeed ordinal anova(gpcmod, nomod) itemplot(nomod, 3)  # generalized graded unfolding model (ggum <- mirt(Science, 1, 'ggum')) coef(ggum, simplify=TRUE) plot(ggum) plot(ggum, type = 'trace') plot(ggum, type = 'itemscore')  # monotonic polyomial models (monopoly <- mirt(Science, 1, 'monopoly')) coef(monopoly, simplify=TRUE) plot(monopoly) plot(monopoly, type = 'trace') plot(monopoly, type = 'itemscore')  # unipolar IRT model unimod <- mirt(Science, itemtype = 'ULL') coef(unimod, simplify=TRUE) plot(unimod) plot(unimod, type = 'trace') itemplot(unimod, 1)  # following use the correct log-normal density for latent trait itemfit(unimod) M2(unimod, type = 'C2') fs <- fscores(unimod) hist(fs, 20) fscores(unimod, method = 'EAPsum', full.scores = FALSE)  ## example applying survey weights. # weight the first half of the cases to be more representative of population survey.weights <- c(rep(2, nrow(Science)/2), rep(1, nrow(Science)/2)) survey.weights <- survey.weights/sum(survey.weights) * nrow(Science) unweighted <- mirt(Science, 1) weighted <- mirt(Science, 1, survey.weights=survey.weights)  ########### # empirical dimensionality testing that includes 'guessing'  data(SAT12) data <- key2binary(SAT12,   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) itemstats(data)  mod1 <- mirt(data, 1) extract.mirt(mod1, 'time') #time elapsed for each estimation component  # optionally use Newton-Raphson for (generally) faster convergence in the M-step's mod1 <- mirt(data, 1, optimizer = 'NR') extract.mirt(mod1, 'time')  mod2 <- mirt(data, 2, optimizer = 'NR') # difficulty converging with reduced quadpts, reduce TOL mod3 <- mirt(data, 3, TOL = .001, optimizer = 'NR') anova(mod1,mod2) anova(mod2, mod3) #negative AIC, 2 factors probably best  # same as above, but using the QMCEM method for generally better accuracy in mod3 mod3 <- mirt(data, 3, method = 'QMCEM', TOL = .001, optimizer = 'NR') anova(mod2, mod3)  # with fixed guessing parameters mod1g <- mirt(data, 1, guess = .1) coef(mod1g)  ########### # graded rating scale example  # make some data set.seed(1234) a <- matrix(rep(1, 10)) d <- matrix(c(1,0.5,-.5,-1), 10, 4, byrow = TRUE) c <- seq(-1, 1, length.out=10) data <- simdata(a, d + c, 2000, itemtype = rep('graded',10)) itemstats(data)  mod1 <- mirt(data, 1) mod2 <- mirt(data, 1, itemtype = 'grsm') coef(mod2) anova(mod2, mod1) #not sig, mod2 should be preferred itemplot(mod2, 1) itemplot(mod2, 5) itemplot(mod2, 10)  ########### # 2PL nominal response model example (Suh and Bolt, 2010) data(SAT12) SAT12[SAT12 == 8] <- NA #set 8 as a missing value head(SAT12)  # correct answer key key <- c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5) scoredSAT12 <- key2binary(SAT12, key) mod0 <- mirt(scoredSAT12, 1)  # for first 5 items use 2PLNRM and nominal scoredSAT12[,1:5] <- as.matrix(SAT12[,1:5]) mod1 <- mirt(scoredSAT12, 1, c(rep('nominal',5),rep('2PL', 27))) mod2 <- mirt(scoredSAT12, 1, c(rep('2PLNRM',5),rep('2PL', 27)), key=key) coef(mod0)$Item.1 coef(mod1)$Item.1 coef(mod2)$Item.1 itemplot(mod0, 1) itemplot(mod1, 1) itemplot(mod2, 1)  # compare added information from distractors Theta <- matrix(seq(-4,4,.01)) par(mfrow = c(2,3)) for(i in 1:5){     info <- iteminfo(extract.item(mod0,i), Theta)     info2 <- iteminfo(extract.item(mod2,i), Theta)     plot(Theta, info2, type = 'l', main = paste('Information for item', i), ylab = 'Information')     lines(Theta, info, col = 'red') } par(mfrow = c(1,1))  # test information plot(Theta, testinfo(mod2, Theta), type = 'l', main = 'Test information', ylab = 'Information') lines(Theta, testinfo(mod0, Theta), col = 'red')  ########### # using the MH-RM algorithm data(LSAT7) fulldata <- expand.table(LSAT7) (mod1 <- mirt(fulldata, 1, method = 'MHRM'))  # Confirmatory models  # simulate data a <- matrix(c( 1.5,NA, 0.5,NA, 1.0,NA, 1.0,0.5,  NA,1.5,  NA,0.5,  NA,1.0,  NA,1.0),ncol=2,byrow=TRUE)  d <- matrix(c( -1.0,NA,NA, -1.5,NA,NA,  1.5,NA,NA,  0.0,NA,NA, 3.0,2.0,-0.5, 2.5,1.0,-1, 2.0,0.0,NA, 1.0,NA,NA),ncol=3,byrow=TRUE)  sigma <- diag(2) sigma[1,2] <- sigma[2,1] <- .4 items <- c(rep('2PL',4), rep('graded',3), '2PL') dataset <- simdata(a,d,2000,items,sigma)  # analyses # CIFA for 2 factor crossed structure  model.1 <- '   F1 = 1-4   F2 = 4-8   COV = F1*F2'  # compute model, and use parallel computation of the log-likelihood if(interactive()) mirtCluster() mod1 <- mirt(dataset, model.1, method = 'MHRM') coef(mod1) summary(mod1) residuals(mod1)  ##### # bifactor model.3 <- '   G = 1-8   F1 = 1-4   F2 = 5-8'  mod3 <- mirt(dataset,model.3, method = 'MHRM') coef(mod3) summary(mod3) residuals(mod3) anova(mod1,mod3)  ##### # polynomial/combinations data(SAT12) data <- key2binary(SAT12,                   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  model.quad <- '        F1 = 1-32   (F1*F1) = 1-32'   model.combo <- '        F1 = 1-16        F2 = 17-32   (F1*F2) = 1-8'  (mod.quad <- mirt(data, model.quad)) summary(mod.quad) (mod.combo <- mirt(data, model.combo)) anova(mod.combo, mod.quad)  # non-linear item and test plots plot(mod.quad) plot(mod.combo, type = 'SE') itemplot(mod.quad, 1, type = 'score') itemplot(mod.combo, 2, type = 'score') itemplot(mod.combo, 2, type = 'infocontour')  ## empirical histogram examples (normal, skew and bimodality) # make some data set.seed(1234) a <- matrix(rlnorm(50, .2, .2)) d <- matrix(rnorm(50)) ThetaNormal <- matrix(rnorm(2000)) ThetaBimodal <- scale(matrix(c(rnorm(1000, -2), rnorm(1000,2)))) #bimodal ThetaSkew <- scale(matrix(rchisq(2000, 3))) #positive skew datNormal <- simdata(a, d, 2000, itemtype = '2PL', Theta=ThetaNormal) datBimodal <- simdata(a, d, 2000, itemtype = '2PL', Theta=ThetaBimodal) datSkew <- simdata(a, d, 2000, itemtype = '2PL', Theta=ThetaSkew)  normal <- mirt(datNormal, 1, dentype = \"empiricalhist\") plot(normal, type = 'empiricalhist') histogram(ThetaNormal, breaks=30)  bimodal <- mirt(datBimodal, 1, dentype = \"empiricalhist\") plot(bimodal, type = 'empiricalhist') histogram(ThetaBimodal, breaks=30)  skew <- mirt(datSkew, 1, dentype = \"empiricalhist\") plot(skew, type = 'empiricalhist') histogram(ThetaSkew, breaks=30)  ##### # non-linear parameter constraints with Rsolnp package (nloptr supported as well): # Find Rasch model subject to the constraint that the intercepts sum to 0  dat <- expand.table(LSAT6) itemstats(dat)  # free latent mean and variance terms model <- 'Theta = 1-5           MEAN = Theta           COV = Theta*Theta'  # view how vector of parameters is organized internally sv <- mirt(dat, model, itemtype = 'Rasch', pars = 'values') sv[sv$est, ]  # constraint: create function for solnp to compute constraint, and declare value in eqB eqfun <- function(p, optim_args) sum(p[1:5]) #could use browser() here, if it helps LB <- c(rep(-15, 6), 1e-4) # more reasonable lower bound for variance term  mod <- mirt(dat, model, sv=sv, itemtype = 'Rasch', optimizer = 'solnp',    solnp_args=list(eqfun=eqfun, eqB=0, LB=LB)) print(mod) coef(mod) (ds <- sapply(coef(mod)[1:5], function(x) x[,'d'])) sum(ds)  # same likelihood location as: mirt(dat, 1, itemtype = 'Rasch')   ####### # latent regression Rasch model  # simulate data set.seed(1234) N <- 1000  # covariates X1 <- rnorm(N); X2 <- rnorm(N) covdata <- data.frame(X1, X2, X3 = rnorm(N)) Theta <- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))  # items and response data a <- matrix(1, 20); d <- matrix(rnorm(20)) dat <- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)  # unconditional Rasch model mod0 <- mirt(dat, 1, 'Rasch', SE=TRUE) coef(mod0, printSE=TRUE)  # conditional model using X1, X2, and X3 (bad) as predictors of Theta mod1 <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2 + X3, SE=TRUE) coef(mod1, printSE=TRUE) coef(mod1, simplify=TRUE) anova(mod0, mod1)  # jointly significant predictors of theta  # large sample z-ratios and p-values (if one cares) cfs <- coef(mod1, printSE=TRUE) (z <- cfs$lr.betas[[1]] / cfs$lr.betas[[2]]) round(pnorm(abs(z[,1]), lower.tail=FALSE)*2, 3)  # drop predictor for nested comparison mod1b <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2) anova(mod1b, mod1)  # compare to mixedmirt() version of the same model mod1.mixed <- mixedmirt(dat, 1, itemtype='Rasch',                         covdata=covdata, lr.fixed = ~ X1 + X2 + X3, SE=TRUE) coef(mod1.mixed) coef(mod1.mixed, printSE=TRUE)  # draw plausible values for secondary analyses pv <- fscores(mod1, plausible.draws = 10) pvmods <- lapply(pv, function(x, covdata) lm(x ~ covdata$X1 + covdata$X2),                  covdata=covdata) # population characteristics recovered well, and can be averaged over so <- lapply(pvmods, summary) so  # compute Rubin's multiple imputation average par <- lapply(so, function(x) x$coefficients[, 'Estimate']) SEpar <- lapply(so, function(x) x$coefficients[, 'Std. Error']) averageMI(par, SEpar)  ############ # Example using Gauss-Hermite quadrature with custom input functions  library(fastGHQuad) data(SAT12) data <- key2binary(SAT12,                    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) GH <- gaussHermiteData(50) Theta <- matrix(GH$x)  # This prior works for uni- and multi-dimensional models prior <- function(Theta, Etable){     P <- grid <- GH$w / sqrt(pi)     if(ncol(Theta) > 1)         for(i in 2:ncol(Theta))             P <- expand.grid(P, grid)      if(!is.vector(P)) P <- apply(P, 1, prod)      P }  GHmod1 <- mirt(data, 1, optimizer = 'NR',               technical = list(customTheta = Theta, customPriorFun = prior)) coef(GHmod1, simplify=TRUE)  Theta2 <- as.matrix(expand.grid(Theta, Theta)) GHmod2 <- mirt(data, 2, optimizer = 'NR', TOL = .0002,               technical = list(customTheta = Theta2, customPriorFun = prior)) summary(GHmod2, suppress=.2)  ############ # Davidian curve example  dat <- key2binary(SAT12,                    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) dav <- mirt(dat, 1, dentype = 'Davidian-4') # use four smoothing parameters plot(dav, type = 'Davidian') # shape of latent trait distribution coef(dav, simplify=TRUE)  fs <- fscores(dav) # assume normal prior fs2 <- fscores(dav, use_dentype_estimate=TRUE) # use Davidian estimated prior shape head(cbind(fs, fs2))  itemfit(dav) # assume normal prior itemfit(dav, use_dentype_estimate=TRUE) # use Davidian estimated prior shape  ########### # 5PL and restricted 5PL example dat <- expand.table(LSAT7)  mod2PL <- mirt(dat) mod2PL  # Following does not converge without including strong priors # mod5PL <- mirt(dat, itemtype = '5PL') # mod5PL  # restricted version of 5PL (asymmetric 2PL) model <- 'Theta = 1-5           FIXED = (1-5, g), (1-5, u)'  mod2PL_asym <- mirt(dat, model=model, itemtype = '5PL') mod2PL_asym coef(mod2PL_asym, simplify=TRUE) coef(mod2PL_asym, simplify=TRUE, IRTpars=TRUE)  # no big difference statistically or visually anova(mod2PL, mod2PL_asym) plot(mod2PL, type = 'trace') plot(mod2PL_asym, type = 'trace')   ################### # LLTM example  a <- matrix(rep(1,30)) d <- rep(c(1,0, -1),each = 10)  # first easy, then medium, last difficult dat <- simdata(a, d, 1000, itemtype = '2PL')  # unconditional model for intercept comparisons mod <- mirt(dat, itemtype = 'Rasch') coef(mod, simplify=TRUE)  # Suppose that the first 10 items were suspected to be easy, followed by 10 medium difficulty items, # then finally the last 10 items are difficult, # and we wish to test this item structure hypothesis (more intercept designs are possible # by including more columns). itemdesign <- data.frame(difficulty =    factor(c(rep('easy', 10), rep('medium', 10), rep('hard', 10)))) rownames(itemdesign) <- colnames(dat) itemdesign  # LLTM with mirt() lltm <- mirt(dat, itemtype = 'Rasch', SE=TRUE,    item.formula = ~ 0 + difficulty, itemdesign=itemdesign) coef(lltm, simplify=TRUE) coef(lltm, printSE=TRUE) anova(lltm, mod)  # models fit effectively the same; hence, intercept variability well captured  # additional information for LLTM plot(lltm) plot(lltm, type = 'trace') itemplot(lltm, item=1) itemfit(lltm) head(fscores(lltm))  #EAP estimates fscores(lltm, method='EAPsum', full.scores=FALSE) M2(lltm) # goodness of fit head(personfit(lltm)) residuals(lltm)  # intercept across items also possible by removing ~ 0 portion, just interpreted differently lltm.int <- mirt(dat, itemtype = 'Rasch',    item.formula = ~ difficulty, itemdesign=itemdesign) anova(lltm, lltm.int) # same coef(lltm.int, simplify=TRUE)  # using unconditional modeling for first four items itemdesign.sub <- itemdesign[5:nrow(itemdesign), , drop=FALSE] itemdesign.sub    # note that rownames are required in this case lltm.4 <- mirt(dat, itemtype = 'Rasch',    item.formula = ~ 0 + difficulty, itemdesign=itemdesign.sub) coef(lltm.4, simplify=TRUE) # first four items are the standard Rasch anova(lltm, lltm.4) # similar fit, hence more constrained model preferred  # LLTM with mixedmirt() (more flexible in general, but slower) LLTM <- mixedmirt(dat, model=1, fixed = ~ 0 + difficulty,                   itemdesign=itemdesign, SE=FALSE) summary(LLTM) coef(LLTM)  # LLTM with random error estimate (not supported with mirt() ) LLTM.e <- mixedmirt(dat, model=1, fixed = ~ 0 + difficulty,                   random = ~ 1|items, itemdesign=itemdesign, SE=FALSE) coef(LLTM.e)   ################### # General MLTM example (Embretson, 1984)  set.seed(42)  as <- matrix(rep(1,60), ncol=2) as[11:18,1] <- as[1:9,2] <- 0 d1 <- rep(c(3,1),each = 6)  # first easy, then medium, last difficult for first trait d2 <- rep(c(0,1,2),times = 4)    # difficult to easy d <- rnorm(18) ds <- rbind(cbind(d1=NA, d2=d), cbind(d1, d2)) (pars <- data.frame(a=as, d=ds)) dat <- simdata(as, ds, 2500,   itemtype = c(rep('dich', 18), rep('partcomp', 12))) itemstats(dat)  # unconditional model syntax <- \"theta1 = 1-9, 19-30            theta2 = 10-30            COV = theta1*theta2\" itemtype <- c(rep('Rasch', 18), rep('PC1PL', 12)) mod <- mirt(dat, syntax, itemtype=itemtype) coef(mod, simplify=TRUE) data.frame(est=coef(mod, simplify=TRUE)$items, pop=data.frame(a=as, d=ds)) itemplot(mod, 1) itemplot(mod, 30)  # MLTM design only for PC1PL items itemdesign <- data.frame(t1_difficulty= factor(d1, labels=c('medium', 'easy')),                         t2_difficulty=factor(d2, labels=c('hard', 'medium', 'easy'))) rownames(itemdesign) <- colnames(dat)[19:30] itemdesign  # fit MLTM design, leaving first 18 items as 'Rasch' type mltm <- mirt(dat, syntax, itemtype=itemtype, itemdesign=itemdesign,              item.formula = list(theta1 ~ 0 + t1_difficulty,                                  theta2 ~ 0 + t2_difficulty), SE=TRUE) coef(mltm, simplify=TRUE) coef(mltm, printSE=TRUE) anova(mltm, mod) # similar fit; hence more constrained version preferred M2(mltm) # goodness of fit head(personfit(mltm)) residuals(mltm)  # EAP estimates fscores(mltm) |> head()  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify model information — mirt.model","title":"Specify model information — mirt.model","text":"mirt.model function scans/reads user input specify confirmatory model. Item locations must used specifications itemnames argument supplied. called implicitly estimation functions string passed model argument.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify model information — mirt.model","text":"","code":"mirt.model(   input = NULL,   itemnames = NULL,   file = \"\",   COV = NULL,   quiet = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify model information — mirt.model","text":"input input writing model syntax. Can either string declaration class character -called Q-matrix class matrix specifies model either integer logical values. Q-matrix method chosen covariances terms can specified COV input itemnames character vector factor indicating item names. data.frame matrix object supplied names extracted using colnames(itemnames). Supplying input allows syntax specified raw item names rather item locations file input specifying external file declares input. COV symmetric, logical matrix used declare covariance terms estimated quiet logical argument passed scan() suppress console read message ... additional arguments scan()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify model information — mirt.model","text":"Returns model specification object used   mirt, bfactor, multipleGroup,   mixedmirt","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify model information — mirt.model","text":"Factors first named specify numerical items affect (.e., slope equal 0), separated either commas - indicate range items. Products factors may specified enclosing left hand term within brackets. finish declaration model simply enter blank line carriage return (.e., 'enter' 'return' key), instead read input version model syntax. associated slopes throughout package label coefficients a1, a2, ..., ak, associated number assigned according respective order defined factors. example, syntax \"G = 1-10        F = 1-5        = 6-10\" G factor assigned slopes a1 item, F assigned slopes a2, assigned slopes a3. principle applies bfactor function whereby slopes automatically included specific factors general factor structure assigned. optional keyword specifying correlation relationships factors called COV, non-linear factor products can included enclosing product combination left hand side declaration (e.g., (F1*F1) create quadratic factor F1). keywords CONSTRAIN, CONSTRAINB, PRIOR, FIXED, FREE, START, UBOUND, LBOUND can applied specific sub-groups multiple-group models included square brackets = sign, groups separated commas. example, apply within-group equality constraints group called \"male\", specifying: CONSTRAIN [male] = (1-5, a1) appropriate, specifying constraints sub-groups \"male\" \"female\" appear CONSTRAIN [male, female] = (1-5, a1) groups multi-group model, within-group equality constraints appear. Therefore, bracketed group specifications useful modifying priors, starting values, /within group equality constraints, specifications sub-group may differ. Additionally, use negations can used omit specific groups constraint specifications prefixing string - operator, following applies -group  constraints groups except \"Group2\" \"Group3\": CONSTRAINB [-Group2, -Group3] = (1-5, a1) Finally, keyword GROUP can used specify group-level hyper-parameter terms, means variance default Gaussian distribution. example, set starting value variance parameter (COV_11) 1.5: START = (GROUP, COV_11, 1.5) COV Specify relationship latent factors.   Estimating correlation factors declared joining two   factors asterisk (e.g., F1*F2), asterisk three factors   estimate possible correlations (e.g., F1*F2*F3). Specifications factor   (e.g., F1*F1) free variance said factor instead MEAN comma separated list specifying latent factor means freely estimate.   E.g., MEAN = F1, F2 free latent means factors F1 F2 CONSTRAIN bracketed, comma separated list specifying equality constrains items.   input format   CONSTRAIN = (items, ..., parameterName(s)),   (items, ..., parameterName). example, single group 10-item dichotomous tests, using default 2PL model,   first last 5 item slopes (a1) can constrained equal using   CONSTRAIN = (1-5, a1), (6-10, a1), combination   CONSTRAIN = (1-3,4,5,a1), (6,7,8-10,a1). constraining parameters equal across items different parameter names,   balanced bracketed vector must supplied. E.g., setting first slope item 1 equal   second slope item 3 CONSTRAIN = (1, 3, a1, a2) CONSTRAINB bracketed, comma separate list specifying equality constrains groups.   input format CONSTRAINB = (items, ..., parameterName),   (items, ..., parameterName). example, two group 10-item dichotomous tests, using default 2PL model, first   5 item slopes (a1) can constrained equal across groups using   CONSTRAINB = (1-5, a1), combination CONSTRAINB = (1-3,4,5,a1) PRIOR bracketed, comma separate list specifying prior parameter distributions.   input format   PRIOR = (items, ..., parameterName, priorType, val1, val2),   (items, ..., parameterName, priorType, val1, val2).   example, single group 10-item dichotomous tests, using default 2PL model,   defining normal prior N(0,2) first 5 item intercepts (d) can defined   PRIOR = (1-5, d, norm, 0, 2) Currently supported priors form: (items, norm, mean, sd)   normal/Gaussian, (items, lnorm, log_mean, log_sd) log-normal,   (items, beta, alpha, beta) beta, (items, expbeta, alpha, beta)   beta distribution applying   function plogis input value (note, specifically applying beta   prior lower-bound parameters 3/4PL models) LBOUND bracketed, comma separate list specifying lower bounds estimated   parameters (used optimizers L-BFGS-B nlminb).   input format LBOUND = (items, ..., parameterName, value),   (items, ..., parameterName, value). example, single group 10-item dichotomous tests, using 3PL model   setting lower bounds 'g' parameters first 5 items 0.2 accomplished   LBOUND = (1-5, g, 0.2) UBOUND LBOUND, specifying upper bounds estimated parameters START bracketed, comma separate list specifying starting values individual parameters.   input form (items, ..., parameterName, value). instance, setting 10th   12th 15th item slope parameters (a1) 1.0 specified START = (10, 12-15, a1, 1.0) hands control starting values pass argument pars = 'values'   whatever estimation function used FIXED bracketed, comma separate list specifying parameters fixed   starting values (.e., freely estimated).   input form (items, ..., parameterName). instance, fixing 10th   12th 15th item slope parameters (a1) accomplished FIXED = (10, 12-15, a1) hands control estimated values pass argument pars = 'values'   whatever estimation function used FREE Equivalent FIXED input, except parameters freely estimated instead   fixed starting value NEXPLORE Number exploratory factors extract. Usually required   passing numeric value model argument estimation function   generate exploratory factor analysis model, however different start values,   priors, lower upper bounds, etc, desired input can used","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Specify model information — mirt.model","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Specify model information — mirt.model","text":"Phil Chalmers rphilip.chalmers@gmail.com Alexander Robitzsch","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specify model information — mirt.model","text":"","code":"if (FALSE) { # \\dontrun{  # interactively through the console (not run) #model <- mirt.model() #  F1 = 1,2,3,4-10 #  F2 = 10-20 #  (F1*F2) = 1,2,3,4-10 #  COV = F1*F2   # Or alternatively with a string input s <- 'F1 = 1,2,3,4-10       F2 = 10-20       (F1*F2) = 1,2,3,4-10       COV = F1*F2' model <- mirt.model(s)  # strings can also be passed to the estimation functions directly, #   which silently calls mirt.model(). E.g., using the string above: # mod <- mirt(data, s)   # Q-matrix specification Q <- matrix(c(1,1,1,0,0,0,0,0,0,1,1,1), ncol=2, dimnames = list(NULL, c('Factor1', 'Factor2'))) COV <- matrix(c(FALSE, TRUE, TRUE, FALSE), 2) model <- mirt.model(Q, COV=COV)  ## constrain various items slopes and all intercepts in single group model to be equal, #   and use a log-normal prior for all the slopes s <- 'F = 1-10       CONSTRAIN = (1-3, 5, 6, a1), (1-10, d)       PRIOR = (1-10, a1, lnorm, .2, .2)' model <- mirt.model(s)   ## constrain various items slopes and intercepts across groups for use in multipleGroup(), #  and constrain first two slopes within 'group1' to be equal s <- 'F = 1-10       CONSTRAIN = (1-2, a1)       CONSTRAINB = (1-3, 5, 6, a1), (1-10, d)' model <- mirt.model(s)   ## specify model using raw item names data(data.read, package = 'sirt') dat <- data.read  # syntax with variable names mirtsyn2 <- \"        F1 = A1,B2,B3,C4        F2 = A1-A4,C2,C4        MEAN = F1        COV = F1*F1, F1*F2        CONSTRAIN=(A2-A4,a2),(A3,C2,d)        PRIOR = (C3,A2-A4,a2,lnorm, .2, .2),(B3,d,norm,0,.0001)\" # create a mirt model mirtmodel <- mirt.model(mirtsyn2, itemnames=dat) # or equivalently: # mirtmodel <- mirt.model(mirtsyn2, itemnames=colnames(dat))  # mod <- mirt(dat , mirtmodel)  # using sprintf() to functionally fill in information (useful for long tests # or more complex specifications) nitems <- 100 s <- sprintf('F = 1-%i       CONSTRAIN = (%s, a1)       CONSTRAINB = (%s, a1), (1-%i, d)',       nitems, \"1,2,4,50,100\",       paste0(1:45, collapse=','),       nitems) cat(s) model <- mirt.model(s)      } # }"},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a parallel cluster object to be used in internal functions — mirtCluster","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"function defines object placed relevant internal environment defined mirt. Internal functions calcLogLik, fscores, etc, utilize object automatically capitalize parallel processing architecture. object defined call parallel::makeCluster(). Note defining parallel objects (simulation designs, example) recommended define mirtCluster.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"","code":"mirtCluster(spec, omp_threads, remove = FALSE, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"spec input passed parallel::makeCluster(). input given maximum number available local cores minus 1 used. Setting NULL skip new definition (allows omp_threads used independently) omp_threads number OpenMP threads use (currently applies E-step computations ). used argument input missing remove logical; remove previously defined mirtCluster()? ... additional arguments pass parallel::makeCluster","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"","code":"if (FALSE) { # \\dontrun{ if(interactive()){   # use all available cores   mirtCluster()   mirtCluster(remove = TRUE)    # make 4 cores available for parallel computing   mirtCluster(4)   mirtCluster(remove = TRUE)    # create 3 core architecture in R, and 4 thread architecture with OpenMP   mirtCluster(spec = 3, omp_threads = 4)    # leave previous multicore objects, but change omp_threads   mirtCluster(spec = NULL, omp_threads = 2) }  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed effects modeling for MIRT models — mixedmirt","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"mixedmirt fits MIRT models using FIML estimation dichotomous polytomous IRT models conditional fixed random effect person item level covariates. can also understood 'explanatory IRT' fixed effects modeled, multilevel/mixed IRT random fixed effects included. method uses MH-RM algorithm exclusively. Additionally, computation log-likelihood can sped using parallel estimation via mirtCluster.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"","code":"mixedmirt(   data,   covdata = NULL,   model = 1,   fixed = ~1,   random = NULL,   itemtype = \"Rasch\",   lr.fixed = ~1,   lr.random = NULL,   itemdesign = NULL,   constrain = NULL,   pars = NULL,   return.design = FALSE,   SE = TRUE,   internal_constraints = TRUE,   technical = list(SEtol = 1e-04),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"data matrix data.frame consists numerically ordered data, organized form integers,  missing data coded NA covdata data.frame consists nrow(data) K 'person level' fixed random predictors. missing data present object observations covdata data removed row-wise via rowSums(.na(covdata)) > 0 model object returned , string passed , mirt.model() declare IRT model estimated. See mirt.model mirt detail fixed right sided R formula specifying fixed effect (aka 'explanatory') predictors covdata itemdesign. estimate intercepts item keyword items reserved automatically added itemdesign input. polytomous items model items argument valid since intercept parameters freely estimated identified parameterizations found mirt, first column fixed design matrix (commonly intercept reference group) omitted random right sided formula list formulas containing crossed random effects form v1 + ... v_n | G, G grouping variable v_n random numeric predictors within group. intercept value specified default correlations v's G estimated, can suppressed including ~ -1 + ... 0 constant. G may contain interaction terms, group:items include cross person-level interactions effects itemtype itemtype mirt, except fixed random inputs used support following item types: c('PC2PL', 'PC3PL', '2PLNRM', '3PLNRM', '3PLuNRM', '4PLNRM') lr.fixed R formula (list formulas) specify regression effects latent variables variables covdata. used construct models -called 'latent regression model' explain person-level ability/trait differences. named list formulas supplied (names correspond latent trait names model) specific regression effects can estimated factor. Supplying single formula estimate regression parameters latent traits default. lr.random list random effect terms modeling variability latent trait scores, syntax uses style random argument. Useful building -called 'multilevel IRT' models non-Rasch (multilevel Rasch models technically require can built using fixed random inputs alone) itemdesign data.frame object used create design matrix items, nrow(itemdesign) == nitems number columns equal number fixed effect predictors (.e., item intercepts). default items variable reserved modeling item intercept parameters constrain list indicating parameter equality constrains. See mirt detail pars used parameter starting values. See mirt detail return.design logical; return design matrices (potentially) reassigned? SE logical; compute standard errors approximating information matrix using MHRM algorithm? Default TRUE internal_constraints logical; use internally defined constraints constraining effects across persons items? Default TRUE. Setting FALSE runs risk -identification technical technical list passed MH-RM estimation engine, SEtol default increased .0001. Additionally, argument RANDSTART available indicate iteration (burn-stage) additional random effect variables begin approximated (.e., elements lr.random random). default RANDSTART start iteration 100, random effects included default number burn-iterations increased 150 200. See mirt details ... additional arguments passed MH-RM estimation engine. See mirt details examples","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"function returns object class MixedClass   (MixedClass-class).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"dichotomous response models, mixedmirt follows general form $$P(x = 1|\\theta, \\psi) = g + \\frac{(u - g)}{1 + exp(-1 * [\\theta +  X \\beta + Z \\delta])}$$ X design matrix associated \\(\\beta\\) fixed effect intercept coefficients,  Z design matrix associated \\(\\delta\\) random effects intercepts.  simplicity easier interpretation, unique item intercept values typically found  \\(X \\beta\\)  extracted reassigned within mirt's 'intercept' parameters (e.g., 'd').  observe design matrices structured prior reassignment estimation pass  argument return.design = TRUE. Polytomous IRT models follow similar format except item intercepts automatically  estimated internally, rendering items argument fixed formula redundant  therefore must omitted specification. mixture dichotomous  polytomous items intercepts dichotomous models also estimated consistency. decomposition \\(\\theta\\) parameters also possible form  latent regression multilevel IRT models using lr.fixed lr.random  inputs. effects decompose \\(\\theta\\) $$\\theta = V \\Gamma + W \\zeta + \\epsilon$$ V W fixed random effects design matrices associated coefficients. simulate expected posteriori predictions random effect terms  use randef function.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models MH-RM Algorithm. Journal Educational Measurement, 52, 200-222. doi:10.1111/jedm.12072","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"","code":"if (FALSE) { # \\dontrun{  # make some data set.seed(1234) N <- 750 a <- matrix(rlnorm(10,.3,1),10,1) d <- matrix(rnorm(10), 10) Theta <- matrix(sort(rnorm(N))) pseudoIQ <- Theta * 5 + 100  + rnorm(N, 0 , 5) pseudoIQ <- (pseudoIQ - mean(pseudoIQ))/10  #rescale variable for numerical stability group <- factor(rep(c('G1','G2','G3'), each = N/3)) data <- simdata(a,d,N, itemtype = rep('2PL',10), Theta=Theta) covdata <- data.frame(group, pseudoIQ)  itemstats(data)  # use parallel computing if(interactive()) mirtCluster()  # specify IRT model model <- 'Theta = 1-10'  # model with no person predictors mod0 <- mirt(data, model, itemtype = 'Rasch')  # group as a fixed effect predictor (aka, uniform dif) mod1 <- mixedmirt(data, covdata, model, fixed = ~ 0 + group + items) anova(mod0, mod1) summary(mod1) coef(mod1)  # same model as above in lme4 wide <- data.frame(id=1:nrow(data),data,covdata) long <- reshape2::melt(wide, id.vars = c('id', 'group', 'pseudoIQ')) library(lme4) lmod0 <- glmer(value ~ 0 + variable + (1|id), long, family = binomial) lmod1 <- glmer(value ~ 0 + group + variable + (1|id), long, family = binomial) anova(lmod0, lmod1)  # model using 2PL items instead of Rasch mod1b <- mixedmirt(data, covdata, model, fixed = ~ 0 + group + items, itemtype = '2PL') anova(mod1, mod1b) #better with 2PL models using all criteria (as expected, given simdata pars)  # continuous predictor with group mod2 <- mixedmirt(data, covdata, model, fixed = ~ 0 + group + items + pseudoIQ) summary(mod2) anova(mod1b, mod2)  # view fixed design matrix with and without unique item level intercepts withint <- mixedmirt(data, covdata, model, fixed = ~ 0 + items + group, return.design = TRUE) withoutint <- mixedmirt(data, covdata, model, fixed = ~ 0 + group, return.design = TRUE)  # notice that in result above, the intercepts 'items1 to items 10' were reassigned to 'd' head(withint$X) tail(withint$X) head(withoutint$X) # no intercepts design here to be reassigned into item intercepts tail(withoutint$X)  ################################################### ### random effects # make the number of groups much larger covdata$group <- factor(rep(paste0('G',1:50), each = N/50))  # random groups rmod1 <- mixedmirt(data, covdata, 1, fixed = ~ 0 + items, random = ~ 1|group) summary(rmod1) coef(rmod1)  # random groups and random items rmod2 <- mixedmirt(data, covdata, 1, random = list(~ 1|group, ~ 1|items)) summary(rmod2) eff <- randef(rmod2) #estimate random effects  # random slopes with fixed intercepts (suppressed correlation) rmod3 <- mixedmirt(data, covdata, 1, fixed = ~ 0 + items, random = ~ -1 + pseudoIQ|group) summary(rmod3) eff <- randef(rmod3) str(eff)  ################################################### ## LLTM, and 2PL version of LLTM data(SAT12) data <- key2binary(SAT12,                    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) model <- 'Theta = 1-32'  # for unconditional intercept comparison mod <- mirt(data, model, itemtype='Rasch') coef(mod, simplify=TRUE)  # Suppose that the first 16 items were suspected to be easier than the last 16 items, #   and we wish to test this item structure hypothesis (more intercept designs are possible #   by including more columns). itemdesign <- data.frame(itemorder = factor(c(rep('easier', 16), rep('harder', 16)))) rownames(itemdesign) <- colnames(data) itemdesign  # notice that the 'fixed = ~ ... + items' argument is omitted LLTM <- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, itemdesign = itemdesign,    SE = TRUE) # SE argument ensures that the information matrix is computed accurately summary(LLTM) coef(LLTM) wald(LLTM) L <- matrix(c(-1, 1, 0), 1) wald(LLTM, L) #first half different from second  # compare to items with estimated slopes (2PL) twoPL <- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, itemtype = '2PL',                    itemdesign = itemdesign) # twoPL not mixing too well (AR should be between .2 and .5), decrease MHcand twoPL <- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, itemtype = '2PL',                   itemdesign = itemdesign, technical = list(MHcand = 0.8)) anova(twoPL, LLTM) #much better fit summary(twoPL) coef(twoPL)  wald(twoPL) L <- matrix(0, 1, 34) L[1, 1] <- 1 L[1, 2] <- -1 wald(twoPL, L) # n.s., which is the correct conclusion. Rasch approach gave wrong inference  ## LLTM with item error term LLTMwithError <- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, random = ~ 1|items,     itemdesign = itemdesign) summary(LLTMwithError) # large item level variance after itemorder is regressed; not a great predictor of item difficulty coef(LLTMwithError)  ################################################### ### Polytomous example  # make an arbitrary group difference covdat <- data.frame(group = rep(c('m', 'f'), nrow(Science)/2))  # partial credit model mod <- mixedmirt(Science, covdat, model=1, fixed = ~ 0 + group) coef(mod)  # gpcm to estimate slopes mod2 <- mixedmirt(Science, covdat, model=1, fixed = ~ 0 + group,                  itemtype = 'gpcm') summary(mod2) anova(mod, mod2)  # graded model mod3 <- mixedmirt(Science, covdat, model=1, fixed = ~ 0 + group,                  itemtype = 'graded') coef(mod3)   ################################################### # latent regression with Rasch and 2PL models  set.seed(1) n <- 300 a <- matrix(1, 10) d <- matrix(rnorm(10)) Theta <- matrix(c(rnorm(n, 0), rnorm(n, 1), rnorm(n, 2))) covdata <- data.frame(group=rep(c('g1','g2','g3'), each=n)) dat <- simdata(a, d, N=n*3, Theta=Theta, itemtype = '2PL') itemstats(dat)  # had we known the latent abilities, we could have computed the regression coefs summary(lm(Theta ~ covdata$group))  # but all we have is observed test data. Latent regression helps to recover these coefs # Rasch model approach (and mirt equivalent) rmod0 <- mirt(dat, 1, 'Rasch') # unconditional  # these two models are equivalent rmod1a <- mirt(dat, 1, 'Rasch', covdata = covdata, formula = ~ group) rmod1b <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items + group) anova(rmod0, rmod1b) coef(rmod1a, simplify=TRUE) summary(rmod1b)  # 2PL, requires different input to allow Theta variance to remain fixed mod0 <- mirt(dat, 1) # unconditional mod1a <- mirt(dat, 1, covdata = covdata, formula = ~ group, itemtype = '2PL') mod1b <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, lr.fixed = ~group, itemtype = '2PL') anova(mod0, mod1b) coef(mod1a)$lr.betas summary(mod1b)  # specifying specific regression effects is accomplished by passing a list of formula model <- 'F1 = 1-5          F2 = 6-10' covdata$contvar <- rnorm(nrow(covdata)) mod2 <- mirt(dat, model, itemtype = 'Rasch', covdata=covdata,         formula = list(F1 = ~ group + contvar, F2 = ~ group)) coef(mod2)[11:12] mod2b <- mixedmirt(dat, covdata, model, fixed = ~ 0 + items,         lr.fixed = list(F1 = ~ group + contvar, F2 = ~ group)) summary(mod2b)  #################################################### ## Simulated Multilevel Rasch Model  set.seed(1) N <- 2000 a <- matrix(rep(1,10),10,1) d <- matrix(rnorm(10)) cluster = 100 random_intercept = rnorm(cluster,0,1) Theta = numeric() for (i in 1:cluster)     Theta <- c(Theta, rnorm(N/cluster,0,1) + random_intercept[i])  group = factor(rep(paste0('G',1:cluster), each = N/cluster)) covdata <- data.frame(group) dat <- simdata(a,d,N, itemtype = rep('2PL',10), Theta=matrix(Theta)) itemstats(dat)  # null model mod1 <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, random = ~ 1|group) summary(mod1)  # include level 2 predictor for 'group' variance covdata$group_pred <- rep(random_intercept, each = N/cluster) mod2 <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items + group_pred, random = ~ 1|group)  # including group means predicts nearly all variability in 'group' summary(mod2) anova(mod1, mod2)  # can also be fit for Rasch/non-Rasch models with the lr.random input mod1b <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, lr.random = ~ 1|group) summary(mod1b)  mod2b <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items + group_pred, lr.random = ~ 1|group) summary(mod2b) anova(mod1b, mod2b)  mod3 <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, lr.random = ~ 1|group, itemtype = '2PL') summary(mod3) anova(mod1b, mod3)  head(cbind(randef(mod3)$group, random_intercept))  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an estimated mirt model to a data.frame — mod2values","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"Given estimated model mirt's model fitting functions function convert model parameters design data frame starting values parameter characteristics (similar using pars = 'values' obtaining starting values).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"","code":"mod2values(x)"},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"x estimated model x mirt package","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"","code":"if (FALSE) { # \\dontrun{ dat <- expand.table(LSAT7) mod <- mirt(dat, \"F=1-5                   CONSTRAIN=(1-5, a1)\") values <- mod2values(mod) values  # use the converted values as starting values in a new model, and reduce TOL mod2 <- mirt(dat, 1, pars = values, TOL=1e-5) coef(mod2, simplify=TRUE)  # use parameters on different dataset mod3 <- mirt(expand.table(LSAT6), pars=values) coef(mod3, simplify=TRUE)  # supports differing itemtypes on second model sv <- mirt(Science, itemtype=c('graded', rep('gpcm', 3)), pars='values') mod3 <- mirt(Science, pars = sv)  # itemtype omitted coef(mod3, simplify=TRUE)$items extract.mirt(mod3, 'itemtype')   } # }"},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple Group Estimation — multipleGroup","title":"Multiple Group Estimation — multipleGroup","text":"multipleGroup performs full-information maximum-likelihood multiple group analysis combination dichotomous polytomous data item response theory paradigm using either Cai's (2010) Metropolis-Hastings Robbins-Monro (MHRM) algorithm EM algorithm approach. function may used detecting differential item functioning (DIF), thought DIF function may provide convenient approach. grouping variable specified dentype input can modified fit mixture models estimate latent group components.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple Group Estimation — multipleGroup","text":"","code":"multipleGroup(   data,   model = 1,   group,   itemtype = NULL,   invariance = \"\",   method = \"EM\",   dentype = \"Gaussian\",   itemdesign = NULL,   item.formula = NULL,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple Group Estimation — multipleGroup","text":"data matrix data.frame consists numerically ordered data, organized form integers,  missing data coded NA model string passed , model object returned , mirt.model declaring global model estimated (useful apply constraints ) group character factor vector indicating group membership. character vector supplied automatically transformed factor variable. well, first level (factorized) grouping variable treated \"reference\" group itemtype can type input documented mirt, however may also ngroups nitems matrix specifying type IRT models group, respectively. Rows input correspond levels group input. mixture models rows correspond respective mixture grouping variables constructed, IRT models within mixtures invariance character vector containing following possible options: 'free_mean' 'free_means' freely estimate latent means focal groups       (reference group constrained vector 0's) 'free_var', 'free_vars', 'free_variance', 'free_variances' freely estimate latent variances focal groups       (reference group variances constrained 1) 'slopes' constrain slopes equal across groups 'intercepts' constrain intercepts equal across       groups, note nominal models also includes category specific slope parameters Additionally, specifying specific item name bundles (colnames(data))   constrain freely estimated parameters item equal across groups.   useful selecting 'anchor' items vertical horizontal scaling, detecting   differential item functioning (DIF) across groups method character object either 'EM', 'QMCEM', 'MHRM' (default 'EM'). See mirt details dentype type density form use latent trait parameters. Current options include   methods described mirt, well  'mixture-#' estimates mixtures Gaussian distributions,       # placeholder represents number potential grouping variables       (e.g., 'mixture-3' estimate 3 underlying classes). class       assigned group name MIXTURE_#, # class number.       Note internally mixture coefficients stored log values       first mixture group coefficient fixed 0 itemdesign see mirt details item.formula see mirt details ... additional arguments passed estimation engine. See mirt details examples","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiple Group Estimation — multipleGroup","text":"function returns object class MultipleGroupClass   (MultipleGroupClass-class).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiple Group Estimation — multipleGroup","text":"default estimation multipleGroup assumes models maximally independent, therefore initially performed sub-setting data running identical models mirt aggregating results (e.g., log-likelihood). However, constrains may automatically imposed across groups invoking various invariance keywords. Users may also supply list parameter equality constraints constrain argument, define equality constraints using mirt.model syntax (recommended).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multiple Group Estimation — multipleGroup","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Magnus, B. E.  Garnier-Villarreal (2022). multidimensional zero-inflated graded response model ordinal symptom data. Psychological Methods, 27, 261-279. Wall, M., M., Park, J., Y., Moustaki . (2015). IRT modeling presence zero-inflation application psychiatric disorder severity. Applied Psychological Measurement 39: 583-597.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multiple Group Estimation — multipleGroup","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple Group Estimation — multipleGroup","text":"","code":"if (FALSE) { # \\dontrun{  # single factor set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  # marginal information itemstats(dat)  # conditional information itemstats(dat, group=group)  mod_configural <- multipleGroup(dat, 1, group = group) #completely separate analyses # limited information fit statistics M2(mod_configural)  mod_metric <- multipleGroup(dat, 1, group = group, invariance=c('slopes')) #equal slopes # equal intercepts, free variance and means mod_scalar2 <- multipleGroup(dat, 1, group = group,                              invariance=c('slopes', 'intercepts', 'free_var','free_means')) mod_scalar1 <- multipleGroup(dat, 1, group = group,  #fixed means                              invariance=c('slopes', 'intercepts', 'free_var')) mod_fullconstrain <- multipleGroup(dat, 1, group = group,                              invariance=c('slopes', 'intercepts')) extract.mirt(mod_fullconstrain, 'time') #time of estimation components  # optionally use Newton-Raphson for (generally) faster convergence in the #  M-step's, though occasionally less stable mod_fullconstrain <- multipleGroup(dat, 1, group = group, optimizer = 'NR',                              invariance=c('slopes', 'intercepts')) extract.mirt(mod_fullconstrain, 'time') #time of estimation components  summary(mod_scalar2) coef(mod_scalar2, simplify=TRUE) residuals(mod_scalar2) plot(mod_configural) plot(mod_configural, type = 'info') plot(mod_configural, type = 'trace') plot(mod_configural, type = 'trace', which.items = 1:4) itemplot(mod_configural, 2) itemplot(mod_configural, 2, type = 'RE')  anova(mod_metric, mod_configural) #equal slopes only anova(mod_scalar2, mod_metric) #equal intercepts, free variance and mean anova(mod_scalar1, mod_scalar2) #fix mean anova(mod_fullconstrain, mod_scalar1) #fix variance  # compared all at once (in order of most constrained to least) anova(mod_fullconstrain, mod_scalar2, mod_configural)   # test whether first 6 slopes should be equal across groups values <- multipleGroup(dat, 1, group = group, pars = 'values') values constrain <- list(c(1, 63), c(5,67), c(9,71), c(13,75), c(17,79), c(21,83)) equalslopes <- multipleGroup(dat, 1, group = group, constrain = constrain) anova(equalslopes, mod_configural)  # same as above, but using mirt.model syntax newmodel <- '     F = 1-15     CONSTRAINB = (1-6, a1)' equalslopes <- multipleGroup(dat, newmodel, group = group) coef(equalslopes, simplify=TRUE)  ############ # vertical scaling (i.e., equating when groups answer items others do not) dat2 <- dat dat2[group == 'D1', 1:2] <- dat2[group != 'D1', 14:15] <- NA head(dat2) tail(dat2)  # items with missing responses need to be constrained across groups for identification nms <- colnames(dat2) mod <- multipleGroup(dat2, 1, group, invariance = nms[c(1:2, 14:15)])  # this will throw an error without proper constraints (SEs cannot be computed either) # mod <- multipleGroup(dat2, 1, group)  # model still does not have anchors, therefore need to add a few (here use items 3-5) mod_anchor <- multipleGroup(dat2, 1, group,                             invariance = c(nms[c(1:5, 14:15)], 'free_means', 'free_var')) coef(mod_anchor, simplify=TRUE)  # check if identified by computing information matrix mod_anchor <- multipleGroup(dat2, 1, group, pars = mod2values(mod_anchor), TOL=NaN, SE=TRUE,                             invariance = c(nms[c(1:5, 14:15)], 'free_means', 'free_var')) mod_anchor coef(mod_anchor) coef(mod_anchor, printSE=TRUE)   ############# # DIF test for each item (using all other items as anchors) itemnames <- colnames(dat) refmodel <- multipleGroup(dat, 1, group = group, SE=TRUE,                           invariance=c('free_means', 'free_var', itemnames))  # loop over items (in practice, run in parallel to increase speed). May be better to use ?DIF estmodels <- vector('list', ncol(dat)) for(i in 1:ncol(dat))     estmodels[[i]] <- multipleGroup(dat, 1, group = group, verbose = FALSE,                              invariance=c('free_means', 'free_var', itemnames[-i])) anova(refmodel, estmodels[[1]]) (anovas <- lapply(estmodels, function(x, refmodel) anova(refmodel, x),    refmodel=refmodel))  # family-wise error control p <- do.call(rbind, lapply(anovas, function(x) x[2, 'p'])) p.adjust(p, method = 'BH')  # same as above, except only test if slopes vary (1 df) # constrain all intercepts estmodels <- vector('list', ncol(dat)) for(i in 1:ncol(dat))     estmodels[[i]] <- multipleGroup(dat, 1, group = group, verbose = FALSE,                              invariance=c('free_means', 'free_var', 'intercepts',                              itemnames[-i]))  (anovas <- lapply(estmodels, function(x, refmodel) anova(refmodel, x),    refmodel=refmodel))  # quickly test with Wald test using DIF() mod_configural2 <- multipleGroup(dat, 1, group = group, SE=TRUE) DIF(mod_configural2, which.par = c('a1', 'd'), Wald=TRUE, p.adjust = 'fdr')    ############# # Three group model where the latent variable parameters are constrained to # be equal in the focal groups  set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dataset3 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2, dataset3) group <- rep(c('D1', 'D2', 'D3'), each=N)  # marginal information itemstats(dat)  # conditional information itemstats(dat, group=group)  model <- 'F1 = 1-15           FREE[D2, D3] = (GROUP, MEAN_1), (GROUP, COV_11)           CONSTRAINB[D2,D3] = (GROUP, MEAN_1), (GROUP, COV_11)'  mod <- multipleGroup(dat, model, group = group, invariance = colnames(dat)) coef(mod, simplify=TRUE)  ############# # Testing main effects in multiple independent grouping variables set.seed(1234) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 500  # generated data have interaction effect for latent means, as well as a # main effect across D but no main effect across G d11 <- simdata(a, d, N, itemtype, mu = 0) d12 <- simdata(a, d, N, itemtype, mu = 0) d13 <- simdata(a, d, N, itemtype, mu = 0) d21 <- simdata(a, d, N, itemtype, mu = 1/2) d22 <- simdata(a, d, N, itemtype, mu = 1/2) d23 <- simdata(a, d, N, itemtype, mu = -1) dat <- do.call(rbind, list(d11, d12, d13, d21, d22, d23)) group <- rep(c('G1.D1', 'G1.D2', 'G1.D3', 'G2.D1', 'G2.D2', 'G2.D3'), each=N) table(group)  # in practice, group would be organized in a data.frame as follows df <- data.frame(group) dfw <- tidyr::separate_wider_delim(df, group, delim='.', names = c('G', 'D')) head(dfw)  # for use with multipleGroup() combine into a single long group group <- with(dfw, factor(G):factor(D))  # conditional information itemstats(dat, group=group)  mod <- multipleGroup(dat, group = group, SE=TRUE,                      invariance = c(colnames(dat), 'free_mean', 'free_var')) coef(mod, simplify=TRUE) sapply(coef(mod, simplify=TRUE), \\(x) unname(x$means)) # mean estimates wald(mod) # view parameter names for later testing  # test for main effect over G group (manually compute marginal mean) wald(mod, \"0 + MEAN_1.123 + MEAN_1.185 = MEAN_1.247 + MEAN_1.309 + MEAN_1.371\")  # test for main effect over D group  (manually compute marginal means) wald(mod, c(\"0 + MEAN_1.247 = MEAN_1.123 + MEAN_1.309\",             \"0 + MEAN_1.247 = MEAN_1.185 + MEAN_1.371\"))  # post-hoc tests (better practice would include p.adjust() ) wald(mod, \"0 + MEAN_1.247 = MEAN_1.123 + MEAN_1.309\") # D1 vs D2 wald(mod, \"0 + MEAN_1.247 = MEAN_1.185 + MEAN_1.371\") # D1 vs D3 wald(mod, \"MEAN_1.123 + MEAN_1.309 = MEAN_1.185 + MEAN_1.371\") # D2 vs D3   ############# # multiple factors  a <- matrix(c(abs(rnorm(5,1,.3)), rep(0,15),abs(rnorm(5,1,.3)),      rep(0,15),abs(rnorm(5,1,.3))), 15, 3) d <- matrix(rnorm(15,0,.7),ncol=1) mu <- c(-.4, -.7, .1) sigma <- matrix(c(1.21,.297,1.232,.297,.81,.252,1.232,.252,1.96),3,3) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = mu, sigma = sigma) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  # group models model <- '    F1 = 1-5    F2 = 6-10    F3 = 11-15'  # define mirt cluster to use parallel architecture if(interactive()) mirtCluster()  # EM approach (not as accurate with 3 factors, but generally good for quick model comparisons) mod_configural <- multipleGroup(dat, model, group = group) #completely separate analyses mod_metric <- multipleGroup(dat, model, group = group, invariance=c('slopes')) #equal slopes mod_fullconstrain <- multipleGroup(dat, model, group = group, #equal means, slopes, intercepts                              invariance=c('slopes', 'intercepts'))  anova(mod_metric, mod_configural) anova(mod_fullconstrain, mod_metric)  # same as above, but with MHRM (generally  more accurate with 3+ factors, but slower) mod_configural <- multipleGroup(dat, model, group = group, method = 'MHRM') mod_metric <- multipleGroup(dat, model, group = group, invariance=c('slopes'), method = 'MHRM') mod_fullconstrain <- multipleGroup(dat, model, group = group, method = 'MHRM',                              invariance=c('slopes', 'intercepts'))  anova(mod_metric, mod_configural) anova(mod_fullconstrain, mod_metric)  ############ # polytomous item example set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) d <- cbind(d, d-1, d-2) itemtype <- rep('graded', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N)) model <- 'F1 = 1-15'  mod_configural <- multipleGroup(dat, model, group = group) plot(mod_configural) plot(mod_configural, type = 'SE') itemplot(mod_configural, 1) itemplot(mod_configural, 1, type = 'info') plot(mod_configural, type = 'trace') # messy, score function typically better plot(mod_configural, type = 'itemscore')  fs <- fscores(mod_configural, full.scores = FALSE) head(fs[[\"D1\"]]) fscores(mod_configural, method = 'EAPsum', full.scores = FALSE)  # constrain slopes within each group to be equal (but not across groups) model2 <- 'F1 = 1-15            CONSTRAIN = (1-15, a1)' mod_configural2 <- multipleGroup(dat, model2, group = group) plot(mod_configural2, type = 'SE') plot(mod_configural2, type = 'RE') itemplot(mod_configural2, 10)  ############ ## empirical histogram example (normal and bimodal groups) set.seed(1234) a <- matrix(rlnorm(50, .2, .2)) d <- matrix(rnorm(50)) ThetaNormal <- matrix(rnorm(2000)) ThetaBimodal <- scale(matrix(c(rnorm(1000, -2), rnorm(1000,2)))) #bimodal Theta <- rbind(ThetaNormal, ThetaBimodal) dat <- simdata(a, d, 4000, itemtype = '2PL', Theta=Theta) group <- rep(c('G1', 'G2'), each=2000)  EH <- multipleGroup(dat, 1, group=group, dentype=\"empiricalhist\", invariance = colnames(dat)) coef(EH, simplify=TRUE) plot(EH, type = 'empiricalhist', npts = 60)  # DIF test for item 1 EH1 <- multipleGroup(dat, 1, group=group, dentype=\"empiricalhist\", invariance = colnames(dat)[-1]) anova(EH, EH1)  #-------------------------------- # Mixture model (no prior group variable specified)  set.seed(12345) nitems <- 20 a1 <- matrix(.75, ncol=1, nrow=nitems) a2 <- matrix(1.25, ncol=1, nrow=nitems) d1 <- matrix(rnorm(nitems,0,1),ncol=1) d2 <- matrix(rnorm(nitems,0,1),ncol=1) itemtype <- rep('2PL', nrow(a1)) N1 <- 500 N2 <- N1*2 # second class twice as large  dataset1 <- simdata(a1, d1, N1, itemtype) dataset2 <- simdata(a2, d2, N2, itemtype) dat <- rbind(dataset1, dataset2) # group <- c(rep('D1', N1), rep('D2', N2))  # Mixture Rasch model (Rost, 1990) models <- 'F1 = 1-20            CONSTRAIN = (1-20, a1)' mod_mix <- multipleGroup(dat, models, dentype = 'mixture-2', GenRandomPars = TRUE) coef(mod_mix, simplify=TRUE) summary(mod_mix) plot(mod_mix) plot(mod_mix, type = 'trace') itemplot(mod_mix, 1, type = 'info')  head(fscores(mod_mix)) # theta estimates head(fscores(mod_mix, method = 'classify')) # classification probability itemfit(mod_mix)  # Mixture 2PL model mod_mix2 <- multipleGroup(dat, 1, dentype = 'mixture-2', GenRandomPars = TRUE) anova(mod_mix, mod_mix2) coef(mod_mix2, simplify=TRUE) itemfit(mod_mix2)  # Compare to single group mod <- mirt(dat) anova(mod, mod_mix2)  ######################################## # Zero-inflated 2PL IRT model (Wall, Park, and Moustaki, 2015)  n <- 1000 nitems <- 20  a <- rep(2, nitems) d <- rep(c(-2,-1,0,1,2), each=nitems/5) zi_p <- 0.2 # Proportion of people in zero class  theta <- rnorm(n, 0, 1) zeros <- matrix(0, n*zi_p, nitems) nonzeros <- simdata(a, d, n*(1-zi_p), itemtype = '2PL',                    Theta = as.matrix(theta[1:(n*(1-zi_p))])) data <- rbind(nonzeros, zeros)  # define class with extreme theta but fixed item parameters zi2PL <- \"F = 1-20           START [MIXTURE_1] = (GROUP, MEAN_1, -100), (GROUP, COV_11, .00001),                               (1-20, a1, 1.0), (1-20, d, 0)           FIXED [MIXTURE_1] = (GROUP, MEAN_1), (GROUP, COV_11),                               (1-20, a1), (1-20, d)\"  # define custom Theta integration grid that contains extreme theta + normal grid technical <- list(customTheta = matrix(c(-100, seq(-6,6,length.out=61))))  # fit ZIM-IRT zi2PL.fit <- multipleGroup(data, zi2PL, dentype = 'mixture-2', technical=technical) coef(zi2PL.fit, simplify=TRUE)  # classification estimates pi_hat <- fscores(zi2PL.fit, method = 'classify') head(pi_hat) tail(pi_hat)  # EAP estimates (not useful for zip class) fs <- fscores(zi2PL.fit) head(fs) tail(fs)  ######################################## # Zero-inflated graded response model (Magnus and Garnier-Villarreal, 2022)  n <- 1000 nitems <- 20  a <- matrix(rlnorm(20,.2,.3))  # for the graded model, ensure that there is enough space between the intercepts, # otherwise closer categories will not be selected often (minimum distance of 0.3 here) diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d <- diffs + rnorm(20)  zi_p <- 0.2 # Proportion of people in zero/lowest category class  theta <- rnorm(n, 0, 1) zeros <- matrix(0, n*zi_p, nitems) nonzeros <- simdata(a, d, n*(1-zi_p), itemtype = 'graded',                     Theta = as.matrix(theta[1:(n*(1-zi_p))])) data <- rbind(nonzeros, zeros)  # intercepts will be labelled as d1 through d4 apply(data, 2, table)  # ignoring zero inflation (bad idea) modGRM <- mirt(data) coef(modGRM, simplify=TRUE)  # Define class with extreme theta but fixed item parameters #   For GRM in zero-inflated class the intercept values are arbitrary #   as the model forces the responses all into the first category (hence, #   spacing arbitrarily set to 1) ziGRM <- \"F = 1-20           START [MIXTURE_1] = (GROUP, MEAN_1, -100), (GROUP, COV_11, .00001),                               (1-20, a1, 1.0),                               (1-20, d1, 2), (1-20, d2, 1), (1-20, d3, 0), (1-20, d4, -1)           FIXED [MIXTURE_1] = (GROUP, MEAN_1), (GROUP, COV_11),                               (1-20, a1),                               (1-20, d1), (1-20, d2), (1-20, d3), (1-20, d4)\"  # define custom Theta integration grid that contains extreme theta + normal grid technical <- list(customTheta = matrix(c(-100, seq(-6,6,length.out=61))))  # fit zero-inflated GRM ziGRM.fit <- multipleGroup(data, ziGRM, dentype = 'mixture-2', technical=technical) coef(ziGRM.fit, simplify=TRUE)  # classification estimates pi_hat <- fscores(ziGRM.fit, method = 'classify') head(pi_hat) tail(pi_hat)  # EAP estimates (not useful for zip class) fs <- fscores(ziGRM.fit) head(fs) tail(fs)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute numerical derivatives — numerical_deriv","title":"Compute numerical derivatives — numerical_deriv","text":"Compute numerical derivatives using forward/backward difference, central difference, Richardson extrapolation.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute numerical derivatives — numerical_deriv","text":"","code":"numerical_deriv(   par,   f,   ...,   delta = 1e-05,   gradient = TRUE,   type = \"Richardson\" )"},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute numerical derivatives — numerical_deriv","text":"par vector parameters find partial derivative f objective function evaluated ... additional arguments passed f delta term used perturb f function. Default 1e-5 gradient logical; compute gradient terms? FALSE Hessian computed instead type type difference compute. Can either 'forward' forward difference, 'central' central difference, 'Richardson' Richardson extrapolation (default). Backward difference achieved supplying negative delta value 'forward'. type = 'Richardson', default value delta increased delta * 1000 Hessian delta * 10 gradient provide reasonable perturbation starting location (delta halved iteration).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute numerical derivatives — numerical_deriv","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute numerical derivatives — numerical_deriv","text":"","code":"if (FALSE) { # \\dontrun{ f <- function(x) 3*x[1]^3 - 4*x[2]^2 par <- c(3,8)  # grad = 9 * x^2 , -8 * y (actual <- c(9 * par[1]^2, -8 * par[2])) numerical_deriv(par, f, type = 'forward') numerical_deriv(par, f, type = 'central') numerical_deriv(par, f, type = 'Richardson') # default  # Hessian = h11 -> 18 * x, h22 -> -8, h12 -> h21 -> 0 (actual <- matrix(c(18 * par[1], 0, 0, -8), 2, 2)) numerical_deriv(par, f, type = 'forward', gradient = FALSE) numerical_deriv(par, f, type = 'central', gradient = FALSE) numerical_deriv(par, f, type = 'Richardson', gradient = FALSE) # default  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Person fit statistics — personfit","title":"Person fit statistics — personfit","text":"personfit calculates Zh values Drasgow, Levine Williams (1985) unidimensional multidimensional models, well infit outfit statistics. returned object data.frame consisting either tabulated data full data statistics appended rightmost columns.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Person fit statistics — personfit","text":"","code":"personfit(   x,   method = \"EAP\",   Theta = NULL,   stats.only = TRUE,   return.resids = FALSE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Person fit statistics — personfit","text":"x computed model object class SingleGroupClass MultipleGroupClass method type factor score estimation method. See fscores detail Theta matrix factor scores used statistics require empirical estimates. supplied, arguments typically passed fscores() ignored values used instead stats.logical; return person fit statistics without associated response pattern? return.resids logical; return standardized unstandardized N J matrices person item residuals? TRUE return named list residual type ... additional arguments passed fscores()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Person fit statistics — personfit","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Drasgow, F., Levine, M. V., & Williams, E. . (1985). Appropriateness measurement polychotomous item response models standardized indices. British Journal Mathematical Statistical Psychology, 38, 67-86. Reise, S. P. (1990). comparison item- person-fit methods assessing model-data fit IRT. Applied Psychological Measurement, 14, 127-137. Wright B. D. & Masters, G. N. (1982). Rating scale analysis. MESA Press.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Person fit statistics — personfit","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Person fit statistics — personfit","text":"","code":"if (FALSE) { # \\dontrun{  #make some data set.seed(1) a <- matrix(rlnorm(20),ncol=1) d <- matrix(rnorm(20),ncol=1) items <- rep('2PL', 20) data <- simdata(a,d, 2000, items)  # first observation responds 1 for most difficult, 0 for easiest data[1,] <- ifelse(d > 0, 0, 1)  # second observations answers first half as 1 second half as 0 data[2,] <- rep(1:0, each = 10)  x <- mirt(data, 1) fit <- personfit(x) head(fit)  # raw/standardized residuals resid_list <- personfit(x, return.resids=TRUE) head(resid_list$resid) # unstandardized head(resid_list$std.resid) # standardized (approximate z-scores)  residuals(x, type = 'score')  # with missing data data[3, c(1,3,5,7)] <- NA x.miss <- mirt(data, 1) fit.miss <- personfit(x.miss) head(fit.miss) head(personfit(x.miss, return.resids=TRUE))  #using precomputed Theta Theta <- fscores(x, method = 'MAP', full.scores = TRUE) head(personfit(x, Theta=Theta))  # multiple group Rasch model example set.seed(12345) a <- matrix(rep(1, 16), ncol=1) d <- matrix(rnorm(16,0,.7),ncol=1) itemtype <- rep('dich', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2)  # first observation responds 1 for most difficult, 0 for easiest dat[1,] <- ifelse(d > 0, 0, 1)  group <- c(rep('D1', N), rep('D2', N)) models <- 'F1 = 1-16' mod_Rasch <- multipleGroup(dat, models, itemtype = 'Rasch', group = group) coef(mod_Rasch, simplify=TRUE) pf <- personfit(mod_Rasch, method='MAP') head(pf)    } # }"},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"Plot various test implied response functions models estimated mirt package.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"","code":"# S4 method for class 'MultipleGroupClass,missing' plot(   x,   y,   type = \"score\",   npts = 200,   drop2 = TRUE,   degrees = 45,   which.items = 1:extract.mirt(x, \"nitems\"),   rot = list(xaxis = -70, yaxis = 30, zaxis = 10),   facet_items = TRUE,   theta_lim = c(-6, 6),   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )  # S4 method for class 'SingleGroupClass,missing' plot(   x,   y,   type = \"score\",   npts = 200,   drop2 = TRUE,   degrees = 45,   theta_lim = c(-6, 6),   which.items = 1:extract.mirt(x, \"nitems\"),   MI = 0,   CI = 0.95,   rot = list(xaxis = -70, yaxis = 30, zaxis = 10),   facet_items = TRUE,   main = NULL,   drape = TRUE,   colorkey = TRUE,   ehist.cut = 1e-10,   add.ylab2 = TRUE,   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   profile = FALSE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"x object class SingleGroupClass, MultipleGroupClass, DiscreteClass y arbitrary missing argument required R CMD check type type plot view. Can 'info' test information function 'rxx' reliability function 'infocontour' test information contours 'SE' test standard error function 'infotrace' item information traceline plots 'infoSE' combined test information standard error plot 'trace' item probability traceline plots 'itemscore' item scoring traceline plots 'score' expected total score surface 'scorecontour' expected total score contour plot 'posteriorTheta' posterior latent trait distribution 'EAPsum' compares sum-scores expected values based       EAP sum-scores method (see fscores) Note dentype = 'empiricalhist' used estimation   type 'empiricalhist'   also available generate empirical histogram plot,   dentype = 'Davidian-#' used type 'Davidian'   also available generate curve estimates quadrature   nodes used estimation npts number quadrature points used plotting features. Larger values make plots look smoother drop2 logical; appropriate, dichotomous response items drop lowest category provide information pertaining second response option? degrees numeric value ranging 0 90 used plot compute angle information-based plots respect first dimension. vector used bubble plot created summed information across angles specified (e.g., degrees = seq(0, 90, =10)) .items numeric vector indicating items used plotting. Default use available items rot allows rotation 3D graphics facet_items logical; apply grid plots across items? FALSE, items placed one plot group theta_lim lower upper limits latent trait (theta) evaluated, used conjunction npts par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice ... additional arguments passed lattice MI single number indicating many imputations draw form bootstrapped confidence intervals selected test statistic. greater 0 plot drawn shaded region interval CI number 0 1 indicating confidence interval select MI input used. Default uses 95% confidence (CI = .95) main argument passed lattice. Default generated automatically drape logical argument passed lattice. Default generated automatically colorkey logical argument passed lattice. Default generated automatically ehist.cut probability value indicating threshold excluding cases empirical histogram plots. Values larger default include points tails plot, potentially squishing 'meat' plot take less area visually desired add.ylab2 logical argument passed lattice. Default generated automatically profile logical; provide profile plot response probabilities (objects returned mdirt )","code":""},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"","code":"if (FALSE) { # \\dontrun{ x <- mirt(Science, 1, SE=TRUE) plot(x) plot(x, type = 'info') plot(x, type = 'infotrace') plot(x, type = 'infotrace', facet_items = FALSE) plot(x, type = 'infoSE') plot(x, type = 'rxx') plot(x, type = 'posteriorTheta')  # confidence interval plots when information matrix computed plot(x) plot(x, MI=100) plot(x, type='info', MI=100) plot(x, type='SE', MI=100) plot(x, type='rxx', MI=100)  # use the directlabels package to put labels on tracelines library(directlabels) plt <- plot(x, type = 'trace') direct.label(plt, 'top.points')  # additional modifications can be made via update(). # See ?update.trellis for further documentation plt update(plt, ylab = expression(Prob(theta)),             main = \"Item Traceline Functions\") # ylab/main changed  set.seed(1234) group <- sample(c('g1','g2'), nrow(Science), TRUE) x2 <- multipleGroup(Science, 1, group) plot(x2) plot(x2, type = 'trace') plot(x2, type = 'trace', which.items = 1:2) plot(x2, type = 'itemscore', which.items = 1:2) plot(x2, type = 'trace', which.items = 1, facet_items = FALSE) #facet by group plot(x2, type = 'info')  x3 <- mirt(Science, 2) plot(x3, type = 'info') plot(x3, type = 'SE', theta_lim = c(-3,3))  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":null,"dir":"Reference","previous_headings":"","what":"Change polytomous items to dichotomous item format — poly2dich","title":"Change polytomous items to dichotomous item format — poly2dich","text":"Transforms matrix items new matrix select polytomous items converted comparable dichotomous items information.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change polytomous items to dichotomous item format — poly2dich","text":"","code":"poly2dich(data, which.items = 1:ncol(data), sep = \"_cat.\")"},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change polytomous items to dichotomous item format — poly2dich","text":"data object class data.frame matrix .items vector indicating items transformed dichotomous form. Default uses input items sep character vector pattern append item name data","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change polytomous items to dichotomous item format — poly2dich","text":"Returns integer matrix","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Change polytomous items to dichotomous item format — poly2dich","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Change polytomous items to dichotomous item format — poly2dich","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change polytomous items to dichotomous item format — poly2dich","text":"","code":"if (FALSE) { # \\dontrun{ data(Science)  head(Science) newScience <- poly2dich(Science) head(newScience)  newScience2 <- poly2dich(Science, which.items = 2) head(newScience2)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Print the model objects — print-method","title":"Print the model objects — print-method","text":"Print model object summaries console.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print the model objects — print-method","text":"","code":"# S4 method for class 'SingleGroupClass' print(x)"},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print the model objects — print-method","text":"x object class SingleGroupClass, MultipleGroupClass, MixedClass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print the model objects — print-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print the model objects — print-method","text":"","code":"if (FALSE) { # \\dontrun{ x <- mirt(Science, 1) print(x) } # }"},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print generic for customized data.frame console output — print.mirt_df","title":"Print generic for customized data.frame console output — print.mirt_df","text":"Provides nicer output printed data.frame objects defined functions mirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print generic for customized data.frame console output — print.mirt_df","text":"","code":"# S3 method for class 'mirt_df' print(x, digits = 3, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print generic for customized data.frame console output — print.mirt_df","text":"x object class 'mirt_df' digits number digits round ... additional arguments passed print(...)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Print generic for customized list console output — print.mirt_list","title":"Print generic for customized list console output — print.mirt_list","text":"Provides nicer output printed list objects defined functions mirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print generic for customized list console output — print.mirt_list","text":"","code":"# S3 method for class 'mirt_list' print(x, digits = 3, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print generic for customized list console output — print.mirt_list","text":"x object class 'mirt_list' digits number digits round ... additional arguments passed print(...)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Print generic for customized matrix console output — print.mirt_matrix","title":"Print generic for customized matrix console output — print.mirt_matrix","text":"Provides nicer output printed matrix objects defined functions mirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print generic for customized matrix console output — print.mirt_matrix","text":"","code":"# S3 method for class 'mirt_matrix' print(x, digits = 3, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print generic for customized matrix console output — print.mirt_matrix","text":"x object class 'mirt_matrix' digits number digits round ... additional arguments passed print(...)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate probability trace lines — probtrace","title":"Function to calculate probability trace lines — probtrace","text":"Given internal mirt object extracted estimated model, single-group estimated model , compute probability trace lines categories.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate probability trace lines — probtrace","text":"","code":"probtrace(x, Theta)"},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate probability trace lines — probtrace","text":"x either extracted internal mirt object containing item information (see extract.item) model class SingleGroupClass typically returned function mirt bfactor Theta vector (unidimensional) matrix (unidimensional/multidimensional) latent trait values","code":""},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate probability trace lines — probtrace","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate probability trace lines — probtrace","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate probability trace lines — probtrace","text":"","code":"mod <- mirt(Science, 1) #>  Iteration: 1, Log-Lik: -1629.361, Max-Change: 0.50660 Iteration: 2, Log-Lik: -1617.374, Max-Change: 0.25442 Iteration: 3, Log-Lik: -1612.894, Max-Change: 0.16991 Iteration: 4, Log-Lik: -1610.306, Max-Change: 0.10461 Iteration: 5, Log-Lik: -1609.814, Max-Change: 0.09162 Iteration: 6, Log-Lik: -1609.534, Max-Change: 0.07363 Iteration: 7, Log-Lik: -1609.030, Max-Change: 0.03677 Iteration: 8, Log-Lik: -1608.988, Max-Change: 0.03200 Iteration: 9, Log-Lik: -1608.958, Max-Change: 0.02754 Iteration: 10, Log-Lik: -1608.878, Max-Change: 0.01443 Iteration: 11, Log-Lik: -1608.875, Max-Change: 0.00847 Iteration: 12, Log-Lik: -1608.873, Max-Change: 0.00515 Iteration: 13, Log-Lik: -1608.872, Max-Change: 0.00550 Iteration: 14, Log-Lik: -1608.872, Max-Change: 0.00318 Iteration: 15, Log-Lik: -1608.871, Max-Change: 0.00462 Iteration: 16, Log-Lik: -1608.871, Max-Change: 0.00277 Iteration: 17, Log-Lik: -1608.870, Max-Change: 0.00145 Iteration: 18, Log-Lik: -1608.870, Max-Change: 0.00175 Iteration: 19, Log-Lik: -1608.870, Max-Change: 0.00126 Iteration: 20, Log-Lik: -1608.870, Max-Change: 0.00025 Iteration: 21, Log-Lik: -1608.870, Max-Change: 0.00285 Iteration: 22, Log-Lik: -1608.870, Max-Change: 0.00108 Iteration: 23, Log-Lik: -1608.870, Max-Change: 0.00022 Iteration: 24, Log-Lik: -1608.870, Max-Change: 0.00059 Iteration: 25, Log-Lik: -1608.870, Max-Change: 0.00014 Iteration: 26, Log-Lik: -1608.870, Max-Change: 0.00068 Iteration: 27, Log-Lik: -1608.870, Max-Change: 0.00065 Iteration: 28, Log-Lik: -1608.870, Max-Change: 0.00019 Iteration: 29, Log-Lik: -1608.870, Max-Change: 0.00061 Iteration: 30, Log-Lik: -1608.870, Max-Change: 0.00012 Iteration: 31, Log-Lik: -1608.870, Max-Change: 0.00012 Iteration: 32, Log-Lik: -1608.870, Max-Change: 0.00058 Iteration: 33, Log-Lik: -1608.870, Max-Change: 0.00055 Iteration: 34, Log-Lik: -1608.870, Max-Change: 0.00015 Iteration: 35, Log-Lik: -1608.870, Max-Change: 0.00052 Iteration: 36, Log-Lik: -1608.870, Max-Change: 0.00010  # single item probabilty tracelines for Item 2 extr.2 <- extract.item(mod, 2) Theta <- matrix(seq(-4,4, by = .1)) traceline <- probtrace(extr.2, Theta) head(data.frame(traceline, Theta=Theta)) #>         P.1       P.2        P.3          P.4 Theta #> 1 0.8786646 0.1033965 0.01717048 0.0007684150  -4.0 #> 2 0.8649759 0.1147928 0.01936274 0.0008685506  -3.9 #> 3 0.8500065 0.1271837 0.02182811 0.0009817226  -3.8 #> 4 0.8336966 0.1405950 0.02459876 0.0011096245  -3.7 #> 5 0.8159972 0.1550385 0.02771018 0.0012541689  -3.6 #> 6 0.7968730 0.1705082 0.03120137 0.0014175155  -3.5  # probability tracelines for all items in test tracelines <- probtrace(mod, Theta) head(tracelines) #>      Comfort.P.1 Comfort.P.2 Comfort.P.3 Comfort.P.4  Work.P.1  Work.P.2 #> [1,]   0.3324476   0.4891306   0.1748568 0.003564956 0.8786646 0.1033965 #> [2,]   0.3097452   0.4960477   0.1902523 0.003954823 0.8649759 0.1147928 #> [3,]   0.2879244   0.5010453   0.2066432 0.004387139 0.8500065 0.1271837 #> [4,]   0.2670460   0.5040571   0.2240304 0.004866481 0.8336966 0.1405950 #> [5,]   0.2471562   0.5050429   0.2424030 0.005397913 0.8159972 0.1550385 #> [6,]   0.2282864   0.5039894   0.2617372 0.005987029 0.7968730 0.1705082 #>        Work.P.3     Work.P.4 Future.P.1 Future.P.2   Future.P.3   Future.P.4 #> [1,] 0.01717048 0.0007684150  0.9809133 0.01813820 0.0009339072 1.456036e-05 #> [2,] 0.01936274 0.0008685506  0.9761110 0.02269637 0.0011743453 1.831346e-05 #> [3,] 0.02182811 0.0009817226  0.9701371 0.02836330 0.0014765907 2.303394e-05 #> [4,] 0.02459876 0.0011096245  0.9627263 0.03538820 0.0018564770 2.897114e-05 #> [5,] 0.02771018 0.0012541689  0.9535646 0.04406509 0.0023338620 3.643864e-05 #> [6,] 0.03120137 0.0014175155  0.9422860 0.05473458 0.0029336324 4.583085e-05 #>      Benefit.P.1 Benefit.P.2 Benefit.P.3 Benefit.P.4 #> [1,]   0.7372533   0.2300751  0.03036097 0.002310633 #> [2,]   0.7155002   0.2481850  0.03373746 0.002577309 #> [3,]   0.6926969   0.2669559  0.03747256 0.002874673 #> [4,]   0.6689116   0.2862818  0.04160042 0.003206237 #> [5,]   0.6442308   0.3060358  0.04615750 0.003575906 #> [6,]   0.6187588   0.3260706  0.05118258 0.003988026"},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute posterior estimates of random effect — randef","title":"Compute posterior estimates of random effect — randef","text":"Stochastically compute random effects MixedClass objects Metropolis-Hastings samplers averaging draws obtain expected posteriori predictions. Returns list estimated effects.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute posterior estimates of random effect — randef","text":"","code":"randef(x, ndraws = 1000, thin = 10, return.draws = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute posterior estimates of random effect — randef","text":"x estimated model object mixedmirt function ndraws total number draws perform. Default 1000 thin amount thinning apply. Default use every 10th draw return.draws logical; return list containing thinned draws posterior?","code":""},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute posterior estimates of random effect — randef","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models MH-RM Algorithm. Journal Educational Measurement, 52, 200-222. doi:10.1111/jedm.12072  doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute posterior estimates of random effect — randef","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute posterior estimates of random effect — randef","text":"","code":"if (FALSE) { # \\dontrun{ # make an arbitrary groups covdat <- data.frame(group = rep(paste0('group', 1:49), each=nrow(Science)/49))  # partial credit model mod <- mixedmirt(Science, covdat, model=1, random = ~ 1|group) summary(mod)  effects <- randef(mod, ndraws = 2000, thin = 20) head(effects$Theta) head(effects$group)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Translate mirt parameters into suitable structure for plink package — read.mirt","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"function exports item parameters mirt package plink package.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"","code":"read.mirt(x, as.irt.pars = TRUE, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"x single object (list objects) returned mirt, bfactor, single object returned multipleGroup .irt.pars TRUE, parameters output irt.pars object ... additional arguments passed coef()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"","code":"if (FALSE) { # \\dontrun{  ## unidimensional library(plink)  data <- expand.table(LSAT7) (mod1 <- mirt(data, 1)) plinkpars <- read.mirt(mod1) plot(plinkpars) plot(mod1, type = 'trace')  # graded mod2 <- mirt(Science, 1) plinkpars <- read.mirt(mod2) plot(plinkpars) plot(mod2, type = 'trace')  # gpcm mod3 <- mirt(Science, 1, itemtype = 'gpcm') plinkpars <- read.mirt(mod3) plot(plinkpars) plot(mod3, type = 'trace')  # nominal mod4 <- mirt(Science, 1, itemtype = 'nominal') plinkpars <- read.mirt(mod4) plot(plinkpars) plot(mod4, type = 'trace')  ## multidimensional  data <- expand.table(LSAT7) (mod1 <- mirt(data, 2)) plinkpars <- read.mirt(mod1) plinkpars plot(plinkpars) plot(mod1, type = 'trace')  cmod <- mirt.model('    F1 = 1,4,5    F2 = 2-4') model <- mirt(data, cmod) plot(read.mirt(model)) itemplot(model, 1)  # graded mod2 <- mirt(Science, 2) plinkpars <- read.mirt(mod2) plinkpars plot(plinkpars) plot(mod2, type = 'trace')  ### multiple group equating example set.seed(1234) dat <- expand.table(LSAT7) group <- sample(c('g1', 'g2'), nrow(dat), TRUE) dat1 <- dat[group == 'g1', ] dat2 <- dat[group == 'g2', ] mod1 <- mirt(dat1, 1) mod2 <- mirt(dat2, 1)  # convert and combine pars plinkMG <- read.mirt(list(g1=mod1, g2=mod2))  # equivalently: # mod <- multipleGroup(dat, 1, group) # plinkMG <- read.mirt(mod)  combine <- matrix(1:5, 5, 2) comb <- combine.pars(plinkMG, combine, grp.names=unique(group)) out <- plink(comb, rescale=\"SL\") equate(out) equate(out, method = 'OSE')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Remap item categories to have integer distances of 1 — remap.distance","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"mirt package's estimation setup requires item responses spaces equal 1 (e.g., Likert scale scored 1 5). event categories missing categories must re-coded. function automatically called package estimation functions (e.g., mirt), however convince function extracted users better understand remapping consequences.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"","code":"remap.distance(data, message = TRUE)"},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"data response data remap data.frame matrix message logical; print message information pertaining items remapped?","code":""},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"","code":"# category 2 for item 1 missing dat <- Science dat[,1] <- ifelse(Science[,1] == 2, 1, Science[,1]) apply(dat, 2, table) #> $Comfort #>  #>   1   3   4  #>  37 266  89  #>  #> $Work #>  #>   1   2   3   4  #>  33  98 206  55  #>  #> $Future #>  #>   1   2   3   4  #>  14  72 210  96  #>  #> $Benefit #>  #>   1   2   3   4  #>  21 100 193  78  #>   # mirt() automatically remaps categories mod <- mirt(dat, 1) #> \"Comfort\" re-mapped to ensure all categories have a distance of 1 #>  Iteration: 1, Log-Lik: -1614.807, Max-Change: 0.40351 Iteration: 2, Log-Lik: -1603.657, Max-Change: 0.23414 Iteration: 3, Log-Lik: -1599.256, Max-Change: 0.19589 Iteration: 4, Log-Lik: -1596.125, Max-Change: 0.06372 Iteration: 5, Log-Lik: -1595.799, Max-Change: 0.06841 Iteration: 6, Log-Lik: -1595.611, Max-Change: 0.06323 Iteration: 7, Log-Lik: -1595.135, Max-Change: 0.02986 Iteration: 8, Log-Lik: -1595.122, Max-Change: 0.01730 Iteration: 9, Log-Lik: -1595.116, Max-Change: 0.01053 Iteration: 10, Log-Lik: -1595.112, Max-Change: 0.02062 Iteration: 11, Log-Lik: -1595.109, Max-Change: 0.00770 Iteration: 12, Log-Lik: -1595.107, Max-Change: 0.00676 Iteration: 13, Log-Lik: -1595.103, Max-Change: 0.00260 Iteration: 14, Log-Lik: -1595.103, Max-Change: 0.00029 Iteration: 15, Log-Lik: -1595.103, Max-Change: 0.00494 Iteration: 16, Log-Lik: -1595.102, Max-Change: 0.00098 Iteration: 17, Log-Lik: -1595.102, Max-Change: 0.00033 Iteration: 18, Log-Lik: -1595.102, Max-Change: 0.00109 Iteration: 19, Log-Lik: -1595.102, Max-Change: 0.00020 Iteration: 20, Log-Lik: -1595.102, Max-Change: 0.00359 Iteration: 21, Log-Lik: -1595.102, Max-Change: 0.00022 Iteration: 22, Log-Lik: -1595.102, Max-Change: 0.00022 Iteration: 23, Log-Lik: -1595.102, Max-Change: 0.00075 Iteration: 24, Log-Lik: -1595.102, Max-Change: 0.00065 Iteration: 25, Log-Lik: -1595.102, Max-Change: 0.00023 Iteration: 26, Log-Lik: -1595.102, Max-Change: 0.00067 Iteration: 27, Log-Lik: -1595.102, Max-Change: 0.00013 Iteration: 28, Log-Lik: -1595.102, Max-Change: 0.00013 Iteration: 29, Log-Lik: -1595.102, Max-Change: 0.00060 Iteration: 30, Log-Lik: -1595.102, Max-Change: 0.00014 Iteration: 31, Log-Lik: -1595.102, Max-Change: 0.00063 Iteration: 32, Log-Lik: -1595.102, Max-Change: 0.00013 Iteration: 33, Log-Lik: -1595.102, Max-Change: 0.00055 Iteration: 34, Log-Lik: -1595.102, Max-Change: 0.00019 Iteration: 35, Log-Lik: -1595.102, Max-Change: 0.00055 Iteration: 36, Log-Lik: -1595.102, Max-Change: 0.00011 Iteration: 37, Log-Lik: -1595.102, Max-Change: 0.00011 Iteration: 38, Log-Lik: -1595.102, Max-Change: 0.00049 Iteration: 39, Log-Lik: -1595.102, Max-Change: 0.00012 Iteration: 40, Log-Lik: -1595.102, Max-Change: 0.00011 Iteration: 41, Log-Lik: -1595.102, Max-Change: 0.00043 Iteration: 42, Log-Lik: -1595.102, Max-Change: 0.00045 Iteration: 43, Log-Lik: -1595.102, Max-Change: 0.00015 Iteration: 44, Log-Lik: -1595.102, Max-Change: 0.00043 Iteration: 45, Log-Lik: -1595.102, Max-Change: 0.00009 coef(mod, simplify=TRUE) #> $items #>            a1    d1     d2     d3 #> Comfort 0.995 2.626 -1.447     NA #> Work    1.231 2.928  0.903 -2.271 #> Future  2.338 5.293  2.245 -1.989 #> Benefit 1.079 3.333  0.988 -1.681 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   # this is the transformed data used by mirt() remap_dat <- remap.distance(dat) #> \"Comfort\" re-mapped to ensure all categories have a distance of 1 apply(remap_dat, 2, table) #> $Comfort #>  #>   1   2   3  #>  37 266  89  #>  #> $Work #>  #>   1   2   3   4  #>  33  98 206  55  #>  #> $Future #>  #>   1   2   3   4  #>  14  72 210  96  #>  #> $Benefit #>  #>   1   2   3   4  #>  21 100 193  78  #>"},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute model residuals — residuals-method","title":"Compute model residuals — residuals-method","text":"Return model implied residuals linear dependencies items person level. latent trait density approximated (e.g., Davidian curves, Empirical histograms, etc) passing use_dentype_estimate = TRUE use internally saved quadrature density components (applicable).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute model residuals — residuals-method","text":"","code":"# S4 method for class 'SingleGroupClass' residuals(   object,   type = \"LD\",   p.adjust = \"none\",   df.p = FALSE,   approx.z = FALSE,   full.scores = FALSE,   QMC = FALSE,   printvalue = NULL,   tables = FALSE,   verbose = TRUE,   Theta = NULL,   suppress = NA,   theta_lim = c(-6, 6),   quadpts = NULL,   fold = TRUE,   upper = TRUE,   technical = list(),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute model residuals — residuals-method","text":"object object class SingleGroupClass MultipleGroupClass. Bifactor models automatically detected utilized better accuracy type type residuals displayed. Can either 'LD' 'LDG2' local dependence matrix based X2 G2 statistics (Chen & Thissen, 1997), 'Q3' statistic proposed Yen (1984), 'JSI' jack-knife statistic proposed Edwards et al. (2018), 'exp' expected values frequencies every response pattern, 'expfull' expected values every theoretically observable response pattern. 'LD' 'LDG2' types, upper diagonal elements represent standardized residuals form signed Cramers V coefficients p.adjust method use adjusting p-values (see p.adjust available options). Default 'none' df.p logical; print degrees freedom p-values? approx.z logical; transform \\(\\chi^2(df)\\) information LD tests approximate z-ratios instead using transformation \\(z=\\sqrt{2 * \\chi^2} - \\sqrt{2 * df - 1}\\)? full.scores logical; compute relevant statistics subject original data? QMC logical; use quasi-Monte Carlo integration? quadpts omitted default number nodes 5000 printvalue numeric value specified using res='exp' option. prints patterns standardized residuals greater abs(printvalue). default (NULL) prints response patterns tables logical; LD type, return observed, expected, standardized residual tables item combination? verbose logical; allow information printed console? Theta matrix factor scores used statistics require empirical estimates (.e., Q3). supplied, arguments typically passed fscores() ignored values used instead suppress numeric value indicating parameter local dependency combinations flag high (LD, LDG2, Q3 standardize correlations used; JSI, z-ratios used). Absolute values standardized estimates greater value returned, values less value set missing theta_lim range integration grid quadpts number quadrature nodes use. default extracted model (available) generated automatically available fold logical; apply sum 'folding' described Edwards et al. (2018) JSI statistic? upper logical; portion matrix (upper versus lower triangle) suppress argument applied ? technical list technical arguments models re-estimated (see mirt details) ... additional arguments passed fscores()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute model residuals — residuals-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chen, W. H. & Thissen, D. (1997). Local dependence indices item pairs using item response theory. Journal Educational Behavioral Statistics, 22, 265-289. Edwards, M. C., Houts, C. R. & Cai, L. (2018). Diagnostic Procedure Detect Departures Local Independence Item Response Theory Models. Psychological Methods, 23, 138-149. Yen, W. (1984). Effects local item dependence fit equating performance three parameter logistic model. Applied Psychological Measurement, 8, 125-145.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute model residuals — residuals-method","text":"","code":"if (FALSE) { # \\dontrun{  x <- mirt(Science, 1) residuals(x) residuals(x, tables = TRUE) residuals(x, type = 'exp') residuals(x, suppress = .15) residuals(x, df.p = TRUE) residuals(x, df.p = TRUE, p.adjust = 'fdr') # apply FWE control  # Pearson's X2 estimate for goodness-of-fit full_table <- residuals(x, type = 'expfull') head(full_table) X2 <- with(full_table, sum((freq - exp)^2 / exp)) df <- nrow(full_table) - extract.mirt(x, 'nest') - 1 p <- pchisq(X2, df = df, lower.tail=FALSE) data.frame(X2, df, p, row.names='Pearson-X2')  # above FOG test as a function PearsonX2 <- function(x){    full_table <- residuals(x, type = 'expfull')    X2 <- with(full_table, sum((freq - exp)^2 / exp))    df <- nrow(full_table) - extract.mirt(x, 'nest') - 1    p <- pchisq(X2, df = df, lower.tail=FALSE)    data.frame(X2, df, p, row.names='Pearson-X2') } PearsonX2(x)   # extract results manually out <- residuals(x, df.p = TRUE, verbose=FALSE) str(out) out$df.p[1,2]  # with and without supplied factor scores Theta <- fscores(x) residuals(x, type = 'Q3', Theta=Theta) residuals(x, type = 'Q3', method = 'ML')  # Edwards et al. (2018) JSI statistic N <- 250 a <- rnorm(10, 1.7, 0.3) d <- rnorm(10) dat <- simdata(a, d, N=250, itemtype = '2PL')  mod <- mirt(dat, 1) residuals(mod, type = 'JSI') residuals(mod, type = 'JSI', fold=FALSE) # unfolded  # LD between items 1-2 aLD <- numeric(10) aLD[1:2] <- rnorm(2, 2.55, 0.15) a2 <- cbind(a, aLD) dat <- simdata(a2, d, N=250, itemtype = '2PL')  mod <- mirt(dat, 1)  # JSI executed in parallel over multiple cores if(interactive()) mirtCluster() residuals(mod, type = 'JSI')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":null,"dir":"Reference","previous_headings":"","what":"Reverse score one or more items from a response matrix — reverse.score","title":"Reverse score one or more items from a response matrix — reverse.score","text":"Reverse score specific items given empirical range specific scoring range.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reverse score one or more items from a response matrix — reverse.score","text":"","code":"reverse.score(data, which, range = NULL, append = \".RS\")"},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reverse score one or more items from a response matrix — reverse.score","text":"data object class data.frame, matrix, table response patterns names items data rescored. missing columns data reverse scored range (optional) named list specify low high score ranges. Specified names must match names found data, element list contain two values. items specified omitted list empirical min/max information used instead append character vector indicating append item names rescored","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reverse score one or more items from a response matrix — reverse.score","text":"returns original data object specified   items reverse scored replacing original scoring scheme","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reverse score one or more items from a response matrix — reverse.score","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Reverse score one or more items from a response matrix — reverse.score","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reverse score one or more items from a response matrix — reverse.score","text":"","code":"a <- rlnorm(20) a[c(1,5,10)] <- -a[c(1,5,10)] diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d <- diffs + rnorm(20) dat <- simdata(a,d,itemtype='graded', N=300) head(dat) #>      Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> [1,]      4      1      0      2      2      3      3      0      0       4 #> [2,]      0      4      4      1      2      4      4      4      4       0 #> [3,]      3      0      0      1      2      4      0      0      4       4 #> [4,]      3      2      4      1      3      0      0      0      3       4 #> [5,]      0      4      3      0      0      4      4      4      1       0 #> [6,]      4      4      0      2      1      4      4      0      0       4 #>      Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 Item_19 #> [1,]       3       0       2       2       0       4       0       1       0 #> [2,]       0       4       3       3       3       4       4       4       4 #> [3,]       4       0       1       2       2       4       0       3       0 #> [4,]       3       0       0       0       0       4       0       4       0 #> [5,]       4       4       4       4       4       1       4       4       4 #> [6,]       4       0       0       4       3       4       0       0       3 #>      Item_20 #> [1,]       3 #> [2,]       1 #> [3,]       4 #> [4,]       4 #> [5,]       4 #> [6,]       1  if (FALSE) { # \\dontrun{ # fitted model has negative slopes due to flipped scoring mod <- mirt(dat) coef(mod, simplify=TRUE)$items plot(mod, type = 'itemscore') } # }  # reverse the scoring for items 1, 5, and 10 only using empirical min/max revdat <- reverse.score(dat, c('Item_1', 'Item_5', 'Item_10')) head(revdat) #>      Item_1.RS Item_2 Item_3 Item_4 Item_5.RS Item_6 Item_7 Item_8 Item_9 #> [1,]         0      1      0      2         2      3      3      0      0 #> [2,]         4      4      4      1         2      4      4      4      4 #> [3,]         1      0      0      1         2      4      0      0      4 #> [4,]         1      2      4      1         1      0      0      0      3 #> [5,]         4      4      3      0         4      4      4      4      1 #> [6,]         0      4      0      2         3      4      4      0      0 #>      Item_10.RS Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 #> [1,]          0       3       0       2       2       0       4       0       1 #> [2,]          4       0       4       3       3       3       4       4       4 #> [3,]          0       4       0       1       2       2       4       0       3 #> [4,]          0       3       0       0       0       0       4       0       4 #> [5,]          4       4       4       4       4       4       1       4       4 #> [6,]          0       4       0       0       4       3       4       0       0 #>      Item_19 Item_20 #> [1,]       0       3 #> [2,]       4       1 #> [3,]       0       4 #> [4,]       0       4 #> [5,]       4       4 #> [6,]       3       1  # compare apply(dat[,c(1,5,10)], 2, table) #>   Item_1 Item_5 Item_10 #> 0    106     68      82 #> 1     18     54      23 #> 2     18     69      27 #> 3     24     32      33 #> 4    134     77     135 apply(revdat[,c(1,5,10)], 2, table) #>   Item_1.RS Item_5.RS Item_10.RS #> 0       134        77        135 #> 1        24        32         33 #> 2        18        69         27 #> 3        18        54         23 #> 4       106        68         82  if (FALSE) { # \\dontrun{ # slopes all positive now mod2 <- mirt(revdat) coef(mod2, simplify=TRUE)$items plot(mod2, type = 'itemscore') } # }  # use different empirical scoring information due to options not used   # 0 score not observed for item 1, though should have been rescored to a 4 dat[dat[,1] == 0, 1] <- 1 table(dat[,1]) #>  #>   1   2   3   4  #> 124  18  24 134   # 4 score not observed for item 5, though should have been rescored to a 0 dat[dat[,5] == 4, 5] <- 3 table(dat[,5]) #>  #>   0   1   2   3  #>  68  54  69 109   # specify theoretical scoring values in the range list revdat2 <- reverse.score(dat, c('Item_1', 'Item_5', 'Item_10'),                               range = list(Item_1 = c(0,4), Item_5 = c(0,4))) head(revdat2) #>      Item_1.RS Item_2 Item_3 Item_4 Item_5.RS Item_6 Item_7 Item_8 Item_9 #> [1,]         0      1      0      2         2      3      3      0      0 #> [2,]         3      4      4      1         2      4      4      4      4 #> [3,]         1      0      0      1         2      4      0      0      4 #> [4,]         1      2      4      1         1      0      0      0      3 #> [5,]         3      4      3      0         4      4      4      4      1 #> [6,]         0      4      0      2         3      4      4      0      0 #>      Item_10.RS Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 #> [1,]          0       3       0       2       2       0       4       0       1 #> [2,]          4       0       4       3       3       3       4       4       4 #> [3,]          0       4       0       1       2       2       4       0       3 #> [4,]          0       3       0       0       0       0       4       0       4 #> [5,]          4       4       4       4       4       4       1       4       4 #> [6,]          0       4       0       0       4       3       4       0       0 #>      Item_19 Item_20 #> [1,]       0       3 #> [2,]       4       1 #> [3,]       0       4 #> [4,]       0       4 #> [5,]       4       4 #> [6,]       3       1 table(dat[,1]) #>  #>   1   2   3   4  #> 124  18  24 134  table(revdat2[,1]) #>  #>   0   1   2   3  #> 134  24  18 124   table(dat[,5]) #>  #>   0   1   2   3  #>  68  54  69 109  table(revdat2[,5]) #>  #>   1   2   3   4  #> 109  69  54  68"},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Second-order test of convergence — secondOrderTest","title":"Second-order test of convergence — secondOrderTest","text":"Test whether terminated estimation criteria given model passes second order test checking positive definiteness resulting Hessian matrix. function, accepts symmetric Hessian/information matrix input, returns TRUE matrix positive definite FALSE otherwise.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Second-order test of convergence — secondOrderTest","text":"","code":"secondOrderTest(mat, ..., method = \"eigen\")"},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Second-order test of convergence — secondOrderTest","text":"mat symmetric matrix test positive definiteness (typically Hessian highest point model estimator, MLE MAP) ... arguments passed either eigen, chol, 'det' positiveness eigen values, positiveness leading minors via Cholesky decomposition, evaluation whether determinant greater 0 method method use test positive definiteness. Default 'eigen'","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Second-order test of convergence — secondOrderTest","text":"matrix possible combinations","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Second-order test of convergence — secondOrderTest","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Second-order test of convergence — secondOrderTest","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Second-order test of convergence — secondOrderTest","text":"","code":"if (FALSE) { # \\dontrun{  # PD matrix mod <- mirt(Science, 1, SE=TRUE) info <- solve(vcov(mod))   ## observed information secondOrderTest(info) secondOrderTest(info, method = 'chol') secondOrderTest(info, method = 'det')  # non-PD matrix mat <- matrix(c(1,0,0,0,1,1,0,1,1), ncol=3) mat secondOrderTest(mat) secondOrderTest(mat, method = 'chol') secondOrderTest(mat, method = 'det')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Show model object — show-method","title":"Show model object — show-method","text":"Print model object summaries console.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show model object — show-method","text":"","code":"# S4 method for class 'SingleGroupClass' show(object)"},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show model object — show-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Show model object — show-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show model object — show-method","text":"","code":"if (FALSE) { # \\dontrun{ x <- mirt(Science, 1) show(x) } # }"},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate response patterns — simdata","title":"Simulate response patterns — simdata","text":"Simulates response patterns compensatory noncompensatory MIRT models multivariate normally distributed factor (\\(\\theta\\)) scores, user input matrix \\(\\theta\\)'s.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate response patterns — simdata","text":"","code":"simdata(   a,   d,   N,   itemtype,   sigma = NULL,   mu = NULL,   guess = 0,   upper = 1,   nominal = NULL,   t = NULL,   Theta = NULL,   gpcm_mats = list(),   returnList = FALSE,   model = NULL,   equal.K = TRUE,   which.items = NULL,   mins = 0,   lca_cats = NULL,   prob.list = NULL )"},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate response patterns — simdata","text":"matrix/vector slope parameters. slopes constrained zero use NA simply set equal 0 d matrix/vector intercepts. matrix many columns item largest number categories, filled empty locations NA. vector used test assumed consist dichotomous items (one intercept per item provided). itemtype = 'lca' intercepts used N sample size itemtype character vector length nrow() (1, item types   ) specifying type items simulate. Inputs can either   inputs found itemtype argument mirt   internal classes defined package. Typical itemtype inputs   passed mirt used converted   respective internal classes automatically. internal class object specified instead, inputs can   'dich', 'graded', 'gpcm', 'sequential', 'nominal', 'nestlogit', 'partcomp', 'gumm',   'lca', dichotomous, graded, generalized partial credit, sequential,   nominal, nested logit, partially compensatory,   generalized graded unfolding model, latent class analysis model.   Note gpcm, nominal, nested logit models   many parameters desired categories, however parametrized meaningful   interpretation first category intercept   equal 0 models (second column 'nestlogit', since first column   correct item traceline). nested logit models 'correct' category always lowest   category (.e., == 1). may helpful use mod2values data-sets   already estimated understand itemtypes intimately sigma covariance matrix underlying distribution. Default identity matrix. Used Theta supplied mu mean vector underlying distribution. Default vector zeros. Used Theta supplied guess vector guessing parameters item; applicable dichotomous items. Must either scalar value affect dichotomous items, vector many values simulated items upper guess, upper bound parameters nominal matrix specific item category slopes nominal models. dimensions intercept specification one less column, NA locations applicable. Note estimation first slope constrained 0 last constrained number categories minus 1, best set values first last categories well t matrix t-values 'ggum' itemtype, row corresponds given item. Also determines number categories, NA can used non-applicable categories Theta user specified matrix underlying ability parameters, nrow(Theta) == N ncol(Theta) == ncol(). supplied N input required gpcm_mats list matrices specifying scoring scheme generalized partial credit models (see mirt details) returnList logical; return list containing data, item objects defined mirt containing population parameters item structure, latent trait matrix Theta? Default FALSE model single group object, typically returned functions mirt bfactor. Supplying render parameter elements (excluding Theta, N, mu, sigma inputs) redundant (unless explicitly provided). input can therefore used create parametric bootstrap data whereby plausible data implied estimated model can generated evaluated equal.K logical; model input supplied, generated data contain number categories original data indicated extract.mirt(model, 'K')? Default TRUE, redrawn data condition satisfied .items integer vector used indicate items simulate model input included. Default simulates items mins integer vector (single value used item) indicating lowest category . model supplied extracted slot(mod, 'Data')$mins, otherwise default 0 lca_cats vector indicating many categories lca item . supplied assumed 2 categories generated item prob.list optional list containing matrix/data.frames probabilities values category simulated. useful creating customized probability functions sampled ","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate response patterns — simdata","text":"Returns data matrix simulated parameters, list containing data, item objects, Theta matrix.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate response patterns — simdata","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Reckase, M. D. (2009). Multidimensional Item Response Theory. New York: Springer.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate response patterns — simdata","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate response patterns — simdata","text":"","code":"### Parameters from Reckase (2009), p. 153  set.seed(1234)  a <- matrix(c(  .7471, .0250, .1428,  .4595, .0097, .0692,  .8613, .0067, .4040, 1.0141, .0080, .0470,  .5521, .0204, .1482, 1.3547, .0064, .5362, 1.3761, .0861, .4676,  .8525, .0383, .2574, 1.0113, .0055, .2024,  .9212, .0119, .3044,  .0026, .0119, .8036,  .0008, .1905,1.1945,  .0575, .0853, .7077,  .0182, .3307,2.1414,  .0256, .0478, .8551,  .0246, .1496, .9348,  .0262, .2872,1.3561,  .0038, .2229, .8993,  .0039, .4720, .7318,  .0068, .0949, .6416,  .3073, .9704, .0031,  .1819, .4980, .0020,  .4115,1.1136, .2008,  .1536,1.7251, .0345,  .1530, .6688, .0020,  .2890,1.2419, .0220,  .1341,1.4882, .0050,  .0524, .4754, .0012,  .2139, .4612, .0063,  .1761,1.1200, .0870),30,3,byrow=TRUE)*1.702  d <- matrix(c(.1826,-.1924,-.4656,-.4336,-.4428,-.5845,-1.0403,   .6431,.0122,.0912,.8082,-.1867,.4533,-1.8398,.4139,   -.3004,-.1824,.5125,1.1342,.0230,.6172,-.1955,-.3668,   -1.7590,-.2434,.4925,-.3410,.2896,.006,.0329),ncol=1)*1.702  mu <- c(-.4, -.7, .1) sigma <- matrix(c(1.21,.297,1.232,.297,.81,.252,1.232,.252,1.96),3,3)  dataset1 <- simdata(a, d, 2000, itemtype = '2PL') dataset2 <- simdata(a, d, 2000, itemtype = '2PL', mu = mu, sigma = sigma)  #mod <- mirt(dataset1, 3, method = 'MHRM') #coef(mod)  if (FALSE) { # \\dontrun{  ### Unidimensional graded response model with 5 categories each  a <- matrix(rlnorm(20,.2,.3))  # for the graded model, ensure that there is enough space between the intercepts, # otherwise closer categories will not be selected often (minimum distance of 0.3 here) diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d <- diffs + rnorm(20)  dat <- simdata(a, d, 500, itemtype = 'graded') # mod <- mirt(dat, 1)  ### An example of a mixed item, bifactor loadings pattern with correlated specific factors  a <- matrix(c( .8,.4,NA, .4,.4,NA, .7,.4,NA, .8,NA,.4, .4,NA,.4, .7,NA,.4),ncol=3,byrow=TRUE)  d <- matrix(c( -1.0,NA,NA,  1.5,NA,NA,  0.0,NA,NA, 0.0,-1.0,1.5,  #the first 0 here is the recommended constraint for nominal 0.0,1.0,-1, #the first 0 here is the recommended constraint for gpcm 2.0,0.0,NA),ncol=3,byrow=TRUE)  nominal <- matrix(NA, nrow(d), ncol(d)) # the first 0 and last (ncat - 1) = 2 values are the recommended constraints nominal[4, ] <- c(0,1.2,2)  sigma <- diag(3) sigma[2,3] <- sigma[3,2] <- .25 items <- c('2PL','2PL','2PL','nominal','gpcm','graded')  dataset <- simdata(a,d,2000,items,sigma=sigma,nominal=nominal)  #mod <- bfactor(dataset, c(1,1,1,2,2,2), itemtype=c(rep('2PL', 3), 'nominal', 'gpcm','graded')) #coef(mod)  #### Convert standardized factor loadings to slopes  F2a <- function(F, D=1.702){     h2 <- rowSums(F^2)     a <- (F / sqrt(1 - h2)) * D     a }  (F <- matrix(c(rep(.7, 5), rep(.5,5)))) (a <- F2a(F)) d <- rnorm(10)  dat <- simdata(a, d, 5000, itemtype = '2PL') mod <- mirt(dat, 1) coef(mod, simplify=TRUE)$items summary(mod)  mod2 <- mirt(dat, 'F1 = 1-10                    CONSTRAIN = (1-5, a1), (6-10, a1)') summary(mod2) anova(mod2, mod)  #### Convert classical 3PL paramerization into slope-intercept form nitems <- 50 as <- rlnorm(nitems, .2, .2) bs <- rnorm(nitems, 0, 1) gs <- rbeta(nitems, 5, 17)  # convert first item (only intercepts differ in resulting transformation) traditional2mirt(c('a'=as[1], 'b'=bs[1], 'g'=gs[1], 'u'=1), cls='3PL')  # convert all difficulties to intercepts ds <- numeric(nitems) for(i in 1:nitems)    ds[i] <- traditional2mirt(c('a'=as[i], 'b'=bs[i], 'g'=gs[i], 'u'=1),                              cls='3PL')[2]  dat <- simdata(as, ds, N=5000, guess=gs, itemtype = '3PL')  # estimate with beta prior for guessing parameters # mod <- mirt(dat, model=\"Theta = 1-50 #                         PRIOR = (1-50, g, expbeta, 5, 17)\", itemtype = '3PL') # coef(mod, simplify=TRUE, IRTpars=TRUE)$items # data.frame(as, bs, gs, us=1)   #### Unidimensional nonlinear factor pattern  theta <- rnorm(2000) Theta <- cbind(theta,theta^2)  a <- matrix(c( .8,.4, .4,.4, .7,.4, .8,NA, .4,NA, .7,NA),ncol=2,byrow=TRUE) d <- matrix(rnorm(6)) itemtype <- rep('2PL',6)  nonlindata <- simdata(a=a, d=d, itemtype=itemtype, Theta=Theta)  #model <- ' #F1 = 1-6 #(F1 * F1) = 1-3' #mod <- mirt(nonlindata, model) #coef(mod)  #### 2PLNRM model for item 4 (with 4 categories), 2PL otherwise  a <- matrix(rlnorm(4,0,.2))  # first column of item 4 is the intercept for the correct category of 2PL model, #    otherwise nominal model configuration d <- matrix(c( -1.0,NA,NA,NA,  1.5,NA,NA,NA,  0.0,NA,NA,NA,  1, 0.0,-0.5,0.5),ncol=4,byrow=TRUE)  nominal <- matrix(NA, nrow(d), ncol(d)) nominal[4, ] <- c(NA,0,.5,.6)  items <- c(rep('2PL',3),'nestlogit')  dataset <- simdata(a,d,2000,items,nominal=nominal)  #mod <- mirt(dataset, 1, itemtype = c('2PL', '2PL', '2PL', '2PLNRM'), key=c(NA,NA,NA,0)) #coef(mod) #itemplot(mod,4)  # return list of simulation parameters listobj <- simdata(a,d,2000,items,nominal=nominal, returnList=TRUE) str(listobj)  # generate dataset from converged model mod <- mirt(Science, 1, itemtype = c(rep('gpcm', 3), 'nominal')) sim <- simdata(model=mod, N=1000) head(sim)  Theta <- matrix(rnorm(100)) sim <- simdata(model=mod, Theta=Theta) head(sim)  # alternatively, define a suitable object with functions from the mirtCAT package # help(generate.mirt_object) library(mirtCAT)  nitems <- 50 a1 <- rlnorm(nitems, .2,.2) d <- rnorm(nitems) g <- rbeta(nitems, 20, 80) pars <- data.frame(a1=a1, d=d, g=g) head(pars)  obj <- generate.mirt_object(pars, '3PL') dat <- simdata(N=200, model=obj)  #### 10 item GGUMs test with 4 categories each a <- rlnorm(10, .2, .2) b <- rnorm(10) #passed to d= input, but used as the b parameters diffs <- t(apply(matrix(runif(10*3, .3, 1), 10), 1, cumsum)) t <- -(diffs - rowMeans(diffs))  dat <- simdata(a, b, 1000, 'ggum', t=t) apply(dat, 2, table) # mod <- mirt(dat, 1, 'ggum') # coef(mod)  ###### # prob.list example  # custom probability function that returns a matrix fun <- function(a, b, theta){     P <- 1 / (1 + exp(-a * (theta-b)))     cbind(1-P, P) }  set.seed(1) theta <- matrix(rnorm(100)) prob.list <- list() nitems <- 5 a <- rlnorm(nitems, .2, .2); b <- rnorm(nitems, 0, 1/2) for(i in 1:nitems) prob.list[[i]] <- fun(a[i], b[i], theta) str(prob.list)  dat <- simdata(prob.list=prob.list) head(dat)  # prob.list input is useful when defining custom items as well name <- 'old2PL' par <- c(a = .5, b = -2) est <- c(TRUE, TRUE) P.old2PL <- function(par,Theta, ncat){      a <- par[1]      b <- par[2]      P1 <- 1 / (1 + exp(-1*a*(Theta - b)))      cbind(1-P1, P1) }  x <- createItem(name, par=par, est=est, P=P.old2PL)  prob.list[[1]] <- x@P(x@par, theta)   } # }"},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of model object — summary-method","title":"Summary of model object — summary-method","text":"Transforms coefficients standardized factor loading's metric. MixedClass objects, fixed random coefficients printed. Note output console rounded three digits, returned list objects . simulations, use output <- summary(mod, verbose = FALSE) suppress console messages.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of model object — summary-method","text":"","code":"# S4 method for class 'SingleGroupClass' summary(   object,   rotate = \"oblimin\",   Target = NULL,   suppress = 0,   suppress.cor = 0,   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of model object — summary-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass rotate string indicating rotation use exploratory models, primarily   GPArotation package (see documentation therein). Rotations currently supported : 'promax', 'oblimin', 'varimax',   'quartimin', 'targetT', 'targetQ', 'pstT', 'pstQ',   'oblimax', 'entropy', 'quartimax', 'simplimax',   'bentlerT', 'bentlerQ', 'tandemI', 'tandemII',   'geominT', 'geominQ', 'cfT', 'cfQ', 'infomaxT',   'infomaxQ', 'mccammon', 'bifactorT', 'bifactorQ'. models exploratory input automatically set 'none' Target dummy variable matrix indicting target rotation pattern. required rotations 'targetT', 'targetQ', 'pstT', 'pstQ' suppress numeric value indicating (possibly rotated) factor loadings suppressed. Typical values around .3 statistical software. Default 0 suppression suppress.cor suppress, correlation matrix output verbose logical; allow information printed console? ... additional arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summary of model object — summary-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of model object — summary-method","text":"","code":"if (FALSE) { # \\dontrun{ x <- mirt(Science, 2) summary(x) summary(x, rotate = 'varimax')  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate test information — testinfo","title":"Function to calculate test information — testinfo","text":"Given estimated model compute test information.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate test information — testinfo","text":"","code":"testinfo(   x,   Theta,   degrees = NULL,   group = NULL,   individual = FALSE,   which.items = 1:extract.mirt(x, \"nitems\") )"},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate test information — testinfo","text":"x object class 'SingleGroupClass', object class 'MultipleGroupClass' suitable group input supplied Theta matrix latent trait values degrees vector angles degrees 0 90. applicable input object multidimensional group group argument pass extract.group function. Required input object multiple-group model individual logical; return data.frame information traceline item? .items integer vector indicating items include expected information function. Default uses possible items","code":""},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate test information — testinfo","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate test information — testinfo","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate test information — testinfo","text":"","code":"dat <- expand.table(deAyala) (mirt(dat, 1, '2PL', pars = 'values')) #>    group   item     class   name parnum  value lbound ubound   est const nconst #> 1    all Item.1      dich     a1      1  0.851   -Inf    Inf  TRUE  none   none #> 2    all Item.1      dich      d      2  2.384   -Inf    Inf  TRUE  none   none #> 3    all Item.1      dich      g      3  0.000      0      1 FALSE  none   none #> 4    all Item.1      dich      u      4  1.000      0      1 FALSE  none   none #> 5    all Item.2      dich     a1      5  0.851   -Inf    Inf  TRUE  none   none #> 6    all Item.2      dich      d      6  0.726   -Inf    Inf  TRUE  none   none #> 7    all Item.2      dich      g      7  0.000      0      1 FALSE  none   none #> 8    all Item.2      dich      u      8  1.000      0      1 FALSE  none   none #> 9    all Item.3      dich     a1      9  0.851   -Inf    Inf  TRUE  none   none #> 10   all Item.3      dich      d     10  0.327   -Inf    Inf  TRUE  none   none #> 11   all Item.3      dich      g     11  0.000      0      1 FALSE  none   none #> 12   all Item.3      dich      u     12  1.000      0      1 FALSE  none   none #> 13   all Item.4      dich     a1     13  0.851   -Inf    Inf  TRUE  none   none #> 14   all Item.4      dich      d     14 -0.362   -Inf    Inf  TRUE  none   none #> 15   all Item.4      dich      g     15  0.000      0      1 FALSE  none   none #> 16   all Item.4      dich      u     16  1.000      0      1 FALSE  none   none #> 17   all Item.5      dich     a1     17  0.851   -Inf    Inf  TRUE  none   none #> 18   all Item.5      dich      d     18 -0.563   -Inf    Inf  TRUE  none   none #> 19   all Item.5      dich      g     19  0.000      0      1 FALSE  none   none #> 20   all Item.5      dich      u     20  1.000      0      1 FALSE  none   none #> 21   all  GROUP GroupPars MEAN_1     21  0.000   -Inf    Inf FALSE  none   none #> 22   all  GROUP GroupPars COV_11     22  1.000      0    Inf FALSE  none   none #>    prior.type prior_1 prior_2 #> 1        none     NaN     NaN #> 2        none     NaN     NaN #> 3        none     NaN     NaN #> 4        none     NaN     NaN #> 5        none     NaN     NaN #> 6        none     NaN     NaN #> 7        none     NaN     NaN #> 8        none     NaN     NaN #> 9        none     NaN     NaN #> 10       none     NaN     NaN #> 11       none     NaN     NaN #> 12       none     NaN     NaN #> 13       none     NaN     NaN #> 14       none     NaN     NaN #> 15       none     NaN     NaN #> 16       none     NaN     NaN #> 17       none     NaN     NaN #> 18       none     NaN     NaN #> 19       none     NaN     NaN #> 20       none     NaN     NaN #> 21       none     NaN     NaN #> 22       none     NaN     NaN mod <- mirt(dat, 1, '2PL', constrain = list(c(1,5,9,13,17))) #>  Iteration: 1, Log-Lik: -56256.669, Max-Change: 0.23297 Iteration: 2, Log-Lik: -55676.726, Max-Change: 0.15211 Iteration: 3, Log-Lik: -55476.742, Max-Change: 0.08970 Iteration: 4, Log-Lik: -55414.450, Max-Change: 0.05101 Iteration: 5, Log-Lik: -55395.424, Max-Change: 0.02855 Iteration: 6, Log-Lik: -55389.632, Max-Change: 0.01596 Iteration: 7, Log-Lik: -55387.850, Max-Change: 0.00880 Iteration: 8, Log-Lik: -55387.308, Max-Change: 0.00490 Iteration: 9, Log-Lik: -55387.139, Max-Change: 0.00269 Iteration: 10, Log-Lik: -55387.079, Max-Change: 0.00123 Iteration: 11, Log-Lik: -55387.067, Max-Change: 0.00066 Iteration: 12, Log-Lik: -55387.064, Max-Change: 0.00041 Iteration: 13, Log-Lik: -55387.062, Max-Change: 0.00011 Iteration: 14, Log-Lik: -55387.062, Max-Change: 0.00008  Theta <- matrix(seq(-4,4,.01)) tinfo <- testinfo(mod, Theta) plot(Theta, tinfo, type = 'l')   if (FALSE) { # \\dontrun{  # compare information loss between two tests tinfo_smaller <- testinfo(mod, Theta, which.items = 3:5)  # removed item informations plot(Theta, iteminfo(extract.item(mod, 1), Theta), type = 'l') plot(Theta, iteminfo(extract.item(mod, 2), Theta), type = 'l')  # most loss of info around -1 when removing items 1 and 2; expected given item info functions plot(Theta, tinfo_smaller - tinfo, type = 'l')   } # }"},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":null,"dir":"Reference","previous_headings":"","what":"Create all possible combinations of vector input — thetaComb","title":"Create all possible combinations of vector input — thetaComb","text":"function constructs possible k-way combinations input vector. primarily useful used conjunction mdirt function, though users may uses well. See expand.grid flexible combination formats.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create all possible combinations of vector input — thetaComb","text":"","code":"thetaComb(theta, nfact, intercept = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create all possible combinations of vector input — thetaComb","text":"theta vector possible combinations obtained nfact number observations (therefore number columns return matrix combinations) intercept logical; vector 1's appended first column result include intercept design component? Default FALSE","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create all possible combinations of vector input — thetaComb","text":"matrix possible combinations","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create all possible combinations of vector input — thetaComb","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create all possible combinations of vector input — thetaComb","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create all possible combinations of vector input — thetaComb","text":"","code":"# all possible joint combinations for the vector -4 to 4 thetaComb(-4:4, 2) #>       [,1] [,2] #>  [1,]   -4   -4 #>  [2,]   -3   -4 #>  [3,]   -2   -4 #>  [4,]   -1   -4 #>  [5,]    0   -4 #>  [6,]    1   -4 #>  [7,]    2   -4 #>  [8,]    3   -4 #>  [9,]    4   -4 #> [10,]   -4   -3 #> [11,]   -3   -3 #> [12,]   -2   -3 #> [13,]   -1   -3 #> [14,]    0   -3 #> [15,]    1   -3 #> [16,]    2   -3 #> [17,]    3   -3 #> [18,]    4   -3 #> [19,]   -4   -2 #> [20,]   -3   -2 #> [21,]   -2   -2 #> [22,]   -1   -2 #> [23,]    0   -2 #> [24,]    1   -2 #> [25,]    2   -2 #> [26,]    3   -2 #> [27,]    4   -2 #> [28,]   -4   -1 #> [29,]   -3   -1 #> [30,]   -2   -1 #> [31,]   -1   -1 #> [32,]    0   -1 #> [33,]    1   -1 #> [34,]    2   -1 #> [35,]    3   -1 #> [36,]    4   -1 #> [37,]   -4    0 #> [38,]   -3    0 #> [39,]   -2    0 #> [40,]   -1    0 #> [41,]    0    0 #> [42,]    1    0 #> [43,]    2    0 #> [44,]    3    0 #> [45,]    4    0 #> [46,]   -4    1 #> [47,]   -3    1 #> [48,]   -2    1 #> [49,]   -1    1 #> [50,]    0    1 #> [51,]    1    1 #> [52,]    2    1 #> [53,]    3    1 #> [54,]    4    1 #> [55,]   -4    2 #> [56,]   -3    2 #> [57,]   -2    2 #> [58,]   -1    2 #> [59,]    0    2 #> [60,]    1    2 #> [61,]    2    2 #> [62,]    3    2 #> [63,]    4    2 #> [64,]   -4    3 #> [65,]   -3    3 #> [66,]   -2    3 #> [67,]   -1    3 #> [68,]    0    3 #> [69,]    1    3 #> [70,]    2    3 #> [71,]    3    3 #> [72,]    4    3 #> [73,]   -4    4 #> [74,]   -3    4 #> [75,]   -2    4 #> [76,]   -1    4 #> [77,]    0    4 #> [78,]    1    4 #> [79,]    2    4 #> [80,]    3    4 #> [81,]    4    4  # all possible binary combinations for four observations thetaComb(c(0,1), 4) #>       [,1] [,2] [,3] [,4] #>  [1,]    0    0    0    0 #>  [2,]    1    0    0    0 #>  [3,]    0    1    0    0 #>  [4,]    1    1    0    0 #>  [5,]    0    0    1    0 #>  [6,]    1    0    1    0 #>  [7,]    0    1    1    0 #>  [8,]    1    1    1    0 #>  [9,]    0    0    0    1 #> [10,]    1    0    0    1 #> [11,]    0    1    0    1 #> [12,]    1    1    0    1 #> [13,]    0    0    1    1 #> [14,]    1    0    1    1 #> [15,]    0    1    1    1 #> [16,]    1    1    1    1  # all possible binary combinations for four observations (with intercept) thetaComb(c(0,1), 4, intercept=TRUE) #>       [,1] [,2] [,3] [,4] [,5] #>  [1,]    1    0    0    0    0 #>  [2,]    1    1    0    0    0 #>  [3,]    1    0    1    0    0 #>  [4,]    1    1    1    0    0 #>  [5,]    1    0    0    1    0 #>  [6,]    1    1    0    1    0 #>  [7,]    1    0    1    1    0 #>  [8,]    1    1    1    1    0 #>  [9,]    1    0    0    0    1 #> [10,]    1    1    0    0    1 #> [11,]    1    0    1    0    1 #> [12,]    1    1    1    0    1 #> [13,]    1    0    0    1    1 #> [14,]    1    1    0    1    1 #> [15,]    1    0    1    1    1 #> [16,]    1    1    1    1    1"},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"helper function users previously available traditional/classical IRT parameters want know equivalent slope-intercept translation used mirt. Note function assumes supplied models unidimensional definition (.e., one slope/discrimination) logistic metric (.e., logistic-ogive scaling coefficient D=1). supported slope-intercept transformation available original vector parameters returned default.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"","code":"traditional2mirt(x, cls, ncat)"},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"x vector parameters transform cls class itemtype supplied model ncat number categories implied IRT model","code":""},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"named vector slope-intercept parameters (supported)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"Supported class transformations cls input : Rasch, 2PL, 3PL, 3PLu, 4PL Form must : (discrimination, difficulty, lower-bound, upper-bound) graded Form must : (discrimination, difficulty 1, difficulty 2, ..., difficulty k-1) gpcm Form must : (discrimination, difficulty 1, difficulty 2, ..., difficulty k-1) nominal Form must : (discrimination 1, discrimination 2, ..., discrimination k,       difficulty 1, difficulty 2, ..., difficulty k)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"","code":"# classical 3PL model vec <- c(a=1.5, b=-1, g=.1, u=1) slopeint <- traditional2mirt(vec, '3PL', ncat=2) slopeint #>  a1   d   g   u  #> 1.5 1.5 0.1 1.0   # classical graded model (four category) vec <- c(a=1.5, b1=-1, b2=0, b3=1.5) slopeint <- traditional2mirt(vec, 'graded', ncat=4) slopeint #>    a1    d1    d2    d3  #>  1.50  1.50  0.00 -2.25   # classical generalize partial credit model (four category) vec <- c(a=1.5, b1=-1, b2=0, b3=1.5) slopeint <- traditional2mirt(vec, 'gpcm', ncat=4) slopeint #>    a1   ak0   ak1   ak2   ak3    d0    d1    d2    d3  #>  1.50  0.00  1.00  2.00  3.00  0.00  1.50  1.50 -0.75   # classical nominal model (4 category) vec <- c(a1=.5, a2 = -1, a3=1, a4=-.5, d1=1, d2=-1, d3=-.5, d4=.5) slopeint <- traditional2mirt(vec, 'nominal', ncat=4) slopeint #>         a1        ak0        ak1        ak2        ak3         d0         d1  #> -0.3333333  0.0000000  4.5000000 -1.5000000  3.0000000  0.0000000 -2.0000000  #>         d2         d3  #> -1.5000000 -0.5000000"},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract parameter variance covariance matrix — vcov-method","title":"Extract parameter variance covariance matrix — vcov-method","text":"Extract parameter variance covariance matrix","code":""},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract parameter variance covariance matrix — vcov-method","text":"","code":"# S4 method for class 'SingleGroupClass' vcov(object)"},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract parameter variance covariance matrix — vcov-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract parameter variance covariance matrix — vcov-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract parameter variance covariance matrix — vcov-method","text":"","code":"if (FALSE) { # \\dontrun{ x <- mirt(Science, 1, SE=TRUE) vcov(x)  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":null,"dir":"Reference","previous_headings":"","what":"Wald statistics for mirt models — wald","title":"Wald statistics for mirt models — wald","text":"Compute Wald test given L vector matrix numeric contrasts. Requires model information matrix computed (passing SE = TRUE estimating model). Use wald(model) observe information matrix columns named, especially estimated model contains constrained parameters (e.g., 1PL).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wald statistics for mirt models — wald","text":"","code":"wald(object, L, C = NULL)"},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wald statistics for mirt models — wald","text":"object estimated object mirt, bfactor, multipleGroup, mixedmirt, mdirt L coefficient matrix dimensions nconstrasts x npars.estimated, character vector giving hypothesis symbolic form (syntax format borrowed car package; see Details ). Omitting value return column names information matrix used identify (potentially constrained) parameters C constant vector population parameters compared along side L,   length(C) == row(L). default vector 0's constructed. Note using   syntax input L argument ignored following description borrowed car package documentation pertaining character vector input argument L: \"hypothesis matrix can supplied numeric matrix (vector), rows specify linear combinations model coefficients, tested equal corresponding entries right-hand-side vector, defaults vector zeroes. Alternatively, hypothesis can specified symbolically character vector one elements, gives either linear combination coefficients, linear equation coefficients (.e., left right side separated equals sign). Components linear expression linear equation can consist numeric constants, numeric constants multiplying coefficient names (case number precedes coefficient, may separated spaces asterisk); constants 1 -1 may omitted. Spaces always optional. Components separated plus minus signs. Newlines tabs hypotheses treated spaces. See examples .\"","code":""},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Wald statistics for mirt models — wald","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Wald statistics for mirt models — wald","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wald statistics for mirt models — wald","text":"","code":"if (FALSE) { # \\dontrun{  # View parnumber index data(LSAT7) data <- expand.table(LSAT7) mod <- mirt(data, 1, SE = TRUE) coef(mod)  # see how the information matrix relates to estimated parameters, and how it lines up #   with the parameter index (infonames <- wald(mod)) index <- mod2values(mod) index[index$est, ]  # second item slope equal to 0? L <- matrix(0, 1, 10) L[1,3] <- 1 wald(mod, L)  # same as above using character syntax input infonames wald(mod, \"a1.5 = 0\")  # simultaneously test equal factor slopes for item 1 and 2, and 4 and 5 L <- matrix(0, 2, 10) L[1,1] <- L[2, 7] <- 1 L[1,3] <- L[2, 9] <- -1 L wald(mod, L)  # Again, using more efficient syntax infonames wald(mod, c(\"a1.1 = a1.5\", \"a1.13 = a1.17\"))  # log-Liklihood tests (requires estimating a new model) cmodel <- 'theta = 1-5            CONSTRAIN = (1,2, a1), (4,5, a1)' mod2 <- mirt(data, cmodel) # or, equivalently #mod2 <- mirt(data, 1, constrain = list(c(1,5), c(13,17))) anova(mod2, mod)  ##### # test equality of means in multi-group model: #    H0: (mu1 - mu2) = (mu3 - mu4)  set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 500 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .5) dataset3 <- simdata(a, d, N, itemtype, mu = -1) dataset4 <- simdata(a, d, N, itemtype, mu = -.5) dat <- rbind(dataset1, dataset2, dataset3, dataset4) group <- factor(rep(paste0('D', 1:4), each=N)) levels(group) models <- 'F1 = 1-15'  # 3 means estimated mod_free <- multipleGroup(dat, models, group = group, SE=TRUE,                           invariance=c('slopes', 'intercepts', 'free_var','free_means')) wald(mod_free) # obtain parameter names # View(mod2values(mod_free))  # reference group mean = 0 by default wald(mod_free, c(\"0 - MEAN_1.123 = MEAN_1.185 - MEAN_1.247\"))   } # }"},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-143","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.43","title":"Changes in mirt 1.43","text":"CRAN release: 2024-11-14 M2() family longer requires row-wise removal missing data behave correctly. , na.rm argument removed longer required (requested Ulrich Schroeders) Added support latent regression ACOV/SE estimation Oakes method mirt() Related points , general MLTM (Embretson, 1984) added itemtype specified PC1PL itemdesign set used, formula must include name factor formula expressions. See examples mirt documentation (requested Susan Embretson) Added PC1PL itemtype easily specify conjunctive models slopes fixed 1 estimation latent variance term, mimicking Rasch itemtype family mirt() multipleGroup() gain itemdesign item.formula arguments fit fixed item design characteristics (e.g. LLTMs; Fischer, 1983) subset items. Arguments similar mixedmirt(), though currently flexible Partially-compensatory family itemtypes now behave consistently loading structures specified trace lines products computed dimensions non-zero slopes RCI() gains shiny logical create interactive scoring interface","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-142","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.42","title":"Changes in mirt 1.42","text":"CRAN release: 2024-07-14 model argument bfactor() can now specified using mirt.model() syntax include cognitively friendly tracking item names respective locations (requested Afshin Khosravi) Add reverse.score() function reverse scoring specific items within matrix data.frame Fixed issue related missing data patterns resulted bias estimating hyper-parameters single multi-group models (reported Paul Jewsbury) mirt.model() syntax gains negation operator omitting specific observed/latent groups specifications. example, following omit “Group3” identifies groups equality constraint definitions CONSTRAINB[-Group3] = ... RMSD_DIF() now supports datasets follow vertical scaling structures (.e., groups answer items others). Requested Alexandre Jaloto M2() functions now compute null model SRMR fall models whenever possible, including latent class variance (reported Hynek Cigler) VCOV memory leak bugfix mixture models (see Github issue #247) Standardized residuals point estimates now returned personfit() passing return.resids=TRUE (requested Raymond Hernandez)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-141","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.41","title":"Changes in mirt 1.41","text":"CRAN release: 2023-10-17 Fix DIF() sparse data included mixed item formats (reported Heather Leigh Kayton) computing category-level information curves include negative Hessian computations (reported Milica Kabic) Allow missing data patterns personfit(), well new option return raw item person residuals (requested George Karabatsos) Fix Zero-inflated model example multipleGroup(), required discontinuous trait location populated explicitly customTheta syntax (reported Brooke Magnus) Empirical reliability estimates fscores() empirical_rxx() include option use true score variance estimate observed score variance (suggested Hynek Cigler)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-140","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.40","title":"Changes in mirt 1.40","text":"CRAN release: 2023-08-10 technical list gains nconstrain argument specifying equality constraints negative relationships (e.g., a12 = -a21). Requested Berend Terluin Added unipolar log‑logistic model (Lucke, 2015) itemtype, specified itemtype = 'ULL'. Note automatically changes number internal defaults, using log-normal(0,1) density latent traits, theta_lim specified positive Added complementary log‑log model (Shim, Bonifay, Wiedermann, 2022) itemtype, specified itemtype = 'CLL' Added itemtype = '5PL' model unidimensional dichotomous data included asymmetric response functions. Example help(mirt) also demonstrates asymmetric 2PL model 5PL unstable requires strong priors Methods using Quasi-Monte Carlo integration post-convergence respecting correlated latent variable structures (reported George Kephart using M2()) Bugfix fscores() supplying mixture models introduced changing previous classification default latent class models (reported Karel Veldkamp) residuals() gains p.adjust argument FWE control DRF() gains DIF.cat argument compute statistics per-category basis studying polytomous items expected.test() gains probs.logical return probability functions category (used individual = TRUE) Small bug fixes C++ code resulted memory leaks","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-139","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.39","title":"Changes in mirt 1.39","text":"CRAN release: 2023-05-30 models fit using mdirt() fscores() EAP EAPsum methods now always returns classification probabilities default (reported Matthew Madison) SIBTEST() gains DIF logical perform DIF tests across suspect_set DIF() SIBTEST() gain pairwise logical input perform pairwise post-hoc comparisons multi-group applications DRF() gains groups2test argument friends multi-group models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1381","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.38.1","title":"Changes in mirt 1.38.1","text":"CRAN release: 2023-02-28 infit outfit statistics can now computed itemfit() missing data present (requested Hanif mirt-package forum: https://groups.google.com/g/mirt-package/c/_mA3YbMmbzM/m/CydOl-F4BQAJ?utm_medium=email&utm_source=footer) coef(..., IRTpars=TRUE) now applied multidimensional IRT models, provided item contains simple structure (suggested Sverre Ofstad) Fixed match() bug SIBTEST() total score missing (reported Ziying Li) fscores(..., method ='EAPsum') now supports returning ACOV matrices, matching behaviour estimators Store previously defined customItems customGroup lists use secondary functions (e.g., DIF(), boot.mirt(), etc). Reported Nataly Beribisky Combining priors equality constraints longer uses multiple prior definitions likelihood computations. Hence, constrained parameters now treated though single parameter one prior distribution (reported Matthias von Davier context multiple-group models group item priors) Added groups2test argument DIF() isolate individual grouping variable specification using 2 groups Implicit argument ‘invariance’ stored multiple-group objects now automatically used boot.mirt() (previously manually passed) Bugfix using items2test DIF input character vector (reported @jbuncher) Bug fixes multiple-group DIF testing DIF() using two groups (reported Ruben Neda Davin Díaz García)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1371","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.37.1","title":"Changes in mirt 1.37.1","text":"CRAN release: 2022-08-10 boot.mirt() gains boot.fun argument accept user-defined functions extracting associated statistics bootstrap verbose = TRUE residuals() set summary statistics reported easier flagging itemfit() arguments changed accommodate outputting tables consistently. Now single return.tables argument used specify tables return anova() removes support verbose flag, instead labels rows resulting output identify models X2 G2 classes item-fit statistics now better deal large missing value vectors per-item basis better consistency technical list gains storeEMhistory flag store EM history (requested @netique) DRF() gains best-fitting prior support (currently limited Gaussian distributions) Correct index subset caused tmp row removals MG objects (fixes #227)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-136","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.36","title":"Changes in mirt 1.36","text":"CRAN release: 2022-03-21 Progress bar added automatically (controlled via verbose argument) using several package’s secondary functions (e.g., fscores(), DIF(), 'DRF(), mdirt(), etc) Added itemstats() function give basic item information statistics Item-EFA models now automatically flips negative signs rotate solutions (e.g., via summary()) according sign largest observed loading (allows easier interpretation resulting correlation matrix) response.pattern deals completely missing vectors now (issue #220) residuals() gains approx.z logical transform LD values approximate z-ratios mirt(), mixedmirt(), multipleGroup() now model = 1 fit unidimensional IRT model default","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1351","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.35.1","title":"Changes in mirt 1.35.1","text":"CRAN release: 2021-12-08 Added covdata argument fscores() allow latent regression covariate information well. Example added fscores() documentation demonstrate addition Added RCI() function compute reliable change index via IRT modelling Added delta method SE coef(., IRTpars = TRUE) nominal nested-logit models itemfit() gains S_X2.plot argument visualize expected-observed probability differences based S-X2 conditional sum-score strategy Added type = 'EAPsum' plot() generic view expected vs observed sum-scores plot itemfit() gains p.adjust argument allow p-value adjustments output methods anova() generic now supports ... input compare many nested models, compared sequence Added type = 'threshold' itemplot() plot cumulative probability information (requested Azman Sami) Fixed Bug Error ((SEtmp < 0)) appeared due new R 4.0+ behaviour (reported Ziying Li Caroline Böhm) Fix bug itemfit() plotting multiple-group objects Bugfix fscores() report row failed converge datsets contain response patterns completely missing","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-134","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.34","title":"Changes in mirt 1.34","text":"CRAN release: 2021-06-28 Previous technical = list(removeEmptyRows = TRUE) input now deprecated. Response patterns now completely missing supplied NA placeholders within estimation post-estimation supporting functions (e.g., fscores(), personfit(), fixed(), etc) Added converged element DIF() output evaluate whether nested model iteration converged Added support plausible-value draws fscores() using response.pattern argument Fix SE.type = 'Fisher' computation multi-group models (reported Felix Zimmer) Switch par f inputs numerical_deriv()","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1331","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.33.1","title":"Changes in mirt 1.33.1","text":"Added gen.difficulty() compute generalized difficulty statistics described Ali, Chang, Anderson (2015) polytomous response models (suggested Alexander Freund) Added RMSD_DIF() compute marginal effect size measure recently used PISA anlayses investigating ‘badness--fit’ DIF effects using constrained multiple-group models extract.group() now explicitly requires group name passed rather group number (far natural route) plot(..., type =) now supports 'trace', 'infotrace', 'itemscore', '' two-dimensional models create faceted graphics Added read.mirt() function back package now plink available CRAN Syntax input car package’s lht() function adopted within mirt’s wald() function easier specifications (see examples) Better cope syntax definitions models DIF(), particularly CONSTRAINB form (reported Hao Wu) Corrected outer-product summation SE.type = 'Fisher' computation (reported Felix Zimmer) Added fixedCalib() function perform five fixed-calibration methods describe Kim (2006) Empirical histogram dentype convergence tolerance longer modified (default now Gaussian dentype criteria) Fix GGUMs using model syntax input (ignoring slope loading specifications; reported Ben Listyg) fixed traditional2mirt() math gpcm 5 category items supplied (reported Aiden Loe)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1321","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.32.1","title":"Changes in mirt 1.32.1","text":"CRAN release: 2020-04-25 OpenMP support added E-step portion package, number threads can specified via mirtCluster() function argument omp_threads. Special thanks Matthias von Davier providing omp reduction code Estep.cpp file Behaviour mirt(..., large) now modified, large = TRUE now skips computing unique response patterns datasets likely contain little repeated response patterns (suggested Matthias von Davier). previous two-step behaviour now achieved passing large = 'return', storing list object, passing back large input argument Positive/negative sign remove chi-square components residuals(type = 'LD') (requested Cengiz Zopluoglu help avoid confusion). Sign still however present standardized correlation estimates itemtype = 'rsm' reported incorrect information functions due use - instead + traditional2mirt() (reported Nasser Hasan) column names fscores() results now correspond model syntax definition names instead previous F# convention fix method = 'classify' option fscores() two mixtures fitted (reported Lisa Limeri) fix bug 'drop_sequential' scheme DIF() introduced previous version mirt due internal organization changes (reported Balal Izanloo) allow infit/outfit statistics computed non-Rasch models (suggested Alexander Freund use GGUMs) added p.adjust argument DRF() (requested Keri J. S. Brady) support computation ACOV matrix variance specific factors freely estimated bfactor() fix invariance = 'free_var' argument multipleGroup() multidimensional models correlated traits, previously fixed correlation parameters inadvertently (reported Ruoyi Zhu) use proper mins internal using extract.group() keep original minimum response scoring pattern (reported Adam Ťápal) bugfix single-group models draw_parameters() (reported Keri Brady @ddueber) numeric model specification bfactor() bug patched intervals 1 unit apart due NA placeholders (reported Luis Manuel Lozano) latent trait/class names now forced different data column names (bug reported Nathan Carter) fixed X2*_df PV_Q1* missing data pattern resulted dropped categories (reported Mac Pank)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-131","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.31","title":"Changes in mirt 1.31","text":"CRAN release: 2019-09-14 added likert2int() convert Likert-type character/factor responses integer data estfun() gains centering argument center scores (contributed Rudolf Debelak) impute argument itemfit() M2() deprecated favour removing data row-wise via na.rm=TRUE Acceptance ratio using MH samplers now returned prior ‘Stage 2’ estimation ratios better behaved. well, heuristic improved method increasing/decreasing acceptance ratios now implemented Added return_seq_model DIF() return final MG model last iteration sequential search schemes Bugfix DIF() sequential scheme selected items contained DIF first iteration (reported Scott Withrow) SIBTEST() gains plot argument create various plots depicting (weighted) differences focal subtest versus matched subtest information residuals() gains 'JSI' type compute JSI statistics proposed Edwards et al. (2018) residuals() gains 'expfull' type compute expected value table possible response patterns (just observed data) Fix key variable nested-logit models data collapsed equal intervals (reported Emil Kirkegaard) Added delta method IRT parameter transformations using multiple-group models (reported Alex Miller)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-130","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.30","title":"Changes in mirt 1.30","text":"CRAN release: 2019-01-29 empirical.poly.collapse argument added itemfit() plot expected score functions polytomous items (suggested Keri Brady) SRMSR now reported M2() GGUMs (suggested Bo mirt-package forum) weights argument added estfun.AllModelClass allow inclusion survey.weights calculate scores DIF() now simplifies output default rather returning lists anova(). Wald tests always simplified applicable, RMSEA statistics reported itemfit() tests return suitable X2 df components Fix negative TLI CFI values using C2 statistic M2() function (reported Jake Kraska Charlie Iaconangelo) Fix delta method SEs 'gpcm' itemtype (reported Lennart Schneider)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-129","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.29","title":"Changes in mirt 1.29","text":"CRAN release: 2018-08-12 lower/upper bounded parameters included default optimizer now ‘nlminb’ rather ‘L-BFGS-B’. mainly due instability ‘L-BFGS-B’ algorithm prone converging instantly unknown reasons mdirt() gains item.Q list specify Q-matrices item-category level item createItem() functions gain optional argument function definitions allow list-specified data functions mirt() via silent mirt(..., customItemsData) argument lattice auto.key default now reports lines rather points. now consistent , example, color theme changed black white trellis window Added Differential Response Function (DRF) statistics upcoming publication (Chalmers, accepted) new function entitled DRF(). related compensatory non-compensatory measures response bias DIF, DBF, DTF available SIBTEST framework IRT model fitted within multiple-group estimation framework structure argument added mdirt() function allow log-linear models simplifying profile probability model computations export internally used traditional2mirt() function transform small selection classical IRT parameterizations slope-intercept form fix survey.weights input multiple group models (reported Leigh Allison) fix itemtype = \"rsm\" block restriction items contain unequal category lengths (reported Aiden Loe) SIBTEST() computation beta coefficient changed match Shealy Stout’s (1993) form p_k * (Y_R - Y_F) (previously p_k * (Y_F - Y_R); reported Craig Wells). well, Jmin default increased 5 avoid conservative Type error behavior longer tests Fix negative chi-square differences DIF() function due non-converged sub-models (reported Daniel McKelvey)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-128","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.28","title":"Changes in mirt 1.28","text":"CRAN release: 2018-05-20 M2() function gains type input distinguish univariate-bivariate collapsed M2* statistic bivariate collapsed C2 statistic (Cai Monro, 2014). C2 can useful polytomous items degrees freedom compute fully collapsed M2* multipleGroup() gains dentype argument allow mixture IRT models fitted (e.g., dentype = 'mixture-3' fits three-class mixture model). also allow modifications zero-inflated IRT model fitted technical gains zeroExtreme logical flag assign survey weights 0 extreme response patterns (FALSE default). may required Woods’ extrapolation-interpolation method used empirical histograms avoid ill defined extrapolated densities fscores(), itemfit(), M2(), residuals() gain use_dentype_estimate argument compute EAP-based scores whenever latent trait density estimated (e.g., via empirical histograms) Empirical histograms can now now scaled [0,1] using Woods’ extrapolation-interpolation method via input dentype = 'empiricalhist_Woods'. Degrees freedom updated reflect change, 121 quadrature points used instead previous 199 better stability Semi-parametric Davidian curve estimation shape latent trait distribution unidimensional IRT models contributed Oguzhan Ogreden, well associated components used within framework (interpolation-extrapolation method described Woods, 2006). estimation method available new dentype input. mirt also now links dcurver package obtain associated computation functions EM algorithm M2(), itemfit(), SIBTEST(), fscores() gain na.rm logical remove rows missing data fscores() gains append_response.pattern logical indicate whether response patterns via response.pattern input appended factor score results new dentype argument added estimation-based functions specify density structure latent traits (default 'Gaussian'). update breaks previous empiricalhist logical option anova() accept single fitted model object return information related AIC, BIC, log-likelihood, etc Hannan–Quinn (HQ) Criterion added anova()","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-127","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.27","title":"Changes in mirt 1.27","text":"Added multidimensional version sequential response model (e.g., Tutz, 1990). Includes itemtype = 'sequential' multidimensional 2PL variant, itemtype = 'Tutz' Rasch variant Printing IRT parameters via coef(mod, IRTpars = TRUE) now computes delta method g u terms well. Interpreting generally recommended due bounded parameter nature (CIs can outside range [0,1]), included posterity createItem() gains bytecompile flag indicate whether internal functions byte-compiled using (default TRUE) Special GROUP location holder mirt.model() index group-level hyper-parameter terms key2binary() gains score_missing flag indicate whether missing values scored 0 left NA createItem() gains support derivType = 'symbolic' derivType.hss = 'symbolic' symbolically compute gradient/Hessian functions (template code-base contributed Chen-Wei Liu) createItem() gains derivType.hss argument distinguish gradient Hessian numerical computations mdirt() gains support createItem() inputs plotting points added default plot() itemplot() generics create smoother traceline functions","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-27","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"Changes in mirt 1.27","text":"fix simdata() bug new ggum itemtype fix new grouping syntax specification mirt.model() combining START FIXED (reported Garron Gianopulos) fix IRTpars = TRUE input itemtype Rasch (reported Benjamin Shear)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1263","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.26.3","title":"Changes in mirt 1.26.3","text":"CRAN release: 2017-11-29 mod2values() passing pars = 'values' now return data.frame objects without factor variables (previously defaults data.frame() used, created factors categorical variables default) Add monopoly itemtype fit unidimensional monotonic polynomial item response model polytomous data (see Falk Cai, 2016) Add ggum itemtype fit unidimensional/multidimensional graded unfolding model (e.g., Roberts & Laughlin, 1996). Special thanks David King providing necessary C++ derivative functions starting values Square brackets can now included mirt.model() syntax indicate group-specific constraints, priors, starting/fixed values, . general form \"CONSTRAIN [group1, group2] = ...\" \"FIXED [group1] = ...\" Added delta method several classical IRT parameterization (via coef(model, IRTpars = TRUE)) suitable information matrix previously estimated numDeriv dependency removed numerical_deriv() now supports local Richardson extrapolation type. best accuracy, now used default throughout package createItem() lagrange() now use Richardson extrapolation default instead less accurate forward/central difference method estfun() function added extract gradient information directly fitted objects (contributed Lennart Schneider) simdata() gains equal.K argument redraw data KK categories populated given item Fix initialization fscores() using ‘MH’ plausible value imputations (reported Charlie Iaconangelo) Various small bug fixes performance improvements, fixes Solaris compatibility, run small number examples R CMD check","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-125","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.25","title":"Changes in mirt 1.25","text":"CRAN release: 2017-07-23 mdirt() now supports latent regression covariate predictors. Associated function (e.g., fscores()) also include latent regression information discrete models default SIBTEST() replaced asymptotic sampling distribution version CSIBTEST described Chalmers (accepted) calcNull set FALSE default Sandwich ACOV estimate now uses Oakes estimate computations rather intensive Louis form (require low-level coding item-level Hessian terms). Added new SE.type = 'sandwich.Louis' original sandwich VCOV estimate previous version mirt fix latent regression models QMCEM MCEM algorithms (reported Seongho Bae) fscores() gains max_theta argument apply upper/lower bounds iterative searching algorithms (issue reported Sebastian Born), start input set starting values well (primarily useful mirtCAT reduce iterations) alabama package optimizer longer used. Replaced generic interface nloptr package support numerous optimizers greater control instead. Associated inputs (e.g., alabama_args) replaced well Export missing S4 methods external R packages import","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-124","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.24","title":"Changes in mirt 1.24","text":"CRAN release: 2017-05-04 MDIFF MDISC longer normal ogive metric (1.702 scaling value removed) added QMC option residuals() LD LDG2 methods. Also globally set number QMC points 5000 throughout package consistency info_if_converged logLik_if_converged added technical list indicate whether information matrix stochastic log-likelihood computed model converges. Default now TRUE added 'MCEM' method Monte Carlo EM. associated MCEM_draws function added technical list well control number draws throughout EM cycles support information matrix computations QMCEM method added (e.g., Oakes, crossprod, Louis) globally improve numerical efficiency QMC methods, including QMCEM estimator include missing data values itemfit() parametric bootstrap methods replicate missing data pattern ensure nest-logit models least 3 categories (reported Seongho Bae) convergence set FALSE g > u found 4PL model verbose console output log-posterior printed priors included EM (previously marginal likelihood) various bug fixes SIBTEST, particularly small sample sizes","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-123","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.23","title":"Changes in mirt 1.23","text":"CRAN release: 2017-03-02 anova() LRT comparison gains bounded logical indicate whether bounded parameter compared, well mix argument indicate mixture chi-squared distributions MH-RM estimation optimizer argument can now modified BFGS, L-BFGS-B, NR instead default NR1 distinction NR optimizer EM MH-RM applications included, MH-RM now defaults NR1 indicate single Newton-Raphson update uses RM filtered Hessian term method = 'SEM' added perform stochastic EM algorithm (first two stages MH-RM algorithm setup). Alternatively, setting technical = list(NCYCLES = NA) using MH-RM algorithm now returns stochastic EM results added multidim_matrix option iteminfo() expose computation information matrices bounded parameter spaces handled better using NR optimizer various bug fixes performance improvements","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-122","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.22","title":"Changes in mirt 1.22","text":"CRAN release: 2017-02-01 SE.type = 'Oakes' set new default computing standard errors via ACOV matrix using EM algorithm new SE.type = 'Oakes' compute Oakes’ 1999 form observed information matrix using central difference approximation. Applicable IRT models (including customized IRT types) added support gpcmIRT rsm itemtypes traditional generalized partial credit model Rasch rating scale model (may modified generalized rating scale model freeing slope parameters) SE.type = 'Fisher' now supports inclusion latent distribution hyper-parameters. Officially, SE-types now provide proper hyper-parameter influence information matrices wrapped various output objects mirt_df, mirt_matrix, mirt_list class avoid need passing digits argument rounding output console. Now, returned objects never rounded, makes writing Monte Carlo simulation code safer rounded results appear results added Stone’s (2000) fit statistics forthcoming PV-Q1 fit statistics itemfit()","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-22","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"Changes in mirt 1.22","text":"patched underflow bug fscores() EAP estimates used extremely long (1000+ item) tests. Error now reported happens. Using MAP estimates extreme situations essentially equivalent now recommended","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-121","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.21","title":"Changes in mirt 1.21","text":"CRAN release: 2016-12-01 add information number freely estimated parameters print() generic plot(), auto.key disabled facet_items = FALSE dichotomous items. Also, adjusted ordering plot(mod, type = 'itemscore') reflect actual item ordering data Stretched theoretical bounds y-axis score-based functions plot() itemplot() (e.g., 3PL models now always stretch S(theta) = 0) plot(mod, type = 'score') supports .items input make expected score plots bundles items penalized term added EM algorithm estimation subroutines help keep covariance matrix latent trait parameters positive definite M-step (helps convergence properties optimizers, especially ‘L-BFGS-B’). turn penalized term use technical = list(keep_vcov_PD = FALSE) added type = 'itemscore' plot() generic plot faceted version item scoring functions. Particularly useful investigating DIF multipleGroup() better support splines itemtype multiple-group models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-21","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"Changes in mirt 1.21","text":"fix problem ‘EAPsum’ fscores() response.pattern input supplied (reported Eva de Schipper) plot(mod, type = 'rxx') now uses latent variance computations (reported Amin Mousavi) fix syntax input customized IRT models supplied","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1201","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.20.1","title":"Changes in mirt 1.20.1","text":"CRAN release: 2016-10-05 df adjustment S_X2 item-fit statistic models latent trait hyper-parameters estimated itemfit() personfit() properly detect dichotomous Rasch models defined constrained slopes approach argument 'fit_stats' now used itemfit() replace longer list logicals (e.g., itemfit(mod, S_X2 = FALSE, X2 = TRUE, infit = FALSE, ...)). Now fit stats explicitly requested character vector input. Default still uses S_X2 statistic using 'lnorm' prior lower bound automatically set 0, 'beta' prior lower upper bounds set [0,1] mdirt() now uses optimizer = 'nlminb' default revert using default ‘penalized version BFGS algorithm’ instead L-BFGS-B box-constraints used (introduced version 1.19) Neale & Miller 1997 approximation added PLCI() (default still computes exact PL CIs) type = 'score' supported multiple group models itemplot() added poly2dich function quickly change polytomous response data comparable matrix dichotomous response data","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-119","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.19","title":"Changes in mirt 1.19","text":"CRAN release: 2016-08-18 penalized version BFGS algorithm now used instead L-BFGS-B upper lower bounds included (provides robust estimates) variances orthogonal factors bfactor() can now freely estimated. allows modeling designs testlet response model (example included documentation) new spline itemtype model B-spline response functions dichotomous models. Useful diagnostic purposes detecting item-misfit. Additional arguments can passed spline_args list input control behaviour splines item. Currently limited unidimensional models fscores() gains plausible.type argument select normal approximation PVs Metropolis-Hastings samples (suggested Yang Liu) mdirt() modified support DINA, DINO, located latent class, diagnostic classification models. Additionally, customTheta input required build customized latent class patterns changed previously cumbersomemdirt(..., technical = list(customTheta = Theta)) simply mdirt(..., customTheta = Theta) simdata() gains prob.list input supply list matrices probability values sampled (useful specialized response functions outside package required) simdata() supports ‘lca’ itemtypes latent class model generation improved M2 accuracy latent trait variances estimated corrected behaviour M2() linear constraints applied (M2 test previously conservative constraints used). affects single well multiple-group models (reported Rudolf Debelak) add plausible values latent class related models estimated mdirt()","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-19","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.19","text":"multipleGroup() throws proper error vertical scaling identified correctly due NAs S-X2 itemfit statistic fix rare expected categories appear (reported Seongho Bae)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-118","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.18","title":"Changes in mirt 1.18","text":"CRAN release: 2016-06-24 mdirt() function now includes explicit parameters latent class intercepts (log-form). implies correct standard errors can computed using various methods (e.g., SEM, Richardson, etc) new customGroup() function define hyper-parameter objects latent trait distributions (generally assumed Gaussian mean covariance structure) new boot.LR() function perform parametric bootstrap likelihood-ratio test nested models. Useful testing nested models contain bounded parameters (e.g., testing 3PL versus 2PL model) adjust lagrange() function use full information matrix (previously quasi-lagrange approximation) greatly improved speed simdata(), consequently changes default seed","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-18","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.18","text":"fix crash error mirtmirt() multidimensional models lr.random effects (reported Diah Wihardini) expbeta prior starting values fix setting mean prior rather mode (reported Insu Paek)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1171","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.17.1","title":"Changes in mirt 1.17.1","text":"CRAN release: 2016-04-27 itemfit() function reworked statistics input flag (e.g., Zh = TRUE, infit = TRUE, etc). Additionally, S-X2 computed default X2/G2 (associated graphics tables) computed using 10 fixed bins added empirical.table argument return tables expected/observed values X2 G2 group.bins group.fun argument added itemfit() control size bins central tendancy function X2 G2 computations 'expbeta' option added implement beta prior specifically g u parameters internally transformed logits (performes back transformation computing values) check whether multiple-group models contain enough data estimate parameters uniquely constraints applied set starting values using parprior list mirt.model() syntax (reported Insu Paek) empirical_ES() function added effect size estimates DIF/DBF/DTF analyses (contributed Adam Meade)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-17-1","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.17.1","text":"standardized loadings correct factor correlations included confirmatory models (reported Seongho Bae) MDISC MDIFF values missing 1.702 multiplicitive constant (reported Yi-Ling Cheng) fix information trace-lines multiple-group plots (reported Conal Monaghan) suppress standard errors exploratory models rotate != 'none' (suggested Hao Wu) sequential schemes DIF() generated wrong results (reported Adam Meade) M2() properly accounting latent variance terms (reported Ismail Cuhadar)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-116","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.16","title":"Changes in mirt 1.16","text":"CRAN release: 2016-03-07 enable lr.random input mixedmirt() multilevel-IRT models Rasch family add common vcov() logLik() methods latent regression EM models now standard error computation supporte ‘complete’, ‘forward’, ‘central’, ‘Richardson’ methods new areainfo() function compute area information curves within specified ranges (suggested Conal Monaghan) method = 'BL' supported multiple-group models. well, SE.type = 'numerical' included return observed-data ACOV matrix call optim() (can used BL method selected) new SE.type = 'FMHRM' compute information matrix based fixed number MHRM draws, associated technical = list(MHRM_SE_draws) argument added control number draws added lagrange (.e., score) test function testing whether parameters freed single multiple group models estimated EM algorithm numerical_deriv function made available simple numerical derivatives, may useful defining fast custom itemtype derivative terms SE.type used compute ACOV matrix gained three numerical estimates forward difference (‘forward’), central difference (‘central’), Richardson extropolation (‘Richardson’)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-16","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.16","text":"SE methods based Louis (1982) computations longer contain NA placeholders latent trait hyper-parameters","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-115","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.15","title":"Changes in mirt 1.15","text":"CRAN release: 2016-01-21","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"minor-changes-1-15","dir":"Changelog","previous_headings":"","what":"MINOR CHANGES","title":"Changes in mirt 1.15","text":"added SIBTEST crossed-SIBTEST procedures new function SIBTEST() added empirical_plot function building empirical plots (potential smoothing) conditioning total score low-level elements included extract.mirt() function added grsmIRT itemtype classical graded rating scale form (contributed KwonHyun Kim) added missing analytic Hessian terms gpcm_mats used (contributed Carl Falk)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-15","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.15","text":"fixed row-removal bug using technical = list(removeEmptyRows = TRUE) (reported Aaron Kaat)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-114","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.14","title":"Changes in mirt 1.14","text":"CRAN release: 2015-11-19","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-14","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.14","text":"structure output objects now contains considerably fewer S4 slots, instead organized structured list elements Data, Model, Fit, . Additionally, information matrix slot removed favour providing asymptotic covariance matrix (.k.., inverse information matrix)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"minor-changes-1-14","dir":"Changelog","previous_headings":"","what":"MINOR CHANGES","title":"Changes in mirt 1.14","text":"added extract.mirt() function allow convenient extracting internal elements crossprod SE.type now incorporates latent variable information (replaces NA placeholders) changed default full.scores = FALSE argument TRUE fscores() added profile argument plot() mdirt() objects profile plots can generated converge_info option added fscores() return convergence information add removeEmptyRows option technical list","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-14","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.14","text":"return vector NAs WLE estimation Fisher information matrix determinant 0 (reported Christopher Gess) fix df multiple-group models crossed /within constrains (reported Leah Feuerstahler) compute residuals responses sparse, return NaN residual computed (reported Aaron Kaat)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-113","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.13","title":"Changes in mirt 1.13","text":"CRAN release: 2015-09-10 adjust plausible values format multiple group objects simdata() gains model input impute data pre-organized models (useful conjunction mirtCAT generate datasets already converged models). Also gains mins argument specify lowest category item model supplied (default 0) number SEMCYCLES increased 50 100 MH-RM algorithm, RM gain rate changed c(.15, .65) c(.1, .75) improve item fit statistics using imputations facet plots now try keep items respective order panel theme lattice plots changed default lighter blue colour, legend now automatically placed right hand side rather top","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-13","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.13","text":"fix Q3 computations (noticed Katherine Castellano)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-110","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.10","title":"Changes in mirt 1.10","text":"CRAN release: 2015-06-16 using prior distributions, starting values now automatically set equal mode prior distribution, appropriate lower upper parameter bounds supplied added NEXPLORE term mirt.model() specify exploratory models via syntax add itemGAM() function provide non-linear smoother better understanding mis-functioning items (without loosing established precision reverting purely non-parametric IRT methods) category scores now automatically recoded spaces 1, message printed /occurs added MDISC() MDIFF() functions inclusion prior parameter distributions now report log-posterior rather log-likelihood. Functions anova() also report Bayesian criteria rather previous likelihood-based model comparison statistics impute argument itemfit() M2() now use plausible values instead point estimates START syntax element mirt.model() now supports multiple parameters, FIXED argument added declare parameters ‘fixed’ staring values added LBOUND UBOUND syntax support mirt.model() report proper lower upper bounds starting values data frame mod2values() invariance argument bfactor() now automatically indexes second-tier factors make multiple-group testing bfactor() easier remove rotate Target arguments model objects, pass axillary functions summary(), fscores(), etc model based arguments now can strings, passed mirt.model(). now preferred method defining models syntactically, though previous methods still work integration range (theta_lim) globally set c(-6, 6), number default quadrature nodes systematically increased parameter estimation functions. slightly change numerical results, provides consistence throughout package add theta_lim arguments various functions better control QMC grid, effective usage higher dimensions internal code organization now makes easier add user defined itemtypes (can natively added package, requested)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-10","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.10","text":"fix conservative imputation standard errors itemfit() M2() (reported Irshad Mujawar) fixed plausible value draws multidimensional latent regression models (reported Tongyun Li) don’t allow crossprod, Louis, sandwich information matrices using custom item types (reported Charlie Rutgers)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-19","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.9","title":"Changes in mirt 1.9","text":"CRAN release: 2015-03-29 using coef(mod, printSE=TRUE) g u parameters relabeled logit(g) logit(u) represent internal labels added various facet plots three dimensional models plot() generic support optimizer = 'nlminb', pass optimizer control arguments contol list added fixef() function extract expected values implied fixed effect parameters latent regression models added gpcm_mats argument estimation functions specifying customize scoring pattern multidimensional generalized partial credit models added custom_theta input fscores() including customized integration grids add suppress argument residuals() M2() suppress local dependence values less specific value print message DIF() DTF() hyper-parameters freely estimated focal groups constraits hetorogenous item names added mirt.model() syntax WLE support multidimensional models added added 'SEcontour' argument plot() generic use NA’s fscores() response patterns contain NA responses (suggested Tomasz Zoltak)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fix-1-9","dir":"Changelog","previous_headings":"","what":"BUG FIX","title":"Changes in mirt 1.9","text":"S-X2 itemfit() now returns appropriate values multiple-group models multidimensional plausible value imputation fix (reported KK Sasa) plot(..., type = 'infotrace') multiple group objects fixed (reported Danilo Pereira)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-18","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.8","title":"Changes in mirt 1.8","text":"CRAN release: 2015-01-22 fscores() nows accepts method = \"plausible\" draw single plausible value set plot() default type now score, accept rotation arguments exploratory models (default rotation 'none') imputeMissing() supports list plausible values generate multiple complete datasets new custom_den input fscores() use custom prior density functions Bayesian estimates optimized version ‘WLE’ estimator fscores() empirical reliability added method = 'EAPsum' fscores() new START argument mirt.model() specifying simple starting values one parameter time","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fix-1-8","dir":"Changelog","previous_headings":"","what":"BUG FIX","title":"Changes in mirt 1.8","text":"fix carryover print-error summary() confirmatory models estimated bound contraints included group hyper-parameters (reported KK Sasa)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-17","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.7","title":"Changes in mirt 1.7","text":"CRAN release: 2014-12-15","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-7","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.7","text":"improved estimation efficiency using MH-RM algorithm. result, default seed changed, therefore results previous versions slightly different objects class ‘ExploratoryClass’ ‘ConfirmatoryClass’ merged single class ‘SingleGroupClass’ exploratory logical slot technical = list(SEtol) criteria approximating information matrix lowered 1e-4 mixedmirt() provide better standard error estiamtes","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-7","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.7","text":"boot.mirt now uses optimizer used estimate model (default previously EM) mixedmirt now supports interaction effects random intercepts, including cross-level interactions added averageMI() function compute multiple imputation averages plausible values methodology using Rubin’s 1987 method plausible value imputation now available fscores() using new plausible.draws numeric input add return.models argument DIF() return estimated models free/constrained parameters latent regression models added mixedmirt() non-Rasch models using new lr.formula input mirt.model() syntax can now define within individual item equality constraints using 1 parameter specification name syntax latent regression models added mirt() function using new covdata formula inputs added confidence envelope plots PLCI.mirt, throw warnings intervals located coef() now accepts simplify logical, indicating whether items collapsed matrix returned list length 2 (suggested Michael Friendly)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-7","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.7","text":"bias correction variance estimates mixedmirt random effects included (reported KK Sasa) fix missing data imputation bug itemfit() (reported KK Sasa) M2 statistic bifactor/two-tier models overly conservative better checks numerical underflow issues use triangle 0’s identifying exploratory IFA models. , standard errors/condition numbers exploratory models can estimated ","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-161","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.6.1","title":"Changes in mirt 1.6.1","text":"CRAN release: 2014-10-10","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-6-1","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.6.1","text":"sirt package added suggests list. Special thanks Alexander Robitzsch (author sirt) developing useful wrapper functions mirt mirt.wrapper.coef(), tam2mirt(), andlavaan2mirt(). well, many examples sirt demonstrate possibility estimating specialized IRT models mirt, : Ramsay quotient, latent class, mixed Rasch, located latent class, probabilistic Guttman, nonparametric, discrete graded membership, multidimensional IRT discrete traits, DINA, Rasch copula models. exploratory IRT models longer rotated default coef(), now requires explicit rotate argument computation S_X2 statistic itemfit now much stable polytomous item types support plink package now unofficially dropped removed CRAN data inputs now required category spacing codings exactly equal 1 (e.g., [0, 1, 2, …]; patterns [0, 2, 3] implicitly missing spaces now invalid)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-6-1","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.6.1","text":"mdirt function added model discrete latent variables latent class analysis dichotomous polytomous items. Can used model several discrete IRT models well, located latent class model, multidimensional IRT discrete traits, DINA models, etc. See examples documentation details axillary support DiscreteClass objects added itemfit(), M2(), fscores(), wald(), boot.mirt() S-X2 statistic available itemfit() generalized include multidimensional models method 'QMCEM' added quasi-Monte Carlo integration mirt() multipleGroup() estimating higher dimensional models greater accuracy (suggested Alexander Robitzsch). Several axillary function fscores(), itemfit(), M2() also now contain QMC argument (accept one … argument) use integration scheme better accuracy higher dimensional models nonlinear parameter constraints EM estimation can specified using Rsolnp alabama packages passing optimizer = 'solnp' optimizer = 'alabama', well relevant package arguments solnp_ags alabama_ags list inputs itemnames argument added mirt.model() allow model specifications using raw item names rather location indicators accelerate argument changed logical character vector, now allowing three potential options: ‘Ramsay’ (default), ‘squarem’, ‘none’ modifying EM acceleration approach","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-6-1","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.6.1","text":"fixed bug bfactor() starting values NAs specified model argument adjust overly optimistic termination criteria EM algorithm","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-15","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.5","title":"Changes in mirt 1.5","text":"CRAN release: 2014-08-14","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-5","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.5","text":"efficiency, Hessian longer computed fscores() unless required returned object estimation method = 'MHRM' now requires explicitly SE=TRUE call compute information matrix. matrix now computed using ML estimates rather approximated sequentially iteration (unstable), therefore separate stage performed. provides much better accuracy computations","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-5","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.5","text":"new extract.group() function extract single group object objects previously returned multipleGroup() return SRMSR statistic M2() along residual matrix (suggested Dave Flora) accept Etable default input customPriorFun (suggested Alexander Robitzsch) vignette files package examples now hosted Github can accessed following link mentioned vignette location index ?mirt help file E-step now computed parallel (available) following mirtCluster() definition run M-step optimizations passing TOL = NaN. Useful model converge instantly parameters exactly equal starting values confidence envelope plots itemplot() generate shaded regions instead dotted lines, confidence interval plots added plot() generic MI input passes fscores() slightly optimized upcoming mirtCAT package release method = 'EAPsum' argument fscores() support multidimensional models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-5","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.5","text":"fix forcing SEs MHRM information matrix computations positive imputeMissing() crash fix multiple-group models fix divide--0 bug E-step number items large fix crash EM estimation SE.type = 'MHRM'","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-14","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.4","title":"Changes in mirt 1.4","text":"CRAN release: 2014-06-22","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-4","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.4","text":"calculating information matrix exploratory item factor analysis models disabled since rotational indeterminacy model results improper parameter variation changed default theta_lim c(-6,6) number quadrature defaults increased well @Data slot added organizing data based arguments. Removed several data slots estimated objects consequence removed ‘Freq’ column passing response.pattern argument fscores() increase number Mstep iterations proportionally quasi-Newton algorithms estimation approaches ML location ‘rsm’ itemtype removed now optimized version implemented","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-4","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.4","text":"link mirt vignettes Github registered knitr package now available package index optimizer argument added estimation function switch default optimizer. Multiple optimizers now available, including BFGS (EM default), L-BFGS-B, Newton-Raphson, Nelder-Mead, SANN new survey.weights argument can passed parameter estimation functions (.e., mirt()) apply -called stratification/survey-weights estimation returnList argument added simdata() return list containing S4 item objects, Theta matrix, simulated data support custom item type fscores() computations response.pattern passed instead original data impute option itemfit() M2() estimate statistics via plausible imputation missing data present multidimensional ideal-point models added dichotomous items M2* statistic added polytomous item types Bock Lieberman ('BL') method argument added (recommend serious use)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-4","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.4","text":"large bias correction information matrix standard errors models contain equality constraints (standard errors high) drop dimensions fix nested logit models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-13","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.3","title":"Changes in mirt 1.3","text":"CRAN release: 2014-04-23","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-3","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.3","text":"default SE.type changed crossprod since better detecting models identified compared SEM, generally much cheaper compute larger models M-step optimizer now automatically selected ‘BFGS’ bounded parameters, ‘L-BFGS-B’ otherwise. models notably different parameter estimates , nearly identical model log-likelihoods better shiny UI adapts itemtype specifically, allows classical parameter inputs (special thanks Jonathan Lehrfeld providing code inspired changes) scores.option now set TRUE fscores() type = 'score' plot generics longer adjusts categories expected test scores M-step optimizer EM now deters --order graded response model intercepts (problem startvalues far ML estimate graded models)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-3","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.3","text":"return.acov logical added fscores() return list matrices containing ACOV theta values used compute SEs (suggested Shiyang Su) printCI logical option summary() print confidence intervals standardized loadings new expected.test() function, extension expected.item() whole test mirt.model() syntax supports multiple * combinations COV = easily specifying covariation blocks factors. Also allows variances freed specifying factor name, e.g., F*F full.scores.SE logical option fscores() return standard errors respondent multiple imputation (MI) option fscores(), useful obtaining less biased factor score estimates model parameter variability large (usually due smaller sample size) group-level (.e., means/covariances) equality constrains now available EM algorithm theta_lim input plot(), itemplot(), fscores() modifying range latent values evaluated","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-3","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.3","text":"personfit() crash multipleGroup objects since itemtype slot filled (reported Michael Hunter) fix crash two-tier models correlations estimated (reported David Wu) R 3.1.0 appears evaluate List objects differently c level causing strange behaviour, therefore slower R versions internal function (mirt:::reloadPars()) used patch formed behaviour mvtnorm::dmvnorm changed version 0.9-9999, causing widely different convergence results. Similar versions older mvtnorm functions now implemented instead","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-121-1","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.2.1","title":"Changes in mirt 1.2.1","text":"CRAN release: 2014-02-21","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-2-1","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.2.1","text":"fitIndices() replaced M2() function, currently limited dichotomous items class ‘dich’ bfactor() default SE.type set ‘crossprod’ rather ‘SEM’ generalized partial credit models now display fixed scoring coefs TOL convergence criteria moved outside technical input argument restype argument residuals() changed type consistent package removed fitted() since residuals(model, type = 'exp') gives essentially output mixedmirt SE set TRUE default help construct accurate information matrix specified, S-EM TOL dropped 1e-6 EM, SEtol = .001 parameter better approximate information matrix","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-2-1","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.2.1","text":"two new SE.type inputs: ‘Louis’ ‘sandwich’ computing Louis’ 1982 computation observed information matrix, sandwich estimate covariance matrix .data.frame logical option coef() convert list row-stacked data.frame type = 'scorecontour' added plot() contour plot expected total scores type = 'infotrace' added itemplot() plot trace lines information plot, type = 'tracecontour' contour plot using trace lines (suggested Armi Lantano) mirt.model() support multi-line inputs new type = 'LDG2' input residuals() compute local dependence stat based G2 instead X2, type = 'Q3' added well S-EM computation information matrix support latent parameters, previously effective estimation item-level parameters. technical option also added force information matrix symmetric (default set TRUE better numerical stability) new empirical.CI argument itemfit() used plotting confidence intervals dichotomous items (suggested Okan Bulut) printSE argument can now passed coef() printing standard errors instead confidence intervals. consequence, rawug automatically set TRUE (suggested Olivia Bertelli) second-order test condition number added estimated objects information matrix computed tables argument can passed residuals() return observed expected tables used computing LD statistics","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-2-1","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.2.1","text":"using scores.= TRUE multipleGroup objects returns correct person ordering (reported Mateusz Zoltak) read.mirt() crash fix multiple group analyses objects (reported Felix Hansen) updated math SE.type = 'crossprod'","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-11","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.1","title":"Changes in mirt 1.1","text":"CRAN release: 2013-12-20","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-1","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.1","text":"facet_items argument added plot() control whether separate plots constructed item merge onto single plot three dimensional models supported itemplot() types trace, score, info, SE new DIF() function quicky calculate common differential item functioning routines, similar IRTLRDIF worked. Supports likelihood ratio testings well Wald approach, includes forward backword sequential DIF searching methods added shiny = TRUE option itemplot() run interactive shiny applet. Useful instructive purposes, well understanding internal parameters mirt behave type = 'trace' type = 'infotrace' support added plot generic multiple group objects fscores(..., method = 'EAPsum') returns observed expected values, along general fit statistics printed console returned ‘fit’ attribute removed multinomial constant log-likelihood since influence nested model comparisons SE.type = 'crossprod' Fisher added computing parameter information matrix based variance Fisher scoring vector complete Fisher information matrix, respectively customPriorFun input technical list now available utilizing user defined prior distribution functions EM algorithm empirical histogram estimation now available mirt() multipleGroup() unidimensional models. Additional plot type = 'empiricalhist' also added plot() generic re-implement read.mirt() better consistency checking plink package","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-1","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.1","text":"starting values multipleGroup() now returns proper estimated parameter information invariance input argument remove .integer() MultipleGroup df slot pass proper item type using custom pattern calles fscores() return proper object personfit gpcm models used","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-10","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.0","title":"Changes in mirt 1.0","text":"CRAN release: 2013-11-01","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.0","text":"GenRandomPars logical argument now supported technical = list() input. generate random starting values freely estimated parameters, can helpful determine obtained solutions local minimums seperate free_var free_cov invariance options available multipleGroup new CONSTRAIN CONSTRAINB arguments mirt.model() syntax specifying equality constraints explicitly parameters accross items groups. Also PRIOR = ... specification brought back uses similar format new CONSTRAIN options plot(..., type = 'trace') now supports polytomous dichotomous tracelines, type = 'infotrace' better y-axis range removed ‘1PL’ itemtype since name ambiguous. Still possible obtain however applying slope constraints 2PL/graded response models plot() contains .items argument specify items plot aggregate type, 'infotrace' 'trace' fitIndicies() return CFI.M2 TLI.M2 argument calcNull = TRUE passed. CFI stats also normed fall 0 1 data.frame returned mod2values() pars = 'values' now contains column indicating internal item class use ginv() MASS package improve accuracy fitIndices() calculation M2","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.0","text":"fix error thrown PLCI.mirt parameter value equal bound fix global df values, restrict G2 statistic tables sparse","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-090","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.9.0","title":"Changes in mirt 0.9.0","text":"CRAN release: 2013-08-31","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-0-9-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 0.9.0","text":"PLCI.mirt() function added computing profiled likelihood standard errors. Currently applicable unidimensional models prior distributions returned pars = 'values' data.frame along input parameters, can edited returned well full.scores option residuals() compute residuals row original data bfactor() can include additional model argument modeling two-tier structures introduced Cai (2010), now supports 'group' input multiple group analyses added general Ramsey (1975) acceleration EM estimation default. Can disable accelerate = FALSE (done automatically estimating SEM standard errors) renamed response.vector response.pattern fscores(), now supports matrix input computing factor scores larger data sets (suggested Felix Hansen) total.info logical added iteminfo() return either total item information information category mirt.model() supports -called Q-matrix input format, along matrix input covariance terms MH-RM algorithm now accessible passing mirt(..., method = 'MHRM'), confmirt() function removed completely. confmirt.model() also renamed mirt.model() support polynomial interaction terms EM estimation lognormal priors may now passed parprior iterative computations fscores() can now run parallel automatically following mirtCluster() definition mirtCluster() function added make utilizing parallel cores convenient. Globally removed cl argument multi-core objects updated documentation data sets adding relevant examples, added Bock1997 data set replicating table 3 van der Linden, W. J. & Hambleton, R. K. (1997) Handbook modern item response theory general speed improvements functions","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-0-9-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 0.9.0","text":"WLE estimation fixed now estimates extreme response patterns exploratory starting values longer crash datasets huge number NAs, caused standard deviations zero math fix beta priors","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-080","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.8.0","title":"Changes in mirt 0.8.0","text":"CRAN release: 2013-07-02","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-0-8-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 0.8.0","text":"support random effect predictors now available mixedmirt(), along randef() function computing MAP predictions random parameters EAPsum support fscores() mixed item types consistency current IRT software (rather TESTFACT POLYFACT), scaling constant set D = 1 fixed value nominal.highlow option added specify categories highest lowest nominal models. Often provide better numerical stability utilized. Default still use highest lowest categories increase number draws Monte Carlo calculation log-likelihood 3000 5000 itemtype equal ‘Rasch’ ‘rsm’ models latent variance parameter(s) automatically freed estimated mixedmirt() supportive user defined R formulas, now includes internal ‘items’ argument create item design matrix used estimate intercepts. closely mirrors results lme4 Rasch models well (special thanks Kevin Joldersma testing debugging) drop.zeros option added extract.item itemplot reduce dimensionality factor structures contain slopes equal zero EM tolerance (TOL argument) default dropped .0001 (originally .001) type = 'score' type = 'infoSE' added plot() generic expected total score joint test standard error/information custom latent mean covariance matrix can passed fscores() EAP, MAP, EAPsum methods. Also applies personfit() itemfit() diagnostics scores.option fscores() returning just estimated factor scores bfactor can include NA values model omit estimation specific factors corresponding item","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-0-8-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 0.8.0","text":"limiting values z.outfit z.infit statistics small sample sizes (fix suggested Mike Linacre) missing data gradient bug fix MH-RM dichotomous item models global df fix multidimensional confirmatory models SEM information matrix computed accuracy (M-step identical original EM), fixed equality constrains imposed","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-070","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.7.0","title":"Changes in mirt 0.7.0","text":"CRAN release: 2013-04-21","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-0-7-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 0.7.0","text":"new '#PLNRM' models fit Suh & Bolt (2010) nested logistic models 'large' option added estimation functions. Useful datasets analysed large organizing data becomes computationally burdensome task avoided fitting new models. Also, overall faster handling datasets plot(), fitted(), residuals() generic support added MultipleGroup objects CFI X2 model statistics added, output now includes fit stats w.r.t. G2 X2 z stats added itemfit/personfit infit outfit statistics supplemented EM (‘SEM’) added calculating information matrix EM history. default TOL value dropped help make EM iterations longer stable. Supports parallel computing added return empirical reliability (returnER) option fscores() plot() supports individual item information trace lines graph (dichotomous items ) option type = 'infotrace' createItem() function available defining item types can passed estimation functions. can used model items available package (anywhere matter) EM MHRM. Derivatives computed numerically default using numDeriv package defining item types fly Mstep EM moved quasi-Newton instead home grown MV Newton-Raphson approach. Gives stability estimation Hessian ill-conditioned, provide easier front-end defining user rolled IRT models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-0-7-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 0.7.0","text":"small bias fix Hessian gradients mirt() implementation causing likelihood always increasing near maximum fix input itemplot() object list model objects fixed implementation infit outfit Rasch statistics order nominal category intercepts sometimes backwards. Fixed now S_X2 collapsed cells much caused negative df response.vector input now supports NA inputs (reported Neil Rubens)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-060","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.6.0","title":"Changes in mirt 0.6.0","text":"CRAN release: 2013-03-19","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 0.6.0","text":"S-X2 statistic computed automatically unidimensional models via itemfit() EAP sum-scores added fscores() method = ‘EAPsum’. Works full.scores option well improve speed estimation multipleGroup() latent means/variances estimated multipleGroup(invariance = ’’) can include item names specify items considered invariant across groups. Useful anchoring DIF testing type = ‘trace’ option added plot() display item trace lines single graph (dichotomous items ) default estimation method multipleGroup() switched ‘EM’ boot.mirt() function added computing bootstrapped standard errors via boot package (supports parallel computing well), well new option SE.type = ’’ choosing Bock Lieberman MHRM type information matrix computations indexing items itemplot, itemfit, extract.item can called using either number original item name added probtrace() function front end users generate probability trace functions models plotting item tracelines two categories now omits lowest category (common) parallel option passed calcLogLik compute Monte Carlo log-likelihood quickly. Can also passed call stack confmirt, multipleGroup, mixedmirt Confidence envelopes option added itemplot() trace lines information plots lbound ubound parameter bounds now available user restricting parameter estimation space mod2values() function added convert estimated mirt model appropriate data.frame used determine parameter estimation characteristics (starting values, group names, etc) added imputeMissing() function impute missing values given estimated mirt model. Useful checking item person fit diagnostics obtaining overall model fit statistics allow Rasch itemtype multidimensional confirmatory models oblimin new default exploratory rotation (suggested Dave Flora) flexible calculation M2 statistic fitIndicies(), user prompt option internal variables grow large cause time/RAM problems","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-0-6-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 0.6.0","text":"read.mirt() fixed objects contain standard errors (didn’t properly line ) mixedmirt() fix COV argument supplied (reported Aaron Kaat) fix multipleGroup independent groups don’t contain potential response options (reported Scot McNary) prevent using ‘free_means’ ‘free_varcov’ multipleGroup since identified without constraints (reported Ken Beath)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-050","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.5.0","title":"Changes in mirt 0.5.0","text":"CRAN release: 2013-01-17 dichotomous, graded rating scale, (generalized) partial credit, rating scale, nominal models better optimized wald() now support information matrices contain constrained parameters confmirt.model() can accept string inputs, may useful knitr/sweave documents since scan() function tends hang multipleGroup() now logical options bfactor = TRUE use dimensional reduction algorithm factor pattern structured like bifactor model new fitIndices() function added compute additional model fit statistics M2 testinfo() function added test information lower bound parameters stringent control estimation bounded never higher .6 infit outfit stats itemfit() now work Rasch partial credit rating scale models Rasch rating scale models can now estimated potential rsm.blocks (grsm model). “Generalized” rating scale models can also estimated, though requires manipulating starting values directly added sample size adjusted BIC (SABIC) information statistics new mixedmirt() function estimating IRT models person item level (e.g., LLTM) covariates. Currently supports fixed effect predictors, random effect predictors developed structured output using anova() generic","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-042","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.4.2","title":"Changes in mirt 0.4.2","text":"CRAN release: 2012-11-25 item probability functions now permit permissible values, models may converge even log-likelihood decreases estimation. EM model strictly increasing log-likelihood warning message printed infit outfit statistics now applicable Rasch models (), itemfit/personfit() ‘method’ argument added specify factor score estimates used read.mirt() re-added package allow translating estimated models format usable plink package test standard error added plot() generic using type = ‘SE’, expected score plot added itemplot() using type = ‘score’ weighted likelihood estimation (WLE) factor scores now available (without standard errors) removed allpars option coef() generics return named list (possibly rotated) item group coefficients information functions slightly positively biased due logistic constant adjustment, fixed models. Also, information functions now available almost item response models (mcm items missing) constant (D) used estimating logistic functions can now modified (default still 1.702) partcomp models recently broken, fixed now one parameter can now passed parprior make specifying identical priors convenient","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-041","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.4.1","title":"Changes in mirt 0.4.1","text":"CRAN release: 2012-10-23 relative efficiency plots added itemplot(). Works directly multipleGroup analysis comparing different item types (e.g., 1PL vs 2PL) can wrapped named list infit outfit statistics added personfit() itemfit() empirical reliability printed dimension fscores(…, fulldata = FALSE) called better system specify fixed/free parameters starting values using pars = ‘values’. allow much better simulation based work graded model type rating scale added (Muraki, 1990) optional estimation ‘blocks’. Use itemtype = ‘grsm’, grsm.block option multipleGroup(), optional input added change current freely estimated parameters values previously computed model. save needless iterations EM MHRM since parameters much closer new ML estimates itemplot() supports multipleGroup objects now analytical derivatives much stable, although yet optimized estimation bug fix bfactor(), slight bias fix mirt() estimation (introduced version 0.4.0 multipleGroup() added) updated documentation beamer slide show included background MIRT packages capabilities labels added coef() standard errors computed. Also allpars = TRUE now default kernel estimation moved entirely one method. Much easier maintain guarantees consistency across methods (.e., quasi-Newton algorithms used)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-040","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.4.0","title":"Changes in mirt 0.4.0","text":"CRAN release: 2012-09-22 Added itemfit() personfit() functions uni multidimensional models. Within itemfit empirical response curves can also plotted unidimensional models Wrapped itemplot() fscores() S3 function better documentation. Also response curve now contained individual plots Added free.start list option estimation functions. Allows quicker way specify free fixed parameters Added iteminfo() extract.item() calculate item information extract desired items Multiple group estimation available multipleGroup() function. Uses EM MHRM estimation engines. MHRM seems faster two factors+ though naturally accurate, therefore set default wald() function added testing linear constraints. Useful situations testing sets parameters rather estimating new model likelihood ratio test Methods use MHRM can now estimate nominal, gpcm, mcm, 4PL models fscores computable multiple group objects general play nicer missing data (reported Judith Conijn). Also, using options full.scores = TRUE optimized Rcpp Oblique rotation bug fix fscores coef (reported Pedro . Barbetta) Added item probability equations ?mirt documentation reference General bug fixes usual spawned added features. Overall, stay frosty.","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-031","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.3.1","title":"Changes in mirt 0.3.1","text":"Individual classes now correspond type methods: ExploratoryClass, ConfirmatoryClass, MultipleGroupClass plot itemplot now works confmirt objects mirt can now make use confmirt.model specified objects hence confirmatory well stochastic estimation factor scores removed entirely, now quadrature based methods objects. Also, bfactor returned objects now estimate factors scores instead just general dimension Standard errors mirt now automatically calculated (borrowed running tweaked MHRM run)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-030","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.3.0","title":"Changes in mirt 0.3.0","text":"CRAN release: 2012-08-23 radically changed underlying mechanisms estimation functions decided polymirt() redundant replaced completely calling confmirt(data, number_of_factors). reason change facilitate wider range MIRT models allow easier extensions future multiple group analysis multilevel modelling new univariate MV models available, including 1-4 parameter logistic generalized partial credit, nominal, multiple choice models. called specifying character vector called ‘itemtype’ length nitems options ‘2PL’,‘3PL’,‘4PL’,‘graded’,‘gpcm’, ‘nominal’, ‘mcm’; use ‘PC2PL’ ‘PC3PL’ partially-compensatory items. itemtype = ‘1PL’ ‘Rasch’, 1-parameter logistic/1-parameter ordinal Rasch/partial credit models estimated data. default assumes items either ‘2PL’ ‘graded’, . flexible user defined linear equality restrictions may imposed estimation functions, can prior parameter distributions, start values, choice parameters estimate. follow general 2 steps: Call function normally use, example, mirt(data, 1, startvalues = ‘index’) return start values indexed Edit please (without changing structure), input back function mirt(data, 1, startvalues = editedstartvalues). true parprior (MAP priors), constrain (linear equality constraints), freepars (parameters freely estimated), little quirk. inputs lists named parameters easy identification manipulation. Note means partial credit model Rasch models may calculated well modifying either start values constraints accordingly (e.g., constrain slopes equal 1/1.702 freely estimated classical Rasch model, equal estimated 1PL model) number confmirt.model() options decreased due new way specify item types, startvalues, prior parameter distributions, constraints plink package kept item information curves, ’ll implement now. Replaced plink item plots ‘itemplots’ function ones rolled package descriptions documentation updated coef() now prints slightly different output, new option ‘allpars = TRUE’ display item group parameters, returned list simdata() updated support new item types accurate standard errors MAP ML factor scores, specific factors bfactorClass objects can now estimated methods","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-026-1","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.6-1","title":"Changes in mirt 0.2.6-1","text":"dropped ball lots bug fixes round. Future commits avoid problem utilizing testthat package test code extensively release internal change confmirt function move MHRM engine outside function better maintenance theta_angle added mirt polymirt plots changing viewing angle w.r.t theta_1 null model longer calculated missing data present fixed item slope models estimated mirt() associated standard errors","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-026","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.6","title":"Changes in mirt 0.2.6","text":"CRAN release: 2012-07-15 null model computed, allowing model statistics TLI documentation changes many back end technical details estimation moved technical lists support GPArotation methods options, including Target rotations polymirt() uses confmirt() estimation engine 4PL support mirt() bfactor(), treating upper bound fixed coef() now rotate option returning rotated IRT parameters","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-025","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.5","title":"Changes in mirt 0.2.5","text":"CRAN release: 2012-06-07 Fixed translation bug C++ code bfactor() causing illegal vector length throw Fixed fscores() bug using polychotomous items mirt() bfactor() pass rotate=‘rotation’ mirt polymirt override default ‘varimax’ rotation estimation time (suggested Niels Waller) RMSEA, G^2, p set NaN instead internal placeholder missing data df adjusted missing data present oblique rotations return invisible factor correlation matrix","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-024","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.4","title":"Changes in mirt 0.2.4","text":"CRAN release: 2012-05-09 degrees freedom correctly adjusted using noncompensatory items confmirtClass reorganized work S4 methods, now work consistently methods. fixed G^2 log-likelihood logLik() product terms included bugfix drawThetas noncompensatory items used","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-023","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.3","title":"Changes in mirt 0.2.3","text":"CRAN release: 2012-05-02 bugfixes fscores, itemplot, generic functions read.mirt() added creating suitable plink object mirt() bfactor() can now accommodate polychotomous items using ordinal IRT scheme itemplot() now makes use handy plink package plots, giving good deal flexibility. Generic plot()’s now use lattice plots extensively","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-022","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.2","title":"Changes in mirt 0.2.2","text":"Ported src code Rcpp future tweaking. Added better fitted() function missing data exist (noticed Erin Horn)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-021","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.1","title":"Changes in mirt 0.2.1","text":"CRAN release: 2012-04-06 ML estimation factor scores mirt bfactor RMSEA statistic added fitted models Nonlinear polynomial estimation specification confmirt models, now consistent returned labels Provide better identification criteria confmirt() (suggested Hendrik Lohse)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-020","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.0","title":"Changes in mirt 0.2.0","text":"CRAN release: 2012-02-15 parameter standard errors added mirt() (1 factor ) bfactor() models bfactor() values ommited recoded NA summary coef better viewing ‘technical’ added confmirt function, allowing various tweaks varying beta prior weights product relations added confmirt.model(). Specified enclosing brackets using asterisk documentation fixes roxygenize","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-0120","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.1.20","title":"Changes in mirt 0.1.20","text":"allow lower bound beta priors vary items (suggested James Lee)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-016","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.1.6","title":"Changes in mirt 0.1.6","text":"bias fix mirt() function (noticed Pedro Barbetta)","code":""}]
